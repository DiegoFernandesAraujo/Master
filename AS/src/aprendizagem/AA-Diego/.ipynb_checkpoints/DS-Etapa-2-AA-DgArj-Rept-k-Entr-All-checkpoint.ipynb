{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Desconsiderando os registros que possuam grande concordância ou pouquíssima concordância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lançando mão da entropia e monotonicidade sobre **conjunto único**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# nao_passaram = 0\n",
    "# iteracoes = 0\n",
    "\n",
    "############################################################################################################################\n",
    "#Definição de funções\n",
    "############################################################################################################################\n",
    "\n",
    "#Função para geração do F1 médio\n",
    "def geraF1(toClass, classificador): #toClass é o conjunto de treinamento\n",
    "    \n",
    "    f1 = 0\n",
    "    std = 0\n",
    "    coef_var = 0\n",
    "    \n",
    "    if classificador == 'SVM':\n",
    "        modelo = SVC(random_state = seed)\n",
    "    elif classificador == 'DT':\n",
    "        modelo = DecisionTreeClassifier(random_state = seed)\n",
    "    \n",
    "    #Separação do conjunto X e y\n",
    "    XtoClass = toClass.iloc[:,1:]\n",
    "    ytoClass = toClass.duplicata\n",
    "    \n",
    "    #Divisão dos conjuntos de treino e teste (20% para esse último)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(XtoClass, ytoClass, test_size=0.20, random_state=seed)\n",
    "    \n",
    "    #Validação cruzada\n",
    "    #This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    "    \n",
    "    kfold = KFold(n_splits=5, random_state=seed)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        kfold = StratifiedKFold(n_splits=5, random_state=seed) #Mudar para n-fold #Adicionado depois!\n",
    "        \n",
    "    except ValueError:\n",
    "                \n",
    "        kfold = KFold(n_splits=5, random_state=seed)\n",
    "            \n",
    "    except:\n",
    "        print('Erro com a validação cruada!')\n",
    "        print (\"Unexpected error:\", sys.exc_info()[0])\n",
    "    \n",
    "    try:\n",
    "        cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "        \n",
    "        f1 = cv_results.mean()\n",
    "        std = cv_results.std()\n",
    "        coef_var = std/f1\n",
    "    except:\n",
    "        print(\"ERRO NA VALIDAÇÃO CRUZADA!\")\n",
    "#         print(\"Conjunto de treinamento:\")\n",
    "#         print(toClass)\n",
    "        print(\"Tamanho de toClass: {0}\".format(len(toClass)))\n",
    "        print (\"Unexpected error:\", sys.exc_info()[0])\n",
    "        \n",
    "    \n",
    "#     tamTreino = len(XtoClass)\n",
    "    \n",
    "    return f1, std, coef_var#, tamTreino\n",
    "\n",
    "#Função para geração do conjunto de treinamento\n",
    "def geraTrainSet(ct, dir, file1):\n",
    "\n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)     \n",
    "    \n",
    "#Função para geração do conjunto de teste\n",
    "def geraTestSet(ct, dir, file1):\n",
    "\n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)            \n",
    "    \n",
    "############################################################################################################################\n",
    "#Repetições para os experimentos começam aqui\n",
    "############################################################################################################################\n",
    "\n",
    "#Parâmetros do usuário (Definir entrada dos dados)\n",
    "estat_ord = 'min' #Estatística para ordenamento\n",
    "qtd_alg = 23 #Quantidade total de algoritmos\n",
    "qtd_alg_nd = 2 #Quantidade máxima de algoritmos para separar o conjunto de possíves não-duplicadas\n",
    "# k = 3 #Tamanho da janela\n",
    "# janelas = [2,3,4,5]\n",
    "janelas = [3]\n",
    "orcamento = 100 #Ou uma porcentagem da base de dados\n",
    "orcamento_orig = orcamento\n",
    "tam_min_ct = 20\n",
    "seed = 500\n",
    "nAlg = 23\n",
    "\n",
    "etapa = '2 - AA[dg-arj]'\n",
    "\n",
    "# dirOrig = \"../../csv/conjuntosDS/conjuntosDiverg/\"\n",
    "dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAA/\"\n",
    "estat = \"../../csv/estatisticaInicialDS.csv\"\n",
    "\n",
    "for k in janelas:\n",
    "    \n",
    "    nao_passaram = 0\n",
    "    iteracoes = 0\n",
    "\n",
    "\n",
    "    estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados', 'etapa', 'permutacao'], sep=';')\n",
    "\n",
    "    arquivos = [] #Adicionado depois\n",
    "\n",
    "    for _, _, arquivo in os.walk(dirOrig):\n",
    "         arquivos.extend(arquivo)   \n",
    "\n",
    "    for arq in arquivos:\n",
    "\n",
    "        if '_NEW' in arq:\n",
    "            print(\"##################################################################\")\n",
    "            print(\"Analisando o arquivo: {0}\".format(arq))\n",
    "            print(\"##################################################################\")\n",
    "\n",
    "            iteracoes += 1\n",
    "\n",
    "            num = re.sub(r'diverg.*\\)', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            num = num.replace('_NEW.csv','')\n",
    "\n",
    "            algUtl = re.sub(r'diverg.*\\(', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = re.sub(r'\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = int(algUtl)\n",
    "\n",
    "            permutacao = int(num)\n",
    "\n",
    "            linhaAtual = estatisticas.xs((algUtl, '1 - acm diverg', permutacao))    \n",
    "\n",
    "            ###### Leitura do conjunto de pares conflitantes\n",
    "            pc = dirOrig+arq\n",
    "\n",
    "            pc = pd.read_csv(pc, sep=';', index_col=['elemento1', 'elemento2']) #pares conflitantes\n",
    "\n",
    "            cols = list(pc.columns.values)\n",
    "            cols.pop(cols.index('duplicata'))\n",
    "            pc = pc[['duplicata']+cols]\n",
    "\n",
    "            pc_aa = pc.iloc[:, :5 ] #Conjunto onde serão aplicadas as janelas deslizantes\n",
    "            pc_vetores = pc.iloc[:, 5: ] #Conjunto base para compor o conjunto treinamento \n",
    "            \n",
    "            #Criação da coluna de ENTROPIA\n",
    "            \n",
    "            #ENTROPIA = −[P+(e) · ln(P+(e)) +P−(e) · ln(P−(e))]\n",
    "\n",
    "            #Onde, P+(e) é a fração de casos positivos identificados pelo comitê (|CASOS_POSITIVOS|/|COMITÊ|).\n",
    "            \n",
    "            pc_aa['entropia'] = -(pc_aa['qtdAlg']/nAlg * np.log(pc_aa['qtdAlg']/nAlg) + ((nAlg - pc_aa['qtdAlg'])/nAlg) * np.log((nAlg - pc_aa['qtdAlg'])/nAlg))\n",
    "\n",
    "            # pc_aa = pc.loc[:, :'med' ]\n",
    "            # pc_vetor = pc.loc[:, 'med': ] #Como referenciar a coluna vizinha à 'med'?\n",
    "\n",
    "            duplicata = pc_aa.loc[:, 'duplicata' ]\n",
    "\n",
    "            #Adicionando a coluna de duplicatas a pc_vetores\n",
    "            pc_vetores = pd.concat([duplicata, pc_vetores], axis=1, ignore_index=False)\n",
    "\n",
    "            ###### \n",
    "\n",
    "            #Separação do conjunto de pares conflitantes em dois a partir da quantidade de algoritmos \n",
    "            #que aponta o par como possível duplicata \n",
    "            #(conjunto A com quantidade de algoritmos = 1, com maioria composta por possíveis não-duplicatas,\n",
    "            #e conjunto B com quantidade de algoritmos > 1, contendo mais possíveis duplicatas que o conjunto A)\n",
    "#             ndup = pc_aa.loc[pc['qtdAlg'] <= qtd_alg_nd]\n",
    "#             dup = pc_aa.loc[(pc['qtdAlg'] > qtd_alg_nd) & (pc['qtdAlg'] <= (qtd_alg - qtd_alg_nd - 1))]\n",
    "            # dup = dup[pc['qtdAlg'] <= (qtd_alg - qtd_alg_nd)]\n",
    "            \n",
    "            ###### Ordenamento dos pares pela estatística selecionada\n",
    "#             ndup = ndup.sort_values(estat_ord) \n",
    "#             dup = dup.sort_values(estat_ord, ascending=False)\n",
    "            \n",
    "            #O que for considerado prováveis pares óbvios, tanto positivos quanto negativos, \n",
    "            #não serão considerados para a geração do conjunto de treino\n",
    "            pc_aa = pc_aa.loc[(pc['qtdAlg'] > qtd_alg_nd) & (pc['qtdAlg'] <= (qtd_alg - qtd_alg_nd - 1))]\n",
    "            pc_aa = pc_aa.sort_values(estat_ord) \n",
    "\n",
    "            ###### Variáveis para verificar se pode deslizar a janela dentro de dup (ou ndup)\n",
    "\n",
    "            deslz = len(pc_aa)/k #ALTERAÇÃO AQUI\n",
    "            deslz\n",
    "            \n",
    "#             deslz_dup = len(dup)/k\n",
    "#             deslz_dup\n",
    "\n",
    "#             deslz_ndup = len(ndup)/k\n",
    "#             deslz_ndup\n",
    "\n",
    "            ###### Validação do tamanho para deslizamento\n",
    "\n",
    "            #Se não houver espaço suficiente para deslizar as janelas\n",
    "#             if (deslz_dup < tam_min_ct/2) | (deslz_ndup < tam_min_ct/2):\n",
    "            if (deslz < tam_min_ct):\n",
    "                pode_passar = False\n",
    "                print(\"Arquivo: {0} não passou!\".format(arq))\n",
    "                nao_passaram += 1\n",
    "            else:\n",
    "                pode_passar = True\n",
    "\n",
    "            ###### Criação do dataframe que armazenará o conjunto de treinamento\n",
    "\n",
    "            conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "            ###### Povoamento inicial sem aleatoriedade no except\n",
    "\n",
    "            import sys\n",
    "\n",
    "            orcamento = 100\n",
    "            conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "            continua = True\n",
    "            f1_anterior = 0\n",
    "            f1_atual = 0\n",
    "            f1_svm = 0\n",
    "            f1_dt = 0\n",
    "\n",
    "            jan_inic_ndup = 0 \n",
    "            jan_fin_ndup = k\n",
    "\n",
    "            jan_inic_dup = 0 \n",
    "            jan_fin_dup = k\n",
    "\n",
    "            cont = 0\n",
    "\n",
    "            entrouExcept = False\n",
    "\n",
    "            continua = True\n",
    "            \n",
    "            if(pode_passar):\n",
    "\n",
    "#             else: #Se não pode passar!\n",
    "\n",
    "#                 print('ENTROU NO ELSE POR NÃO PASSAR')\n",
    "\n",
    "                jan_inic_dup = 0 \n",
    "                jan_fin_dup = k\n",
    "\n",
    "                jan_inic_ndup = len(pc_aa) - 1 #Fim de pc_aa\n",
    "                jan_fin_ndup = len(pc_aa) - k\n",
    "\n",
    "\n",
    "                #se a janela final de ndup for menor que a janela final de dup para\n",
    "\n",
    "                #Povoamento inicial com 20 pares rotulados (10 de cada)\n",
    "                while (cont < tam_min_ct) & (continua) & (jan_fin_dup < jan_fin_ndup):\n",
    "\n",
    "    #                 print(\"cont < 20: {0} - continua: {1}\".format(cont < tam_min_ct, continua))\n",
    "\n",
    "    #                 print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_dup, jan_fin_ndup))\n",
    "\n",
    "                    #Desliza-se a janela\n",
    "                    reexecuta = True\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "    #                 print(\"reexecuta: {0} - deslz_ndup >= 1: {1}\".format(reexecuta, deslz_ndup >= 1))\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "    #                     grupo = pc_aa.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "                        grupo = pc_aa.iloc[jan_fin_ndup:jan_inic_ndup] # three rows of dataframe\n",
    "\n",
    "                        #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                        #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            print(grupo)\n",
    "                            jan_inic_ndup = jan_inic_ndup - k\n",
    "                            jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "                            print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível não-duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                    #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "                        grupo = pc_aa.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            print(grupo)\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "                            print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    #Atualização das janelas\n",
    "                    jan_inic_ndup = jan_inic_ndup - k\n",
    "                    jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                    jan_inic_dup = jan_inic_dup + k\n",
    "                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                    if(deslz < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                        continua = False\n",
    "\n",
    "\n",
    "                    cont += 1\n",
    "                \n",
    "                #FIM DO WHILE DO CONT\n",
    "\n",
    "\n",
    "                #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                f1_svm, std_svm, cv_svm = geraF1(conj_treino, 'SVM')\n",
    "                f1_dt, std_dt, cv_dt = geraF1(conj_treino, 'DT')\n",
    "\n",
    "                f1_atual = (f1_svm + f1_dt)/2\n",
    "                std_atual = (std_svm + std_dt)/2\n",
    "                cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                ###### Aplicação das janelas deslizantes após o povoamento incial sem aleatoriedade no except\n",
    "\n",
    "\n",
    "\n",
    "                # continua = True\n",
    "                max_local = 0\n",
    "                igual = 0\n",
    "\n",
    "    #             print(\"Início\")\n",
    "    #             print(\"orcamento: {0}\".format(orcamento))\n",
    "    #             print(\"Quantidade de itens no conjunto de treinamento: {}\".format(len(conj_treino)))\n",
    "\n",
    "                while continua:\n",
    "\n",
    "                    f1_anterior = f1_atual\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "                        grupo = pc_aa.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "                        #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                        #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_ndup = jan_inic_ndup - k\n",
    "                            jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível não-duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                    #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "                        grupo = pc_aa.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                    f1_svm, std_svm, cv_svm = geraF1(conj_treino, 'SVM')\n",
    "                    f1_dt, std_dt, cv_dt = geraF1(conj_treino, 'DT')\n",
    "\n",
    "                    f1_atual = (f1_svm + f1_dt)/2\n",
    "                    std_atual = (std_svm + std_dt)/2\n",
    "                    cv_atual = (cv_svm + cv_dt)/2 #Coeficiente de variação\n",
    "\n",
    "                    cv_atual = cv_atual*100\n",
    "\n",
    "\n",
    "                    if orcamento > 0 : #Se ainda tem orçamento pra gastar\n",
    "                        if cv_atual < 10:\n",
    "                            if (f1_atual >= f1_anterior) and (igual <= 3): #Selecionam-se novos pares para rotulação\n",
    "\n",
    "                                if f1_atual == f1_anterior:\n",
    "                                    igual += 1\n",
    "                                elif (f1_atual > f1_anterior) and (igual > 0):\n",
    "                                    igual = 0\n",
    "\n",
    "                                continua = True\n",
    "                            elif (f1_atual < f1_anterior):\n",
    "                                max_local += 1\n",
    "                                #Se entrar aqui tem que remover os últimos pares que entraram no conjunto de treinamento\n",
    "\n",
    "                                #IMPORTANTE! Fazer com que esses devem sejam extraídos para o conjunto PM, não apenas descartados\n",
    "                                conj_treino.drop(conj_treino.tail(2).index,inplace=True)\n",
    "\n",
    "    #                             print(\"f1_atual < f1_anterior\")\n",
    "    #                             print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "\n",
    "                                if (max_local <= 1):\n",
    "                                    f1_atual = f1_anterior\n",
    "                                else:\n",
    "                                    f1_atual = f1_anterior\n",
    "    #                                 print('O f1 passou a piorar')\n",
    "    #                                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "                                    continua = False\n",
    "                                    break\n",
    "                            elif (igual > 3): #Se a medida de qualidade for igual à anterior (por três vezes)\n",
    "    #                                 print('F1 convergiu!') \n",
    "                                    continua = False\n",
    "                                    break\n",
    "\n",
    "                    else:\n",
    "                        continua = False\n",
    "                        break\n",
    "\n",
    "                    #Atualização das janelas\n",
    "                    jan_inic_ndup = jan_inic_ndup - k\n",
    "                    jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                    jan_inic_dup = jan_inic_dup + k\n",
    "                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                    if(deslz < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                        continua = False\n",
    "\n",
    "    #                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "    #                 print(\"igual: {0}\".format(igual))\n",
    "\n",
    "                ##### Salvando os arquivos de treino e teste\n",
    "\n",
    "#                 dirDest = \"../../csv/conjuntosDS/treinoTeste/\"\n",
    "                #FIM DO WHILE\n",
    "    \n",
    "                abordagem = 'DS'\n",
    "\n",
    "                iteracao = 1\n",
    "                inspecoesManuais = orcamento_orig - orcamento\n",
    "\n",
    "                duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "                duplicatas = duplicatas.count(True)\n",
    "\n",
    "                nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "                nao_duplicatas = nao_duplicatas.count(False)\n",
    "\n",
    "                da = linhaAtual['da'].item()\n",
    "                dm = duplicatas\n",
    "                ndm = nao_duplicatas\n",
    "\n",
    "                tp = float(linhaAtual['tp'].item() + dm)\n",
    "                fp = float(linhaAtual['fp'].item())\n",
    "                tn = float(linhaAtual['tn'].item())# + ndm) #Retirado\n",
    "                fn = float(linhaAtual['fn'].item() - dm) #Adicionado\n",
    "\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "                #Adicionando valor à última linha\n",
    "                estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                   'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                   'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais,\n",
    "                   precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "\n",
    "                dirDest = \"../../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\"\n",
    "        #         dirDest = \"../../Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/conjuntosDS/treinoTeste/\"\n",
    "        #         dirDest = \"./arqResult/csv/conjuntosDS/conjuntosDiverg/treinoTeste/\"\n",
    "\n",
    "                #algUtl = str(algUtl).replace('.0','')\n",
    "                algUtl = str(algUtl)\n",
    "\n",
    "                geraTrainSet(conj_treino, dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "                indicesCT = conj_treino.index.values.tolist()\n",
    "\n",
    "                geral = pd.concat([pc_vetores,conj_treino]) #Concatenando pc_vetores e conj_treino\n",
    "\n",
    "                #Resta para compor o conjunto teste tudo aquilo que está em pc_vetores, mas não em conj_treino\n",
    "                conj_teste = geral.drop(indicesCT, axis='rows') \n",
    "\n",
    "                geraTestSet(conj_teste, dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############################################################################################################################\n",
    "    #Estatísticas\n",
    "    ############################################################################################################################\n",
    "\n",
    "    # if (pode_passar):\n",
    "\n",
    "    #Para voltar o dataframe ao normal\n",
    "    estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'etapa', 'permutacao'])\n",
    "\n",
    "    estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "    dirEst = \"../../csv/\"\n",
    "\n",
    "    # Diretório para Windows\n",
    "    # dirEst = \"C:\\Users\\Diego\\Documents\\NetBeansProjects\\Master-SKYAM\\AS\\src\\csv\\\\\"\n",
    "    # dirEst = \"../../Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/\"\n",
    "\n",
    "\n",
    "    # Diretório para Linux\n",
    "    # dirEst = \"./arqResult/csv/\"\n",
    "\n",
    "    estatisticas.to_csv(dirEst+'estatisticaInicialDS2-DgArj-k'+str(k)+'.csv', sep=';', index=False)   \n",
    "\n",
    "    if(iteracoes >= 3000):\n",
    "\n",
    "        print(\"Não passaram: {0}\".format(nao_passaram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
