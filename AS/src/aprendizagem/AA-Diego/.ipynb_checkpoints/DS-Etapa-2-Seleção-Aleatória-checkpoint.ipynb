{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Desconsiderando os registros que possuam grande concordância ou pouquíssima concordância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção aleatória de conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base atual: cd\n",
      "QP atual: qp2b\n",
      "Orçamento atual: 50 \n",
      "['diverg(5)10_NEW.csv', 'diverg(5)1_NEW.csv', 'diverg(5)2_NEW.csv', 'diverg(5)3_NEW.csv', 'diverg(5)4_NEW.csv', 'diverg(5)5_NEW.csv', 'diverg(5)6_NEW.csv', 'diverg(5)7_NEW.csv', 'diverg(5)8_NEW.csv', 'diverg(5)9_NEW.csv']\n",
      "diverg(5)10_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)10_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 10\n",
      "diverg(5)1_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)1_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 1\n",
      "diverg(5)2_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)2_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 2\n",
      "diverg(5)3_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)3_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 3\n",
      "diverg(5)4_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)4_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 4\n",
      "diverg(5)5_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)5_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 5\n",
      "diverg(5)6_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)6_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 6\n",
      "diverg(5)7_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)7_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 7\n",
      "diverg(5)8_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)8_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 8\n",
      "diverg(5)9_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)9_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 9\n",
      "Orçamento atual: 100 \n",
      "['diverg(5)10_NEW.csv', 'diverg(5)1_NEW.csv', 'diverg(5)2_NEW.csv', 'diverg(5)3_NEW.csv', 'diverg(5)4_NEW.csv', 'diverg(5)5_NEW.csv', 'diverg(5)6_NEW.csv', 'diverg(5)7_NEW.csv', 'diverg(5)8_NEW.csv', 'diverg(5)9_NEW.csv']\n",
      "diverg(5)10_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)10_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 10\n",
      "diverg(5)1_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)1_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 1\n",
      "diverg(5)2_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)2_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6f3f88741a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m                     \u001b[1;31m#             conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                     \u001b[0mconj_treino\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpc_vetores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morcamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     \u001b[0miteracao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                              \"provide positive value.\")\n\u001b[0;32m   2899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "import os, errno\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# nao_passaram = 0\n",
    "# iteracoes = 0\n",
    "\n",
    "############################################################################################################################\n",
    "#Definição de funções\n",
    "############################################################################################################################\n",
    "\n",
    "#Função para geração do conjunto de treinamento\n",
    "def geraTrainSet(ct, dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "        \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)     \n",
    "    \n",
    "#Função para geração do conjunto de teste\n",
    "def geraTestSet(ct, dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)\n",
    "    \n",
    "    \n",
    "############################\n",
    "\n",
    "#Parâmetros do usuário (Definir entrada dos dados)\n",
    "estat_ord = 'med' #Estatística para ordenamento\n",
    "#qtd_alg = 23 #Quantidade total de algoritmos (Modificado para ser atualizado em cada iteração de acordo com a quantidade máxima de algoritmos em cada experimento)\n",
    "qtd_alg_nd = 2 #Quantidade máxima de algoritmos para separar o conjunto de possíves não-duplicadas\n",
    "# k = 3 #Tamanho da janela\n",
    "# janelas = [2,3,4,5]\n",
    "# janelas = [3] \n",
    "# janelas = [1, 0.01, 0.03, 0.05] # K = {1, 1%, 3%, 5%}\n",
    "janelas = [0.01] #Quando houver a janela vencedora. Após testar as combinações acima\n",
    " #com todas as bases. Lembrando que só deve ser usada para as demais QP além e QP6\n",
    "orcamentos = [50, 100, 150, 200]\n",
    "tam_min_ct = 20\n",
    "seed = 500\n",
    "# nAlg = 23\n",
    "\n",
    "etapa = '2 - AA[random]'\n",
    "\n",
    "bases = [\"cd\"]\n",
    "qps = [\"qp4\"] #Apenas qp4, na verdade\n",
    "\n",
    "for base in bases:\n",
    "    \n",
    "    print(\"Base atual: {0}\".format(base))\n",
    "    \n",
    "    for qp in qps:\n",
    "        \n",
    "        print(\"QP atual: {0}\".format(qp))\n",
    "\n",
    "\n",
    "        dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAA/\"+base+\"/\"+qp+\"/\"\n",
    "        dirEstat = \"../../csv/estatisticas/\"+base+\"/\"+qp+\"/\"\n",
    "        estat = dirEstat+\"estatisticaDS.csv\"\n",
    "\n",
    "        for orcamento in orcamentos:\n",
    "\n",
    "            dirDest = \"../../csv/conjuntosDS/treinoTeste/\"+base+\"/\"+qp+\"/\"+\"Random-\"+str(orcamento)+\"/\"\n",
    "\n",
    "            print(\"Orçamento atual: {0} \".format(orcamento))\n",
    "\n",
    "            nao_passaram = 0\n",
    "            iteracoes = 0\n",
    "\n",
    "            estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados', 'etapa', 'permutacao'], sep=';')\n",
    "\n",
    "            ###### Criação do dataframe que armazenará as estatísticas dos conjuntos de treino e teste\n",
    "            #   estat_conj = pd.DataFrame (index=['algUtl', 'permutacao'], columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "            estat_conj = pd.DataFrame (columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "\n",
    "\n",
    "            arquivos = [] #Adicionado depois\n",
    "\n",
    "            for _, _, arquivo in os.walk(dirOrig):\n",
    "                arquivos.extend(arquivo)   \n",
    "                \n",
    "            print(arquivos)\n",
    "\n",
    "            for arq in arquivos:\n",
    "                \n",
    "                print(arq)\n",
    "\n",
    "                if ('_NEW' in arq):# & (iteracoes <= 50):\n",
    "#                 if ('diverg(10)1_NEW' in arq): # & (iteracoes <= 0): #Aqui, Diego!\n",
    "#                 if (True): # & (iteracoes <= 0): #Aqui, Diego!\n",
    "                    #         if ('diverg(10)18_NEW' in arq) & (iteracoes <= 0):\n",
    "                    #         if ('diverg(10)18_NEW' in arq) | ('diverg(10)15_NEW' in arq) & (iteracoes <= 1):\n",
    "                    print(\"##################################################################\")\n",
    "                    print(\"Analisando o arquivo: {0}\".format(arq))\n",
    "                    print(\"##################################################################\")\n",
    "\n",
    "                    iteracoes += 1\n",
    "\n",
    "                    num = re.sub(r'diverg.*\\)', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    num = num.replace('_NEW.csv','')\n",
    "\n",
    "                    algUtl = re.sub(r'diverg.*\\(', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    algUtl = re.sub(r'\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    algUtl = int(algUtl)\n",
    "\n",
    "                    permutacao = int(num)\n",
    "                    print(\"permutacao: {0}\".format(permutacao))\n",
    "\n",
    "                    linhaAtual = estatisticas.xs((algUtl, '1 - acm diverg', permutacao))    \n",
    "\n",
    "                    ###### Leitura do conjunto de pares conflitantes\n",
    "                    pc = dirOrig+arq\n",
    "                    \n",
    "#                     print(pc)\n",
    "\n",
    "                    pc = pd.read_csv(pc, sep=';', index_col=['elemento1', 'elemento2']) #pares conflitantes\n",
    "\n",
    "                    cols = list(pc.columns.values)\n",
    "                    cols.pop(cols.index('duplicata'))\n",
    "                    pc = pc[['duplicata']+cols]\n",
    "\n",
    "                    pc_aa = pc.iloc[:, :5 ] #Conjunto onde serão aplicadas as janelas deslizantes\n",
    "                    pc_vetores = pc.iloc[:, 5: ] #Conjunto base para compor o conjunto treinamento \n",
    "\n",
    "                    duplicata = pc_aa.loc[:, 'duplicata' ]\n",
    "\n",
    "                    #Adicionando a coluna de duplicatas a pc_vetores\n",
    "                    pc_vetores = pd.concat([duplicata, pc_vetores], axis=1, ignore_index=False)\n",
    "\n",
    "                    #             conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "                    conj_treino = pc_vetores.sample(orcamento, random_state=500)\n",
    "\n",
    "                    iteracao = 1\n",
    "                    inspecoesManuais = orcamento\n",
    "\n",
    "                    duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "                    duplicatas = duplicatas.count(True)\n",
    "                    percentDup = float(duplicatas/float(len(conj_treino))*100)\n",
    "                    percentDup = float(\"{0:.2f}\".format(percentDup))\n",
    "        #             print(\"{0}% de duplicatas.\".format(str(percentage)[:5]))\n",
    "\n",
    "                    nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "                    nao_duplicatas = nao_duplicatas.count(False)\n",
    "                    percentNaoDup = float(nao_duplicatas/float(len(conj_treino))*100)\n",
    "                    percentNaoDup = float(\"{0:.2f}\".format(percentNaoDup))\n",
    "\n",
    "                    abordagem = 'DS'\n",
    "\n",
    "                    da = linhaAtual['da'].item()\n",
    "                    dm = duplicatas\n",
    "                    ndm = nao_duplicatas\n",
    "\n",
    "                    tp = float(linhaAtual['tp'].item() + dm)\n",
    "                    fp = float(linhaAtual['fp'].item())\n",
    "                    tn = float(linhaAtual['tn'].item())# + ndm) #Retirado\n",
    "                    fn = float(linhaAtual['fn'].item() - dm) #Adicionado\n",
    "\n",
    "                    precision = tp/(tp+fp)\n",
    "                    recall = tp/(tp+fn)\n",
    "                    fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "                        #Adicionando valor à última linha\n",
    "                    estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                        'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                        'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais, precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "                        #algUtl = str(algUtl).replace('.0','')\n",
    "                    algUtl = str(algUtl)\n",
    "\n",
    "                    geraTrainSet(conj_treino, dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "                    #Resta para compor o conjunto teste tudo aquilo que está em pc_vetores, mas não em conj_treino\n",
    "                    conj_teste = pc_vetores.loc[pc_vetores.index.difference(conj_treino.index)]\n",
    "                    geraTestSet(conj_teste, dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "                    estat_conj.loc[len(estat_conj.index)] = [algUtl, permutacao, len(conj_treino), percentDup, percentNaoDup, len(conj_teste)]\n",
    "\n",
    "\n",
    "            ############################################################################################################################\n",
    "            #Estatísticas\n",
    "            ############################################################################################################################\n",
    "            #Para voltar o dataframe ao normal\n",
    "            estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'etapa', 'permutacao'])\n",
    "\n",
    "            estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "            estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "            estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "            estatisticas.to_csv(dirEstat+'estatisticaDS2-Random'+str(orcamento)+'.csv', sep=';', index=False)   \n",
    "\n",
    "            estat_conj.to_csv(dirEstat+'estatisticasConjuntos-Random'+str(orcamento)+'.csv', sep=';', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
