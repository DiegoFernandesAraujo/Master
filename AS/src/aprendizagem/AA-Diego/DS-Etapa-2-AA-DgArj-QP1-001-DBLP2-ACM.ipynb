{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QP1 - Janela 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Desconsiderando os registros que possuam grande concordância ou pouquíssima concordância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tamanho das janelas modificado pela porcentagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificada a ordenação de dup e ndup a fim de fazer com que as janelas deslizem a partir do meio do conjunto todo e assim pegar pares da região de incerteza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orçamento = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficiente de variação <= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lançando mão da entropia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando manter o conjunto de treinamento balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base atual: restaurant\n",
      "QP atual: qp1\n",
      "../../csv/estatisticas/restaurant/qp1/log-001.txt\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(15)1_NEW.csv\n",
      "##################################################################\n",
      "pc: ../../csv/conjuntosDS/conjuntosDivergAA/restaurant/qp1/diverg(15)1_NEW.csv\n",
      "pc.columns.values\n",
      "['duplicata' 'qtdAlg' 'min' 'max' 'med' 'name' 'addr' 'city' 'phone' 'type']\n",
      "pc_aa.columns.values\n",
      "['duplicata' 'qtdAlg' 'min' 'max' 'med']\n",
      "pc_vetores.columns.values\n",
      "['name' 'addr' 'city' 'phone' 'type']\n",
      "pc_vetores.columns.values\n",
      "['duplicata' 'name' 'addr' 'city' 'phone' 'type']\n",
      "---At the beginning---\n",
      "len(dup): 99 - len(ndup): 480\n",
      "k: 0.01 --> k_dup: 1 - k_ndup: 5\n",
      "deslz_dup: 99.0 - deslz_ndup: 96.0\n",
      "deslz_dup na geração do conjunto inicial: 98.0\n",
      "deslz_dup na geração do conjunto inicial: 97.0\n",
      "deslz_dup na geração do conjunto inicial: 96.0\n",
      "deslz_dup na geração do conjunto inicial: 95.0\n",
      "deslz_dup na geração do conjunto inicial: 94.0\n",
      "deslz_dup na geração do conjunto inicial: 93.0\n",
      "Diferença entre as porcentagens: 33.34\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 33.33 <= percentNaoDup: 66.67\n",
      "deslz_dup na geração do conjunto inicial: 92.0\n",
      "Diferença entre as porcentagens: 38.46000000000001\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 30.77 <= percentNaoDup: 69.23\n",
      "deslz_dup na geração do conjunto inicial: 91.0\n",
      "Diferença entre as porcentagens: 42.86000000000001\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 28.57 <= percentNaoDup: 71.43\n",
      "deslz_dup na geração do conjunto inicial: 90.0\n",
      "Diferença entre as porcentagens: 46.66\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 26.67 <= percentNaoDup: 73.33\n",
      "deslz_dup na geração do conjunto inicial: 89.0\n",
      "Diferença entre as porcentagens: 50.0\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 25.0 <= percentNaoDup: 75.0\n",
      "deslz_dup na geração do conjunto inicial: 88.0\n",
      "Diferença entre as porcentagens: 55.56\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 22.22 <= percentNaoDup: 77.78\n",
      "deslz_dup na geração do conjunto inicial: 87.0\n",
      "Diferença entre as porcentagens: 60.0\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 20.0 <= percentNaoDup: 80.0\n",
      "deslz_dup na geração do conjunto inicial: 86.0\n",
      "Diferença entre as porcentagens: 63.63999999999999\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 18.18 <= percentNaoDup: 81.82\n",
      "deslz_dup na geração do conjunto inicial: 85.0\n",
      "Diferença entre as porcentagens: 58.34\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 20.83 <= percentNaoDup: 79.17\n",
      "deslz_dup na geração do restante do conjunto: 84.0\n",
      "deslz_dup na geração do restante do conjunto: 83.0\n",
      "deslz_dup na geração do restante do conjunto: 82.0\n",
      "deslz_dup na geração do restante do conjunto: 81.0\n",
      "deslz_dup na geração do restante do conjunto: 80.0\n",
      "deslz_dup na geração do restante do conjunto: 79.0\n",
      "deslz_dup na geração do restante do conjunto: 78.0\n",
      "deslz_dup na geração do restante do conjunto: 77.0\n",
      "deslz_dup na geração do restante do conjunto: 76.0\n",
      "deslz_dup na geração do restante do conjunto: 75.0\n",
      "deslz_dup na geração do restante do conjunto: 74.0\n",
      "deslz_dup na geração do restante do conjunto: 73.0\n",
      "deslz_dup na geração do restante do conjunto: 72.0\n",
      "deslz_dup na geração do restante do conjunto: 71.0\n",
      "deslz_dup na geração do restante do conjunto: 70.0\n",
      "deslz_dup na geração do restante do conjunto: 69.0\n",
      "deslz_dup na geração do restante do conjunto: 68.0\n",
      "deslz_dup na geração do restante do conjunto: 67.0\n",
      "deslz_dup na geração do restante do conjunto: 66.0\n",
      "deslz_dup na geração do restante do conjunto: 65.0\n",
      "deslz_dup na geração do restante do conjunto: 64.0\n",
      "deslz_dup na geração do restante do conjunto: 63.0\n",
      "deslz_dup na geração do restante do conjunto: 62.0\n",
      "deslz_dup na geração do restante do conjunto: 61.0\n",
      "deslz_dup na geração do restante do conjunto: 60.0\n",
      "deslz_dup na geração do restante do conjunto: 59.0\n",
      "deslz_dup na geração do restante do conjunto: 58.0\n",
      "deslz_dup na geração do restante do conjunto: 57.0\n",
      "deslz_dup na geração do restante do conjunto: 56.0\n",
      "deslz_dup na geração do restante do conjunto: 55.0\n",
      "deslz_dup na geração do restante do conjunto: 54.0\n",
      "deslz_dup na geração do restante do conjunto: 53.0\n",
      "deslz_dup na geração do restante do conjunto: 52.0\n",
      "deslz_dup na geração do restante do conjunto: 51.0\n",
      "deslz_dup na geração do restante do conjunto: 50.0\n",
      "deslz_dup na geração do restante do conjunto: 49.0\n",
      "deslz_dup na geração do restante do conjunto: 48.0\n",
      "deslz_dup na geração do restante do conjunto: 47.0\n",
      "deslz_dup na geração do restante do conjunto: 46.0\n",
      "deslz_dup na geração do restante do conjunto: 45.0\n",
      "deslz_dup na geração do restante do conjunto: 44.0\n",
      "deslz_dup na geração do restante do conjunto: 43.0\n",
      "deslz_dup na geração do restante do conjunto: 42.0\n",
      "deslz_dup na geração do restante do conjunto: 41.0\n",
      "deslz_dup na geração do restante do conjunto: 40.0\n",
      "deslz_dup na geração do restante do conjunto: 39.0\n",
      "deslz_dup na geração do restante do conjunto: 38.0\n",
      "deslz_dup na geração do restante do conjunto: 37.0\n",
      "deslz_dup na geração do restante do conjunto: 36.0\n",
      "deslz_dup na geração do restante do conjunto: 35.0\n",
      "deslz_dup na geração do restante do conjunto: 34.0\n",
      "deslz_dup na geração do restante do conjunto: 33.0\n",
      "deslz_dup na geração do restante do conjunto: 32.0\n",
      "deslz_dup na geração do restante do conjunto: 31.0\n",
      "deslz_dup na geração do restante do conjunto: 30.0\n",
      "deslz_dup na geração do restante do conjunto: 29.0\n",
      "deslz_dup na geração do restante do conjunto: 28.0\n",
      "deslz_dup em sel_vetor 2: 27.0\n",
      "deslz_dup na geração do restante do conjunto: 26.0\n",
      "deslz_dup na geração do restante do conjunto: 25.0\n",
      "deslz_dup na geração do restante do conjunto: 24.0\n",
      "deslz_dup na geração do restante do conjunto: 23.0\n",
      "deslz_dup na geração do restante do conjunto: 22.0\n",
      "deslz_dup na geração do restante do conjunto: 21.0\n",
      "deslz_dup na geração do restante do conjunto: 20.0\n",
      "deslz_dup na geração do restante do conjunto: 19.0\n",
      "deslz_dup em sel_vetor 2: 18.0\n",
      "deslz_dup na geração do restante do conjunto: 17.0\n",
      "deslz_dup na geração do restante do conjunto: 16.0\n",
      "deslz_dup na geração do restante do conjunto: 15.0\n",
      "deslz_dup na geração do restante do conjunto: 14.0\n",
      "deslz_dup na geração do restante do conjunto: 13.0\n",
      "deslz_dup na geração do restante do conjunto: 12.0\n",
      "deslz_dup na geração do restante do conjunto: 11.0\n",
      "deslz_dup na geração do restante do conjunto: 10.0\n",
      "deslz_dup na geração do restante do conjunto: 9.0\n",
      "deslz_dup na geração do restante do conjunto: 8.0\n",
      "deslz_dup na geração do restante do conjunto: 7.0\n",
      "deslz_dup na geração do restante do conjunto: 6.0\n",
      "deslz_dup na geração do restante do conjunto: 5.0\n",
      "deslz_dup na geração do restante do conjunto: 4.0\n",
      "deslz_dup na geração do restante do conjunto: 3.0\n",
      "deslz_dup na geração do restante do conjunto: 2.0\n",
      "deslz_dup na geração do restante do conjunto: 1.0\n",
      "---At the end---\n",
      "deslz_dup: 1.0 - deslz_ndup: 0.0\n",
      "Tamanho do conjunto de treinamento: 102\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(15)2_NEW.csv\n",
      "##################################################################\n",
      "pc: ../../csv/conjuntosDS/conjuntosDivergAA/restaurant/qp1/diverg(15)2_NEW.csv\n",
      "pc.columns.values\n",
      "['duplicata' 'qtdAlg' 'min' 'max' 'med' 'name' 'addr' 'city' 'phone' 'type']\n",
      "pc_aa.columns.values\n",
      "['duplicata' 'qtdAlg' 'min' 'max' 'med']\n",
      "pc_vetores.columns.values\n",
      "['name' 'addr' 'city' 'phone' 'type']\n",
      "pc_vetores.columns.values\n",
      "['duplicata' 'name' 'addr' 'city' 'phone' 'type']\n",
      "---At the beginning---\n",
      "len(dup): 90 - len(ndup): 142\n",
      "k: 0.01 --> k_dup: 1 - k_ndup: 1\n",
      "deslz_dup: 90.0 - deslz_ndup: 142.0\n",
      "deslz_dup na geração do conjunto inicial: 89.0\n",
      "deslz_dup na geração do conjunto inicial: 88.0\n",
      "deslz_dup na geração do conjunto inicial: 87.0\n",
      "deslz_dup na geração do conjunto inicial: 86.0\n",
      "deslz_dup na geração do conjunto inicial: 85.0\n",
      "deslz_dup na geração do conjunto inicial: 84.0\n",
      "deslz_dup na geração do conjunto inicial: 83.0\n",
      "deslz_dup na geração do conjunto inicial: 82.0\n",
      "deslz_dup na geração do conjunto inicial: 81.0\n",
      "Diferença entre as porcentagens: 33.34\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 33.33 <= percentNaoDup: 66.67\n",
      "deslz_dup na geração do conjunto inicial: 80.0\n",
      "Diferença entre as porcentagens: 36.84\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 31.58 <= percentNaoDup: 68.42\n",
      "deslz_dup na geração do conjunto inicial: 79.0\n",
      "Diferença entre as porcentagens: 42.86000000000001\n",
      "percentDup <= percentNaoDup\n",
      "percentDup: 28.57 <= percentNaoDup: 71.43\n",
      "deslz_dup na geração do restante do conjunto: 78.0\n",
      "deslz_dup na geração do restante do conjunto: 77.0\n",
      "deslz_dup na geração do restante do conjunto: 76.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deslz_dup na geração do restante do conjunto: 75.0\n",
      "deslz_dup na geração do restante do conjunto: 74.0\n",
      "deslz_dup na geração do restante do conjunto: 73.0\n",
      "deslz_dup na geração do restante do conjunto: 72.0\n",
      "deslz_dup na geração do restante do conjunto: 71.0\n",
      "deslz_dup na geração do restante do conjunto: 70.0\n",
      "deslz_dup na geração do restante do conjunto: 69.0\n",
      "deslz_dup na geração do restante do conjunto: 68.0\n",
      "deslz_dup na geração do restante do conjunto: 67.0\n",
      "deslz_dup na geração do restante do conjunto: 66.0\n",
      "deslz_dup na geração do restante do conjunto: 65.0\n",
      "deslz_dup na geração do restante do conjunto: 64.0\n",
      "deslz_dup na geração do restante do conjunto: 63.0\n",
      "deslz_dup na geração do restante do conjunto: 62.0\n",
      "deslz_dup na geração do restante do conjunto: 61.0\n",
      "deslz_dup na geração do restante do conjunto: 60.0\n",
      "deslz_dup na geração do restante do conjunto: 59.0\n",
      "deslz_dup na geração do restante do conjunto: 58.0\n",
      "deslz_dup na geração do restante do conjunto: 57.0\n",
      "deslz_dup na geração do restante do conjunto: 56.0\n",
      "deslz_dup na geração do restante do conjunto: 55.0\n",
      "deslz_dup na geração do restante do conjunto: 54.0\n",
      "deslz_dup na geração do restante do conjunto: 53.0\n",
      "deslz_dup na geração do restante do conjunto: 52.0\n",
      "deslz_dup na geração do restante do conjunto: 51.0\n",
      "deslz_dup na geração do restante do conjunto: 50.0\n",
      "deslz_dup na geração do restante do conjunto: 49.0\n",
      "deslz_dup na geração do restante do conjunto: 48.0\n",
      "deslz_dup na geração do restante do conjunto: 47.0\n",
      "deslz_dup na geração do restante do conjunto: 46.0\n",
      "deslz_dup na geração do restante do conjunto: 45.0\n",
      "deslz_dup na geração do restante do conjunto: 44.0\n",
      "deslz_dup na geração do restante do conjunto: 43.0\n",
      "deslz_dup na geração do restante do conjunto: 42.0\n",
      "deslz_dup na geração do restante do conjunto: 41.0\n",
      "deslz_dup na geração do restante do conjunto: 40.0\n",
      "deslz_dup na geração do restante do conjunto: 39.0\n",
      "deslz_dup na geração do restante do conjunto: 38.0\n",
      "deslz_dup na geração do restante do conjunto: 37.0\n",
      "deslz_dup na geração do restante do conjunto: 36.0\n",
      "deslz_dup na geração do restante do conjunto: 35.0\n",
      "deslz_dup na geração do restante do conjunto: 34.0\n",
      "deslz_dup na geração do restante do conjunto: 33.0\n",
      "deslz_dup na geração do restante do conjunto: 32.0\n",
      "deslz_dup na geração do restante do conjunto: 31.0\n",
      "deslz_dup na geração do restante do conjunto: 30.0\n",
      "deslz_dup na geração do restante do conjunto: 29.0\n",
      "deslz_dup na geração do restante do conjunto: 28.0\n",
      "deslz_dup na geração do restante do conjunto: 27.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "import os, errno\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# nao_passaram = 0\n",
    "# iteracoes = 0\n",
    "\n",
    "############################################################################################################################\n",
    "#Definição de funções\n",
    "############################################################################################################################\n",
    "\n",
    "#Função para geração do conjunto de treinamento\n",
    "def geraTrainSet(ct, dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "        \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)     \n",
    "    \n",
    "#Função para geração do conjunto de teste\n",
    "def geraTestSet(ct, dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)            \n",
    "    \n",
    "\n",
    "#Função para verificar se o vetor já existe no conjunto de treinamento\n",
    "def comparaVetor(vetor):\n",
    "    achou = False\n",
    "\n",
    "    for index, row in conj_treino.iterrows():\n",
    "\n",
    "        if vetor.equals(row):\n",
    "            achou = True\n",
    "            break\n",
    "\n",
    "#     print('achou')\n",
    "#     print(achou)\n",
    "    \n",
    "    return achou\n",
    "\n",
    "#Função para verificar se uma dada parte do vetor (calculada por uma porcentagem)\n",
    "#já existe no conjunto de treinamento\n",
    "def comparaVetorPorc(vetor):\n",
    "    \n",
    "#     print('****************************')\n",
    "    \n",
    "#     print('vetor recebido:')\n",
    "#     print(vetor)\n",
    "    \n",
    "    achou = False\n",
    "\n",
    "    for index, row in conj_treino.iterrows():\n",
    "        \n",
    "        rowX = row[-1*(row.size-1) :] #Desconsiderando aqui a primeira coluna que contém o status do vetor\n",
    "        vetorX = vetor[-1*(vetor.size-1) :] #Desconsiderando aqui a primeira coluna que contém o status do vetor\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            vetor_bool = rowX == vetorX #Vetor booleano resultante da comparação do vetor de entrada\n",
    "                                  #e cada linha do conjunto de treinamento\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            print(\"except do comparaVetorPorc\")\n",
    "            \n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "            print(sys.exc_info())\n",
    "        \n",
    "        cols_iguais = [i for i in vetor_bool if i == True]\n",
    "        cols_iguais = cols_iguais.count(True) #Quantidade de colunas iguais\n",
    "\n",
    "        #Se a quantidade de colunas com valores iguais for maior ou igual à dada porcentagem,\n",
    "        #considera-se que o vetor passado é semelhante a algum já existente no conjunto treino\n",
    "        if (cols_iguais >= int(0.75*vetor_bool.size)):\n",
    "            achou = True\n",
    "            break\n",
    "        \n",
    "#     print('achou')\n",
    "#     print(achou)\n",
    "    \n",
    "#     if(not achou):\n",
    "        \n",
    "#         print('Vetor distinto dos demais:')\n",
    "#         print(vetorX)\n",
    "#         print('qtd de colunas iguais: {0} - 75% seriam: {1}'.format(cols_iguais), int(0.75*vetor_bool.size))\n",
    "    \n",
    "    return achou\n",
    "\n",
    "#Função para verificar a semelhança entre dois vetores dada a distância entre seus valores\n",
    "def comparaVetorDif(vetor):\n",
    "    \n",
    "#     print('****************************')\n",
    "    \n",
    "#     print('vetor recebido:')\n",
    "#     print(vetor)\n",
    "    \n",
    "    achou = False\n",
    "\n",
    "    for index, row in conj_treino.iterrows():\n",
    "        \n",
    "        rowX = row[-1*(row.size-1) :] #Desconsiderando aqui a primeira coluna que contém o status do vetor\n",
    "        vetorX = vetor[-1*(vetor.size-1) :] #Desconsiderando aqui a primeira coluna que contém o status do vetor\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            vetor_dif = abs(rowX - vetorX) #Vetor com a diferença entre os dois vetores comparados\n",
    "                                           # (o vetor de entrada e cada linha do conjunto de treinamento)\n",
    "        except:\n",
    "            \n",
    "            print(\"except do comparaVetorDif\")\n",
    "            \n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "            print(sys.exc_info())\n",
    "        \n",
    "#         print('$$$$$$$$$$$$$$$$$$$$$')\n",
    "#         print(\"vetor_dif\")\n",
    "#         print(vetor_dif)\n",
    "#         print('$$$$$$$$$$$$$$$$$$$$$')\n",
    "        \n",
    "        cols = [i for i in vetor_dif if i <= 0.1] #Se a diferença for menor ou igual a 0.1,\n",
    "                                                        #nesse exemplo, os vetores são considerados iguais\n",
    "        qtd_cols = len(cols) \n",
    "\n",
    "        #Se a quantidade de colunas com valores iguais for maior ou igual à dada porcentagem,\n",
    "        #considera-se que o vetor passado é semelhante a algum já existente no conjunto treino\n",
    "        if (qtd_cols >= int(0.90*vetor_dif.size)): #Nesse exemplo, apenas é considerado igual se for maior ou igual a 90%\n",
    "                                                    #de algum vetor já existente no conjunto de treinamento\n",
    "            achou = True\n",
    "            break\n",
    "#         else:\n",
    "#             \n",
    "#             print('$$$$$$$$$$$$$$$$$$$$$')\n",
    "#             print(\"vetor_dif\")\n",
    "#             print(vetor_dif)\n",
    "#             print('$$$$$$$$$$$$$$$$$$$$$')\n",
    "            \n",
    "#             print('cols')\n",
    "#             print(cols)\n",
    "            \n",
    "#             print('qtd_cols')\n",
    "#             print(qtd_cols)\n",
    "        \n",
    "#     print('achou')\n",
    "#     print(achou)\n",
    "    \n",
    "#     if(not achou):\n",
    "        \n",
    "#         print('Vetor distinto dos demais:')\n",
    "#         print(vetorX)\n",
    "#         print('qtd de colunas iguais: {0} - 75% seriam: {1}'.format(cols_iguais), int(0.75*vetor_bool.size))\n",
    "    \n",
    "    return achou\n",
    "\n",
    "#Função para...\n",
    "\n",
    "#grupo - conjunto de vetores de similaridade de tamanho k\n",
    "#col_comp - coluna do conjunto \"grupo\" a ser utilizada para comparação dos vetores deste\n",
    "#tipo_conj - define se o tratamento do vetor a ser selecionado para rotulação é para o conjunto de possíveis duplicatas ou não-duplicatas\n",
    "\n",
    "def sel_vet_rot(grupo, col_comp, tipo_conj, qm_chamou):\n",
    "    warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "    \n",
    "#     if(qm_chamou == 'rec'):\n",
    "#         print('A recursividade chamou')\n",
    "    \n",
    "#     print(qm_chamou)\n",
    "#     print(\"Entrando em sel_vet_rot\")\n",
    "    \n",
    "    global conj_treino, orcamento, reexecuta, deslz_dup, jan_inic_dup, jan_fin_dup, deslz_ndup, jan_inic_ndup, jan_fin_ndup, k_dup, k_ndup\n",
    "    \n",
    "#     print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "    \n",
    "#     print(\"Comprimento do grupo: {0}\".format(len(grupo)))\n",
    "    \n",
    "    \n",
    "    if len(grupo) > 0:\n",
    "\n",
    "        try:\n",
    "            \n",
    "            id_row_sel = grupo[col_comp].idxmax() #Retorna o índice da linha com maior valor da coluna ('entropia') especificada\n",
    "\n",
    "            #SÓ PASSA PRA CÁ SE NÃO LANÇAR EXCEPT\n",
    "\n",
    "            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final dacomposição do conjunto de treinamento)\n",
    "            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "#             print('vetor_sel')\n",
    "#             print(vetor_sel)\n",
    "\n",
    "            #Se o vetor já existir no conjunto de treino\n",
    "#             if comparaVetorDif(vetor_sel):\n",
    "            if comparaVetor(vetor_sel):\n",
    "#             if comparaVetorPorc(vetor_sel):\n",
    "                \n",
    "                grupo.drop([id_row_sel], axis = 'rows', inplace = True)#Retira do grupo o vetor anteriormente selecionado\n",
    "#                 print(\"grupo depois de dropado\")\n",
    "#                 print(grupo)\n",
    "                \n",
    "                sel_vet_rot(grupo, col_comp, tipo_conj, 'rec')\n",
    "           \n",
    "            #Senão, adiciona o vetor selecionado ao conjunto treino\t\n",
    "            else:\n",
    "                \n",
    "                conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                orcamento -= 1\n",
    "                reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                return reexecuta\n",
    "#                 print(\"conj_treino\")\n",
    "#                 print(conj_treino)\n",
    "\n",
    "        except ValueError:\n",
    "\n",
    "            print(\"Atualizando janelas no except\")\n",
    "#             exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "#             fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "#             print(exc_type, fname, exc_tb.tb_lineno)\n",
    "#             print(sys.exc_info())\n",
    "            \n",
    "            if tipo_conj == \"dup\":\n",
    "                \n",
    "#                 print(\"ValueError - tipo_conj == dup\")\n",
    "                \n",
    "                jan_inic_dup = jan_inic_dup + k_dup\n",
    "                jan_fin_dup = jan_fin_dup + k_dup\n",
    "\n",
    "                deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "                print(\"deslz_dup em sel_vetor: {0}\".format(deslz_dup))\n",
    "            \n",
    "            elif tipo_conj == \"ndup\":\n",
    "                \n",
    "#                 print(\"ValueError - tipo_conj == ndup\")\n",
    "                \n",
    "                jan_inic_ndup = jan_inic_ndup + k_ndup\n",
    "                jan_fin_ndup = jan_fin_ndup + k_ndup\n",
    "\n",
    "                deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "            reexecuta = True\n",
    "            return reexecuta\n",
    "            \n",
    "\n",
    "        except:\n",
    "\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "#             print(\"Eita!\")\n",
    "#             print(sys.exc_info())\n",
    "# #             print(grupo)\n",
    "            reexecuta = True\n",
    "            return reexecuta\n",
    "#             sys.exit(1)\n",
    "\n",
    "    #Caso em que todos os vetores já existiam no conj_treino\n",
    "    #Reexecuta (Desliza a janela e chama sel_vet_rot(----):)\n",
    "    else:\n",
    "\n",
    "#         print(\"Atualizando janelas depois de dropar todos os elementos do grupo\")de\n",
    "#         print(\"Quem chamou: {0}\".format(qm_chamou))\n",
    "        \n",
    "        if tipo_conj == \"dup\":\n",
    "                \n",
    "            jan_inic_dup = jan_inic_dup + k_dup\n",
    "            jan_fin_dup = jan_fin_dup + k_dup\n",
    "\n",
    "            deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "            print(\"deslz_dup em sel_vetor 2: {0}\".format(deslz_dup))\n",
    "            \n",
    "        elif tipo_conj == \"ndup\":\n",
    "                    \n",
    "            jan_inic_ndup = jan_inic_ndup + k_ndup\n",
    "            jan_fin_ndup = jan_fin_ndup + k_ndup\n",
    "\n",
    "            deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "#         print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "        reexecuta = True #Se não selecionou um registro no comando anterior, precisa reexecutar o while\n",
    "        return reexecuta\n",
    "        \n",
    "#     print(\"reexecuta\")\n",
    "#     print(reexecuta)\n",
    "    return reexecuta\n",
    "\n",
    "#Função para geração do F1 médio\n",
    "def geraF1(toClass, classificador, onde_foi_chamado): #toClass é o conjunto de treinamento\n",
    "    \n",
    "#     print(\"F1 chamado {0}\".format(onde_foi_chamado))\n",
    "    \n",
    "    f1 = 0\n",
    "    std = 0\n",
    "    coef_var = 0\n",
    "    svm_ok = True\n",
    "    \n",
    "    if classificador == 'SVM':\n",
    "        modelo = SVC(random_state = seed)\n",
    "    elif classificador == 'DT':\n",
    "        modelo = DecisionTreeClassifier(random_state = seed)\n",
    "    \n",
    "    #Separação do conjunto X e y\n",
    "    XtoClass = toClass.iloc[:,1:]\n",
    "    ytoClass = toClass.duplicata\n",
    "    \n",
    "    #Divisão dos conjuntos de treino e teste (20% para esse último)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(XtoClass, ytoClass, test_size=0.20, random_state=seed)\n",
    "    \n",
    "    #Validação cruzada\n",
    "    #This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    "    \n",
    "    kfold = KFold(n_splits=2, random_state=seed)\n",
    "    kfoldUtilizado = \"kf-2\"\n",
    "    cv_results = 0\n",
    "    \n",
    "    try:\n",
    "                \n",
    "        kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "        kfoldUtilizado = \"skf-5\"\n",
    "        cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "            \n",
    "    except ValueError:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            kfold = KFold(n_splits=5, random_state=seed)\n",
    "            kfoldUtilizado = \"kf-5\"\n",
    "            cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "\n",
    "        except ValueError:\n",
    "            \n",
    "            try:\n",
    "\n",
    "                kfold = KFold(random_state=seed) #Default n_splits = 3\n",
    "                kfoldUtilizado = \"kf-3\"\n",
    "                cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "\n",
    "            except ValueError:\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    kfold = KFold(n_splits=2, random_state=seed)\n",
    "                    kfoldUtilizado = \"kf-2\"\n",
    "                    cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "\n",
    "                except:\n",
    "                    if classificador == 'SVM':\n",
    "                        svm_ok = False\n",
    "                    print('Erro com a geração dos folds!')\n",
    "                    print(\"kfold utilizado: {0}\".format(kfoldUtilizado))\n",
    "                    print(\"classificador: {0}\".format(classificador))\n",
    "                    exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                    fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                    print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                    print(sys.exc_info())\n",
    "                    return f1, std, coef_var, svm_ok#, tamTreino\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        f1 = cv_results.mean()\n",
    "        std = cv_results.std()\n",
    "        coef_var = std/f1\n",
    "    except:\n",
    "        print(\"ERRO NA VALIDAÇÃO CRUZADA!\")\n",
    "        print(\"kfold utilizado: {0}\".format(kfoldUtilizado))\n",
    "#         print(\"Conjunto de treinamento:\")\n",
    "#         print(toClass)\n",
    "        print(\"Tamanho de toClass: {0}\".format(len(toClass)))\n",
    "        print(\"F1 foi chamado: {0}\".format(onde_foi_chamado))\n",
    "    \n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "        print(sys.exc_info())\n",
    "        \n",
    "    \n",
    "#     tamTreino = len(XtoClass)\n",
    "    \n",
    "    return f1, std, coef_var, svm_ok#, tamTreino\n",
    "\n",
    "############################################################################################################################\n",
    "#Repetições para os experimentos começam aqui\n",
    "############################################################################################################################\n",
    "\n",
    "#Parâmetros do usuário (Definir entrada dos dados)\n",
    "estat_ord = 'med' #Estatística para ordenamento\n",
    "#qtd_alg = 23 #Quantidade total de algoritmos (Modificado para ser atualizado em cada iteração de acordo com a quantidade máxima de algoritmos em cada experimento)\n",
    "qtd_alg_nd = 2 #Quantidade máxima de algoritmos para separar o conjunto de possíves não-duplicadas\n",
    "# k = 3 #Tamanho da janela\n",
    "# janelas = [2,3,4,5]\n",
    "    # janelas = [3] \n",
    "# janelas = [1, 0.01, 0.03, 0.05] # K = {1, 1%, 3%, 5%}\n",
    "janelas = [0.01]\n",
    "orcamento = 200 #Ou uma porcentagem da base de dados\n",
    "orcamento_orig = orcamento\n",
    "tam_min_ct = 20\n",
    "seed = 500\n",
    "# nAlg = 23\n",
    "\n",
    "etapa = '2 - AA[dg-arj]'\n",
    "\n",
    "# base = \"cds\"\n",
    "# qp = \"QP1\"\n",
    "\n",
    "# bases = [\"cds\", \"dblp\"]\n",
    "bases = [\"restaurant\"]\n",
    "qps = [\"qp1\"] #Apenas QP1.\n",
    "\n",
    "for base in bases:\n",
    "    \n",
    "    print(\"Base atual: {0}\".format(base))\n",
    "    \n",
    "    for qp in qps:\n",
    "        \n",
    "        print(\"QP atual: {0}\".format(qp))\n",
    "\n",
    "        # dirOrig = \"../../csv/conjuntosDS/conjuntosDiverg/\"\n",
    "        # dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAA/\"\n",
    "#         dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAAMenor/\"\n",
    "        dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAA/\"+base+\"/\"+qp+\"/\"\n",
    "        dirEstat = \"../../csv/estatisticas/\"+base+\"/\"+qp+\"/\"\n",
    "        estat = dirEstat+\"estatisticaDS.csv\"\n",
    "        \n",
    "        #Arquivo para armazenar os erros\n",
    "        logErros = dirEstat+'log-001.txt'\n",
    "        print(logErros)\n",
    "        \n",
    "        for k in janelas:\n",
    "\n",
    "            nao_passaram = 0\n",
    "            iteracoes = 0\n",
    "\n",
    "            estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados', 'etapa', 'permutacao'], sep=';')\n",
    "\n",
    "            ###### Criação do dataframe que armazenará as estatísticas dos conjuntos de treino e teste\n",
    "        #   estat_conj = pd.DataFrame (index=['algUtl', 'permutacao'], columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "            estat_conj = pd.DataFrame (columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste', 'passou'])\n",
    "\n",
    "\n",
    "            arquivos = [] #Adicionado depois\n",
    "\n",
    "            for _, _, arquivo in os.walk(dirOrig):\n",
    "                arquivos.extend(arquivo)\n",
    "\n",
    "            for arq in arquivos:\n",
    "\n",
    "                if ('_NEW' in arq):# & (iteracoes <= 50):\n",
    "#                 if ('_NEW' in arq) & (iteracoes <= 0):\n",
    "#                 if ('diverg(10)133_NEW' in arq) & (iteracoes <= 0): #Aqui, Diego!\n",
    "                    \n",
    "        #         if ('diverg(10)18_NEW' in arq) & (iteracoes <= 0):\n",
    "        #         if ('diverg(10)18_NEW' in arq) | ('diverg(10)15_NEW' in arq) & (iteracoes <= 1):\n",
    "                    print(\"##################################################################\")\n",
    "                    print(\"Analisando o arquivo: {0}\".format(arq))\n",
    "                    print(\"##################################################################\")\n",
    "\n",
    "                    iteracoes += 1\n",
    "\n",
    "                    num = re.sub(r'diverg.*\\)', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    num = num.replace('_NEW.csv','')\n",
    "\n",
    "                    algUtl = re.sub(r'diverg.*\\(', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    algUtl = re.sub(r'\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    algUtl = int(algUtl)\n",
    "\n",
    "                    permutacao = int(num)\n",
    "\n",
    "                    linhaAtual = estatisticas.xs((algUtl, '1 - acm diverg', permutacao))    \n",
    "\n",
    "                    ###### Leitura do conjunto de pares conflitantes\n",
    "                    pc = dirOrig+arq\n",
    "\n",
    "                    print(\"pc: {0}\".format(pc))\n",
    "\n",
    "                    pc = pd.read_csv(pc, sep=';', index_col=['elemento1', 'elemento2']) #pares conflitantes\n",
    "\n",
    "                    cols = list(pc.columns.values)\n",
    "                    cols.pop(cols.index('duplicata'))\n",
    "                    pc = pc[['duplicata']+cols]\n",
    "                    \n",
    "                    print(\"pc.columns.values\")\n",
    "                    print(pc.columns.values)\n",
    "\n",
    "                    pc_aa = pc.iloc[:, :5 ] #Conjunto onde serão aplicadas as janelas deslizantes\n",
    "                    pc_vetores = pc.iloc[:, 5: ] #Conjunto base para compor o conjunto treinamento \n",
    "                    \n",
    "                    print(\"pc_aa.columns.values\")\n",
    "                    print(pc_aa.columns.values)\n",
    "                                        \n",
    "                    print(\"pc_vetores.columns.values\")\n",
    "                    print(pc_vetores.columns.values)\n",
    "\n",
    "                    #Criação da coluna de ENTROPIA\n",
    "\n",
    "                    #ENTROPIA = −[P+(e) · ln(P+(e)) +P−(e) · ln(P−(e))]\n",
    "\n",
    "                    #Onde, P+(e) é a fração de casos positivos identificados pelo comitê (|CASOS_POSITIVOS|/|COMITÊ|).\n",
    "\n",
    "                    #             pc_aa['entropia'] = -(pc_aa['qtdAlg']/nAlg * np.log(pc_aa['qtdAlg']/nAlg) + ((nAlg - pc_aa['qtdAlg'])/nAlg) * np.log((nAlg - pc_aa['qtdAlg'])/nAlg))\n",
    "                    pc_aa['entropia'] = -(pc_aa['qtdAlg']/algUtl * np.log(pc_aa['qtdAlg']/algUtl) + ((algUtl - pc_aa['qtdAlg'])/algUtl) * np.log((algUtl - pc_aa['qtdAlg'])/algUtl))\n",
    "\n",
    "                    # pc_aa = pc.loc[:, :'med' ]\n",
    "                    # pc_vetor = pc.loc[:, 'med': ] #Como referenciar a coluna vizinha à 'med'?\n",
    "\n",
    "                    duplicata = pc_aa.loc[:, 'duplicata' ]\n",
    "\n",
    "                    #Adicionando a coluna de duplicatas a pc_vetores\n",
    "                    pc_vetores = pd.concat([duplicata, pc_vetores], axis=1, ignore_index=False)\n",
    "                    \n",
    "                    print(\"pc_vetores.columns.values\")\n",
    "                    print(pc_vetores.columns.values)\n",
    "\n",
    "                    conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "                    ###### \n",
    "\n",
    "                    #Separação do conjunto de pares conflitantes em dois a partir da quantidade de algoritmos \n",
    "                    #que aponta o par como possível duplicata \n",
    "                    #(conjunto A com quantidade de algoritmos = 1, com maioria composta por possíveis não-duplicatas,\n",
    "                    #e conjunto B com quantidade de algoritmos > 1, contendo mais possíveis duplicatas que o conjunto A)\n",
    "                    ndup = pc_aa.loc[pc['qtdAlg'] <= qtd_alg_nd]\n",
    "                    dup = pc_aa.loc[(pc['qtdAlg'] > qtd_alg_nd) & (pc['qtdAlg'] < (algUtl - qtd_alg_nd))]\n",
    "                    #dup = pc_aa.loc[(pc['qtdAlg'] > qtd_alg_nd) & (pc['qtdAlg'] < (qtd_alg - qtd_alg_nd))]\n",
    "                    # dup = dup[pc['qtdAlg'] <= (qtd_alg - qtd_alg_nd)]\n",
    "\n",
    "                    ###### Ordenamento dos pares pela estatística selecionada\n",
    "        #             ndup = ndup.sort_values(estat_ord) \n",
    "        #             dup = dup.sort_values(estat_ord, ascending=False)\n",
    "\n",
    "                    ###### Ordenamento dos pares pela estatística selecionada \n",
    "                    #Modificando a ordenação a fim de fazer com que as janelas deslizem \n",
    "                    #a partir do meio do conjunto todo e assim pegar pares da região de incerteza do conjunto todo\n",
    "\n",
    "        #             ndup = ndup.sort_values(estat_ord) #ndup - pegando do menor para o maior\n",
    "                    ndup = ndup.sort_values(estat_ord, ascending=False) #ndup - pegando do maior para o menor (INCERTEZA)\n",
    "                    dup = dup.sort_values(estat_ord) #dup - pegando do menor para o maior (INCERTEZA)\n",
    "        #             dup = dup.sort_values(estat_ord, ascending=False) #dup - pegando do maior para o menor \n",
    "\n",
    "                    ###### Variáveis para verificar se pode deslizar a janela dentro de dup (ou ndup)\n",
    "\n",
    "        #             deslz_dup = len(dup)/k\n",
    "        #             deslz_ndup = len(ndup)/k\n",
    "                    deslz_dup = 0\n",
    "                    deslz_ndup = 0\n",
    "                    k_dup = 0\n",
    "                    k_ndup = 0\n",
    "\n",
    "\n",
    "\n",
    "                    if (k == 1):\n",
    "\n",
    "                        deslz_dup = len(dup)\n",
    "                        deslz_ndup = len(ndup)\n",
    "\n",
    "                        k_dup = 1\n",
    "                        k_ndup = 1\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        try:\n",
    "\n",
    "                            k_dup = int(np.around(len(dup)*k))\n",
    "                            k_ndup = int(np.around(len(ndup)*k))\n",
    "                            \n",
    "                            if k_dup < 1:\n",
    "                                k_dup = 1\n",
    "                            if k_ndup < 1:\n",
    "                                k_ndup = 1\n",
    "\n",
    "                            deslz_dup = len(dup)/k_dup\n",
    "                            deslz_ndup = len(ndup)/k_ndup\n",
    "                        \n",
    "                        except ZeroDivisionError:\n",
    "                            \n",
    "                            with open(logErros, 'a+') as arqLogErros:\n",
    "                                arqLogErros.write('#############################')\n",
    "                                arqLogErros.write('\\n')\n",
    "                                arqLogErros.write('Erro, divisão por zero!')\n",
    "                                arqLogErros.write('\\n')\n",
    "                                arqLogErros.write(\"Arquivo: {0}\".format(arq))\n",
    "                                arqLogErros.write('\\n')\n",
    "                                arqLogErros.write(\"len(dup): {0} - len(ndup): {1}\".format(len(dup), len(ndup)))\n",
    "                                arqLogErros.write('\\n')\n",
    "                                arqLogErros.write(\"k: {0} --> k_dup: {1} - k_ndup: {2}\".format(k, k_dup, k_ndup))\n",
    "                                arqLogErros.write('\\n')\n",
    "                                arqLogErros.write(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "                                arqLogErros.write('\\n')\n",
    "#                                 arqLogErros.close()\n",
    "                            \n",
    "                            print('Erro, divisão por zero!')\n",
    "                            print(\"Arquivo: {0}\".format(arq))\n",
    "                            print(\"len(dup): {0} - len(ndup): {1}\".format(len(dup), len(ndup)))\n",
    "                            print(\"k: {0} --> k_dup: {1} - k_ndup: {2}\".format(k, k_dup, k_ndup))\n",
    "                            print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "                        \n",
    "                        \n",
    "                            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                            print(sys.exc_info())\n",
    "                        except:\n",
    "                            \n",
    "                            print('O outro except!')\n",
    "                            print(\"Arquivo: {0}\".format(arq))\n",
    "                            print(\"len(dup): {0} - len(ndup): {1}\".format(len(dup), len(ndup)))\n",
    "                            print(\"k: {0} --> k_dup: {1} - k_ndup: {2}\".format(k, k_dup, k_ndup))\n",
    "                            print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "                            \n",
    "                            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                            print(sys.exc_info())\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "                    print(\"---At the beginning---\")\n",
    "\n",
    "                    print(\"len(dup): {0} - len(ndup): {1}\".format(len(dup), len(ndup)))\n",
    "                    print(\"k: {0} --> k_dup: {1} - k_ndup: {2}\".format(k, k_dup, k_ndup))\n",
    "                    print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "\n",
    "\n",
    "                    ###### Validação do tamanho para deslizamento\n",
    "\n",
    "                    #Se não houver espaço suficiente para deslizar as janelas,\n",
    "                    #a ponto de formar o conjunto mínimo de treinamento\n",
    "                    if (deslz_dup < tam_min_ct/2) | (deslz_ndup < tam_min_ct/2):\n",
    "                        pode_passar = False #Teria que ser informado para o usuário definir novo tamanho de janela\n",
    "                        print(\"Arquivo: {0} não passou!\".format(arq))\n",
    "                        nao_passaram += 1\n",
    "                    else:\n",
    "                        pode_passar = True\n",
    "\n",
    "                    ###### Criação do dataframe que armazenará o conjunto de treinamento\n",
    "\n",
    "                    conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "                    ###### Criação do dataframe que armazenará os pares descartados na etada de max_local\n",
    "                    conj_descart = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "                    ###### Povoamento inicial sem aleatoriedade no except\n",
    "\n",
    "                    orcamento = orcamento_orig\n",
    "        #             conj_treino = pd.DataFrame(columns=pc_vetores.columns.values) #LOCAL ORIGINAL DE conj_treino\n",
    "\n",
    "                    continua = True\n",
    "                    f1_anterior = 0\n",
    "                    f1_atual = 0\n",
    "                    f1_svm = 0\n",
    "                    f1_dt = 0\n",
    "\n",
    "                    jan_inic_ndup = 0 \n",
    "                    jan_fin_ndup = k_ndup\n",
    "\n",
    "                    jan_inic_dup = 0 \n",
    "                    jan_fin_dup = k_dup\n",
    "\n",
    "        #             cont = 0\n",
    "                    contDup = 0\n",
    "                    contNDup = 0\n",
    "\n",
    "                    continua = True\n",
    "                    unblock_ndup = True #Adicionado para tentar manter o conjunto balanceado\n",
    "                    unblock_dup = True #Adicionado para tentar manter o conjunto balanceado\n",
    "\n",
    "                    if (pode_passar):\n",
    "\n",
    "                        #Povoamento inicial com 20 pares rotulados (10 de cada)\n",
    "        #                 while (cont < tam_min_ct) & (continua): #Nesse exemplo seriam 20 de cada\n",
    "                        while ((contDup < tam_min_ct/2) | (contNDup < tam_min_ct/2)) & (continua):\n",
    "\n",
    "        #                     print('contDup: {0} - contNDup: {1}'.format(contDup, contNDup))\n",
    "                            reexecuta = True\n",
    "\n",
    "                            #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                            #Seleciona-se o par com maior valor de similaridade para rotulação\n",
    "\n",
    "                            deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "        #                     while (reexecuta) & (deslz_ndup >= 1):\n",
    "                            while (reexecuta) & (deslz_ndup >= 1) & (unblock_ndup):\n",
    "#                             while (reexecuta) & (deslz_ndup >= 1) & (unblock_ndup) & (contNDup < tam_min_ct/2):\n",
    "\n",
    "        #                         print(\"while sendo chamado para ndup!\")\n",
    "\n",
    "        #                         print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "\n",
    "                                grupo = ndup.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "                                sel_vet_rot(grupo, 'min', 'ndup', 'o ndup chamou de 20')\n",
    "\n",
    "                                if not(reexecuta):\n",
    "                                    contNDup += 1 #Atualização da variável utilizada para monitorar o tamanho do conjunto de treinamento inicial\n",
    "\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                            #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                            #Seleciona-se o par com maior entropia (mais conflitante) para rotulação\n",
    "\n",
    "                            deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "                            print(\"deslz_dup na geração do conjunto inicial: {0}\".format(deslz_dup))\n",
    "\n",
    "        #                     while (reexecuta) & (deslz_dup >= 1):\n",
    "                            while (reexecuta) & (deslz_dup >= 1) & (unblock_dup):\n",
    "#                             while (reexecuta) & (deslz_dup >= 1) & (unblock_dup) & (contDup < tam_min_ct/2):\n",
    "\n",
    "        #                         print(\"while sendo chamado para dup!\")\n",
    "\n",
    "        #                         print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "\n",
    "                                grupo = dup.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                                sel_vet_rot(grupo, 'entropia', 'dup', 'o dup chamou de 20')\n",
    "\n",
    "                                if not(reexecuta):\n",
    "                                    contDup += 1 #Atualização da variável utilizada para monitorar o tamanho do conjunto de treinamento inicial\n",
    "\n",
    "                            #Verificação do balanceamento do conjunto de treinamento gerado até então\n",
    "                            duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "                            duplicatas = duplicatas.count(True)\n",
    "                            percentDup = float(duplicatas/float(len(conj_treino))*100)\n",
    "                            percentDup = float(\"{0:.2f}\".format(percentDup))\n",
    "\n",
    "                            nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "                            nao_duplicatas = nao_duplicatas.count(False)\n",
    "                            percentNaoDup = float(nao_duplicatas/float(len(conj_treino))*100)\n",
    "                            percentNaoDup = float(\"{0:.2f}\".format(percentNaoDup))\n",
    "\n",
    "                            dif_perc = abs(percentDup - percentNaoDup)\n",
    "                            \n",
    "                            unblock_dup = True\n",
    "                            unblock_ndup = True\n",
    "\n",
    "#                             print('contDup: {0} - contNDup: {1}'.format(contDup, contNDup))\n",
    "#                             print('$$$$$Antes de calcular a diferença entre as porcentagens$$$$$')\n",
    "\n",
    "                            if (dif_perc > 25):\n",
    "                                print(\"Diferença entre as porcentagens: {0}\".format(dif_perc))\n",
    "#                                 print(\"Porcentagem de dup: {0} - Porcentagem de ndup: {1}\".format(percentDup, percentNaoDup))\n",
    "        #                         input(\"Enter\")\n",
    "                                if(percentDup > percentNaoDup):\n",
    "                                    print(\"percentDup > percentNaoDup\")\n",
    "                                    print(\"percentDup: {0} > percentNaoDup: {1}\".format(percentDup,percentNaoDup))\n",
    "                    \n",
    "#                                     if not (contNDup < tam_min_ct/2):\n",
    "                                    if (contNDup < tam_min_ct/2): #Se ainda se pode entrar no bloco de atualização de ndup, desbloqueia a execução para ndup\n",
    "                                                                     #Do contrário, não entraria em tal bloco, esgotaria-se o deslz_ndup\n",
    "                                                                    #e ainda impediria o preenchimento da quantidade mínima de vetores em dup\n",
    "                                        \n",
    "                                        \n",
    "                                        unblock_dup = False\n",
    "                                        unblock_ndup = True\n",
    "                                else:\n",
    "                                    print(\"percentDup <= percentNaoDup\")\n",
    "                                    print(\"percentDup: {0} <= percentNaoDup: {1}\".format(percentDup,percentNaoDup)) \n",
    "                                    \n",
    "#                                     if not (contDup < tam_min_ct/2):                                    \n",
    "                                    if (contDup < tam_min_ct/2): #Se ainda se pode entrar no bloco de atualização de dup\n",
    "                                                                    #Do contrário, não entraria em tal bloco, esgotaria-se o deslz_dup\n",
    "                                                                   #e ainda impediria o preenchimento da quantidade mínima de vetores em ndup\n",
    "                                        \n",
    "                                        unblock_dup = True\n",
    "                                        unblock_ndup = False\n",
    "\n",
    "\n",
    "                            #Atualização das janelas\n",
    "                            jan_inic_ndup = jan_inic_ndup + k_ndup\n",
    "                            jan_fin_ndup = jan_fin_ndup + k_ndup\n",
    "\n",
    "                            jan_inic_dup = jan_inic_dup + k_dup\n",
    "                            jan_fin_dup = jan_fin_dup + k_dup\n",
    "\n",
    "                            if(deslz_dup < 1) | (deslz_ndup < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                                continua = False\n",
    "\n",
    "        #                     cont += 1 #Atualização da variável utilizada para monitorar o tamanho do conjunto de treinamento inicial\n",
    "\n",
    "        #                     contNDup += 1 #Atualização da variável utilizada para monitorar o tamanho do conjunto de treinamento inicial\n",
    "\n",
    "                        #Treina SVM e Decision Tree (justificar o pq) e verifica a média da medida de qualidade (f1, precision...)\n",
    "                        f1_svm, std_svm, cv_svm, svmOk = geraF1(conj_treino, 'SVM', 'após os 20')\n",
    "                        f1_dt, std_dt, cv_dt, svmOk_dt = geraF1(conj_treino, 'DT', 'após os 20')\n",
    "\n",
    "                        if svmOk:\n",
    "\n",
    "                            f1_atual = (f1_svm + f1_dt)/2\n",
    "                            std_atual = (std_svm + std_dt)/2\n",
    "                            cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            f1_atual = (f1_dt)\n",
    "                            std_atual = (std_dt)\n",
    "                            cv_atual = (cv_dt)\n",
    "\n",
    "#                         print('')\n",
    "#                         print(\"Tamanho do conjunto de treinamento após os supostos 20: {0}\".format(len(conj_treino)))\n",
    "#                         print('')\n",
    "        #                 print('((contDup < tam_min_ct/2) | (contNDup < tam_min_ct/2)): {0} - (continua): {1}'.format(((contDup < tam_min_ct/2) | (contNDup < tam_min_ct/2)), (continua)))\n",
    "        #                 print('')\n",
    "        #                 print('(deslz_dup < 1) :{0} (deslz_ndup < 1):{1}'.format((deslz_dup < 1), (deslz_ndup < 1)))\n",
    "\n",
    "                        ###### Aplicação das janelas deslizantes após o povoamento incial sem aleatoriedade no except\n",
    "\n",
    "                        # continua = True\n",
    "                        max_local = 0\n",
    "                        igual = 0\n",
    "\n",
    "            #             print(\"Início\")\n",
    "            #             print(\"orcamento: {0}\".format(orcamento))\n",
    "            #             print(\"Quantidade de itens no conjunto de treinamento: {}\".format(len(conj_treino)))\n",
    "\n",
    "                        while continua:\n",
    "\n",
    "                            f1_anterior = f1_atual\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                            deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "        #                     while (reexecuta) & (deslz_ndup >= 1):\n",
    "                            while (reexecuta) & (deslz_ndup >= 1) & (unblock_ndup):\n",
    "\n",
    "        #                         print(\"while sendo chamado para ndup!\")\n",
    "\n",
    "        #                         print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "\n",
    "                                grupo = ndup.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "        #                         #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "        #                         #Seleciona-se o par com maior valor de similaridade para rotulação\n",
    "                                sel_vet_rot(grupo, 'min', 'ndup', 'o ndup chamou')\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                            #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                            #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                            deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "                            print(\"deslz_dup na geração do restante do conjunto: {0}\".format(deslz_dup))\n",
    "\n",
    "        #                     while (reexecuta) & (deslz_dup >= 1):\n",
    "                            while (reexecuta) & (deslz_dup >= 1) & (unblock_dup):\n",
    "\n",
    "        #                         print(\"while sendo chamado para ndup!\")\n",
    "\n",
    "        #                         print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "\n",
    "                                grupo = dup.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                                sel_vet_rot(grupo, 'entropia', 'dup', 'o dup chamou')\n",
    "\n",
    "\n",
    "                            #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                            f1_svm, std_svm, cv_svm, svmOk = geraF1(conj_treino, 'SVM', 'no deslizamento final')\n",
    "                            f1_dt, std_dt, cv_dt, svmOk_dt = geraF1(conj_treino, 'DT', 'no deslizamento final')\n",
    "\n",
    "                            if svmOk:\n",
    "\n",
    "                                f1_atual = (f1_svm + f1_dt)/2\n",
    "                                std_atual = (std_svm + std_dt)/2\n",
    "                                cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                f1_atual = (f1_dt)\n",
    "                                std_atual = (std_dt)\n",
    "                                cv_atual = (cv_dt)\n",
    "\n",
    "                            cv_atual = cv_atual*100\n",
    "\n",
    "                            #Atualização das condições de parada\n",
    "                            #depois de selecionar e rotular a possível duplicata e possível não-duplicata\n",
    "\n",
    "                            if orcamento > 0 : #Se ainda tem orçamento pra gastar\n",
    "                                #if cv_atual < 10:\n",
    "                                if cv_atual <= 5:\n",
    "                                    if (f1_atual >= f1_anterior) and (igual <= 3): #Selecionam-se novos pares para rotulação\n",
    "                                        max_local = 0\n",
    "\n",
    "                                        if f1_atual == f1_anterior:\n",
    "                                            igual += 1\n",
    "                                        elif (f1_atual > f1_anterior) and (igual > 0):\n",
    "                                            igual = 0\n",
    "\n",
    "                                        continua = True\n",
    "                                    elif (f1_atual < f1_anterior):\n",
    "                                        max_local += 1\n",
    "                                        igual = 0\n",
    "                                        #Se entrar aqui tem que remover os últimos pares que entraram no conjunto de treinamento\n",
    "\n",
    "                                        #IMPORTANTE! Fazer com que esses devem sejam extraídos para o conjunto PM, não apenas descartados\n",
    "                                        conj_descart = conj_descart.append(conj_treino.tail(2)) #Guardando os vetores a serem retirados do conjunto treinamento\n",
    "                                        conj_treino.drop(conj_treino.tail(2).index,inplace=True)\n",
    "\n",
    "        #                                 print(\"f1_atual < f1_anterior\")\n",
    "        #                                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "        #                                 input(\"Pressione ENTER para continuar\")\n",
    "\n",
    "                                        if (max_local <= 4):\n",
    "                                            f1_atual = f1_anterior\n",
    "                                        else:\n",
    "                                            f1_atual = f1_anterior\n",
    "        #                                     print('O f1 passou a piorar')\n",
    "        #                                     print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "        #                                     input(\"Pressione ENTER para continuar\")\n",
    "                                            continua = False\n",
    "                                            break\n",
    "                                    elif (igual > 3): #Se a medida de qualidade for igual à anterior (por três vezes)\n",
    "        #                                     print('F1 convergiu!') \n",
    "        #                                     input(\"Pressione ENTER para continuar\")\n",
    "                                            continua = False\n",
    "                                            break\n",
    "\n",
    "                            else:\n",
    "                                continua = False\n",
    "                                break\n",
    "\n",
    "                            #Verificação do balanceamento do conjunto de treinamento gerado até então\n",
    "                            duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "                            duplicatas = duplicatas.count(True)\n",
    "                            percentDup = float(duplicatas/float(len(conj_treino))*100)\n",
    "                            percentDup = float(\"{0:.2f}\".format(percentDup))\n",
    "\n",
    "                            nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "                            nao_duplicatas = nao_duplicatas.count(False)\n",
    "                            percentNaoDup = float(nao_duplicatas/float(len(conj_treino))*100)\n",
    "                            percentNaoDup = float(\"{0:.2f}\".format(percentNaoDup))\n",
    "\n",
    "                            dif_perc = abs(percentDup - percentNaoDup)\n",
    "\n",
    "                            if (dif_perc > 25):\n",
    "                                if(percentDup > percentNaoDup):\n",
    "                                    \n",
    "                                    unblock_dup = False\n",
    "                                    unblock_ndup = True\n",
    "                                else:\n",
    "                                    \n",
    "                                    unblock_dup = True\n",
    "                                    unblock_ndup = False\n",
    "\n",
    "                            #Atualização das janelas\n",
    "                            jan_inic_ndup = jan_inic_ndup + k_ndup\n",
    "                            jan_fin_ndup = jan_fin_ndup + k_ndup\n",
    "\n",
    "                            jan_inic_dup = jan_inic_dup + k_dup\n",
    "                            jan_fin_dup = jan_fin_dup + k_dup\n",
    "\n",
    "                            if(deslz_dup < 1) | (deslz_ndup < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                                continua = False\n",
    "\n",
    "            #                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "            #                 print(\"igual: {0}\".format(igual))\n",
    "\n",
    "\n",
    "                    else: #Se não pode passar, nesses experimentos, ao invés de solicitar que o usuário\n",
    "                          #determine novo tamanho de janela, é estabelecido um único conjunto por onde\n",
    "                          #as janelas irão deslizar.\n",
    "\n",
    "                        print('ENTROU NO ELSE POR NÃO PASSAR')\n",
    "\n",
    "                        pc_aa = pc_aa.sort_values(estat_ord, ascending = False) \n",
    "\n",
    "                        deslz = 0\n",
    "\n",
    "                        if (k == 1):\n",
    "\n",
    "                            deslz = len(pc_aa)\n",
    "                            k = 1\n",
    "\n",
    "                        else:\n",
    "                            \n",
    "                            k = int(np.around(len(pc_aa)*k))\n",
    "                            \n",
    "                            if k < 1:\n",
    "                                k = 1\n",
    "                            \n",
    "                            deslz = len(pc_aa)/k\n",
    "\n",
    "                        jan_inic_dup = 0 \n",
    "                        jan_fin_dup = k\n",
    "\n",
    "                        jan_inic_ndup = len(pc_aa) #Fim de pc_aa\n",
    "                        jan_fin_ndup = len(pc_aa) - k\n",
    "\n",
    "\n",
    "                        #se a janela final de ndup for menor que a janela final de dup, para\n",
    "                        cont = 0\n",
    "                        #Povoamento inicial com 20 pares rotulados (10 de cada)\n",
    "                        while (cont < tam_min_ct) & (continua) & (jan_fin_dup < jan_fin_ndup):\n",
    "\n",
    "                            #Desliza-se a janela\n",
    "                            reexecuta = True\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "            #                 print(\"reexecuta: {0} - deslz_ndup >= 1: {1}\".format(reexecuta, deslz_ndup >= 1))\n",
    "\n",
    "                            while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "            #                     grupo = pc_aa.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "                                grupo = pc_aa.iloc[jan_fin_ndup:jan_inic_ndup] # three rows of dataframe\n",
    "\n",
    "                                #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                                #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    id_row_sel = grupo['min'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                                    #Só passa pra cá se não lançar except\n",
    "                                    reexecuta = False\n",
    "                                    #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                                    vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                                    conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                                    orcamento -= 1\n",
    "\n",
    "\n",
    "                                except ValueError:\n",
    "\n",
    "                                    print(\"Atualizando janelas no except\")\n",
    "                                    print(grupo)\n",
    "                                    jan_inic_ndup = jan_inic_ndup - k\n",
    "                                    jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "        #                             print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "        #                             print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "                                    reexecuta = True\n",
    "\n",
    "                                except:\n",
    "                                    print('Eita!')\n",
    "\n",
    "            #                 print(\"Possível não-duplicata\")\n",
    "            #                 print(vetor_sel)\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                            #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                            #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "                                grupo = pc_aa.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                                    #Só passa pra cá se não lançar except\n",
    "                                    reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                                    #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                                    vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                                    conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                                    orcamento -= 1\n",
    "\n",
    "                                except ValueError:\n",
    "\n",
    "                                    print(\"Atualizando janelas no except\")\n",
    "                                    print(grupo)\n",
    "                                    jan_inic_dup = jan_inic_dup + k\n",
    "                                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                                    print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "                                    print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "\n",
    "                                    reexecuta = True\n",
    "\n",
    "                                except:\n",
    "                                    print('Eita!')\n",
    "\n",
    "            #                 print(\"Possível duplicata\")\n",
    "            #                 print(vetor_sel)\n",
    "\n",
    "                            #Atualização das janelas\n",
    "                            jan_inic_ndup = jan_inic_ndup - k\n",
    "                            jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            if(deslz < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                                continua = False\n",
    "\n",
    "\n",
    "                            cont += 1\n",
    "\n",
    "\n",
    "                        #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                        f1_svm, std_svm, cv_svm, svmOk = geraF1(conj_treino, 'SVM', 'após os 20 quando ENTROU NO ELSE POR NÃO PASSAR')\n",
    "                        f1_dt, std_dt, cv_dt, svmOk_dt = geraF1(conj_treino, 'DT', 'após os 20 quando ENTROU NO ELSE POR NÃO PASSAR')\n",
    "\n",
    "                        if svmOk:\n",
    "\n",
    "                            f1_atual = (f1_svm + f1_dt)/2\n",
    "                            std_atual = (std_svm + std_dt)/2\n",
    "                            cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            f1_atual = (f1_dt)\n",
    "                            std_atual = (std_dt)\n",
    "                            cv_atual = (cv_dt)\n",
    "                        ###### Aplicação das janelas deslizantes após o povoamento incial sem aleatoriedade no except\n",
    "\n",
    "\n",
    "                        # continua = True\n",
    "                        max_local = 0\n",
    "                        igual = 0\n",
    "\n",
    "            #             print(\"Início\")\n",
    "            #             print(\"orcamento: {0}\".format(orcamento))\n",
    "            #             print(\"Quantidade de itens no conjunto de treinamento: {}\".format(len(conj_treino)))\n",
    "\n",
    "                        while continua:\n",
    "\n",
    "                            f1_anterior = f1_atual\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            while (reexecuta) & (deslz_ndup >= 1):\n",
    "                                grupo = pc_aa.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "                                #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                                #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    id_row_sel = grupo['min'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                                    #Só passa pra cá se não lançar except\n",
    "                                    reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                                    #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                                    vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                                    conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                                    orcamento -= 1\n",
    "\n",
    "                                except ValueError:\n",
    "\n",
    "                                    print(\"Atualizando janelas no except\")\n",
    "                                    jan_inic_ndup = jan_inic_ndup - k\n",
    "                                    jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                                    reexecuta = True\n",
    "\n",
    "                                except:\n",
    "                                    print('Eita!')\n",
    "\n",
    "            #                 print(\"Possível não-duplicata\")\n",
    "            #                 print(vetor_sel)\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                            #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                            #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "                                grupo = pc_aa.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                                    #Só passa pra cá se não lançar except\n",
    "                                    reexecuta = False\n",
    "                                    #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                                    vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                                    conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                                    orcamento -= 1\n",
    "\n",
    "                                except ValueError:\n",
    "\n",
    "                                    print(\"Atualizando janelas no except\")\n",
    "                                    jan_inic_dup = jan_inic_dup + k\n",
    "                                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                                    reexecuta = True\n",
    "\n",
    "                                except:\n",
    "                                    print('Eita!')\n",
    "\n",
    "            #                 print(\"Possível duplicata\")\n",
    "            #                 print(vetor_sel)\n",
    "\n",
    "                            #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                            f1_svm, std_svm, cv_svm, svmOk = geraF1(conj_treino, 'SVM', 'quando ENTROU NO ELSE POR NÃO PASSAR')\n",
    "                            f1_dt, std_dt, cv_dt, svmOk_dt = geraF1(conj_treino, 'DT', 'quando ENTROU NO ELSE POR NÃO PASSAR')\n",
    "\n",
    "                            if svmOk:\n",
    "\n",
    "                                f1_atual = (f1_svm + f1_dt)/2\n",
    "                                std_atual = (std_svm + std_dt)/2\n",
    "                                cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                f1_atual = (f1_dt)\n",
    "                                std_atual = (std_dt)\n",
    "                                cv_atual = (cv_dt)\n",
    "\n",
    "                            cv_atual = cv_atual*100\n",
    "\n",
    "\n",
    "                            if orcamento > 0 : #Se ainda tem orçamento pra gastar\n",
    "                                #if cv_atual < 10:\n",
    "                                if cv_atual <= 5:\n",
    "                                    if (f1_atual >= f1_anterior) and (igual <= 3): #Selecionam-se novos pares para rotulação\n",
    "                                        max_local = 0\n",
    "\n",
    "                                        if f1_atual == f1_anterior:\n",
    "                                            igual += 1\n",
    "                                        elif (f1_atual > f1_anterior) and (igual > 0):\n",
    "                                            igual = 0\n",
    "\n",
    "                                        continua = True\n",
    "                                    elif (f1_atual < f1_anterior):\n",
    "                                        max_local += 1\n",
    "                                        igual = 0\n",
    "                                        #Se entrar aqui tem que remover os últimos pares que entraram no conjunto de treinamento\n",
    "\n",
    "                                        conj_descart = conj_descart.append(conj_treino.tail(2)) #Guardando os vetores a serem retirados do conjunto treinamento\n",
    "                                        conj_treino.drop(conj_treino.tail(2).index,inplace=True)\n",
    "\n",
    "            #                             print(\"f1_atual < f1_anterior\")\n",
    "            #                             print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "\n",
    "                                        if (max_local <= 4):\n",
    "                                            f1_atual = f1_anterior\n",
    "                                        else:\n",
    "                                            f1_atual = f1_anterior\n",
    "            #                                 print('O f1 passou a piorar')\n",
    "            #                                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "                                            continua = False\n",
    "                                            break\n",
    "                                    elif (igual > 3): #Se a medida de qualidade for igual à anterior (por três vezes)\n",
    "            #                                 print('F1 convergiu!') \n",
    "                                            continua = False\n",
    "                                            break\n",
    "\n",
    "                            else:\n",
    "                                continua = False\n",
    "                                break\n",
    "\n",
    "                            #Atualização das janelas\n",
    "                            jan_inic_ndup = jan_inic_ndup - k\n",
    "                            jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            if(deslz < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                                continua = False\n",
    "\n",
    "                    print(\"---At the end---\")\n",
    "                    print(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "                    print(\"Tamanho do conjunto de treinamento: {0}\".format(len(conj_treino)))\n",
    "                    ##### Salvando os arquivos de treino e teste\n",
    "\n",
    "        #                 dirDest = \"../../csv/conjuntosDS/treinoTeste/\"\n",
    "\n",
    "        #             dirDest = \"../../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\"\n",
    "                    dirDest = \"../../csv/conjuntosDS/treinoTeste/\"+base+\"/\"+qp+\"/DgArj-k\"+str(k)+\"/\"\n",
    "\n",
    "                    abordagem = 'DS'\n",
    "\n",
    "                    #Verdadeiros positivos constantes no conjunto de pares descartados\n",
    "                    tp_adc = [i for i in conj_descart.duplicata if i == True]\n",
    "                    tp_adc = tp_adc.count(True)\n",
    "\n",
    "                    #Verdadeiros negativos constantes no conjunto de pares descartados\n",
    "                    tn_adc = [i for i in conj_descart.duplicata if i == False]\n",
    "                    tn_adc = tn_adc.count(False)\n",
    "\n",
    "#                     print(\"tp_adc: {0} - tn_adc: {1}\".format(tp_adc,tn_adc))\n",
    "\n",
    "                    iteracao = 1\n",
    "                    inspecoesManuais = orcamento_orig - orcamento\n",
    "\n",
    "                    duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "                    duplicatas = duplicatas.count(True)\n",
    "                    try:\n",
    "                        percentDup = float(duplicatas/float(len(conj_treino))*100)\n",
    "                        percentDup = float(\"{0:.2f}\".format(percentDup))\n",
    "                    except ZeroDivisionError:\n",
    "\n",
    "                        with open(logErros, 'a+') as arqLogErros:\n",
    "                            arqLogErros.write('#############################')\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write('Erro, percentDup!')\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"Arquivo: {0}\".format(arq))\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"len(dup): {0} - len(ndup): {1}\".format(len(dup), len(ndup)))\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"k: {0} --> k_dup: {1} - k_ndup: {2}\".format(k, k_dup, k_ndup))\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "                            arqLogErros.write('\\n')\n",
    "                        percentDup = 0\n",
    "        #             print(\"{0}% de duplicatas.\".format(str(percentage)[:5]))\n",
    "\n",
    "                    nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "                    nao_duplicatas = nao_duplicatas.count(False)\n",
    "                    try:\n",
    "                        percentNaoDup = float(nao_duplicatas/float(len(conj_treino))*100)\n",
    "                        percentNaoDup = float(\"{0:.2f}\".format(percentNaoDup))\n",
    "\n",
    "                    except ZeroDivisionError:\n",
    "\n",
    "                        with open(logErros, 'a+') as arqLogErros:\n",
    "                            arqLogErros.write('#############################')\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write('Erro, percentNaoDup!')\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"Arquivo: {0}\".format(arq))\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"len(dup): {0} - len(ndup): {1}\".format(len(dup), len(ndup)))\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"k: {0} --> k_dup: {1} - k_ndup: {2}\".format(k, k_dup, k_ndup))\n",
    "                            arqLogErros.write('\\n')\n",
    "                            arqLogErros.write(\"deslz_dup: {0} - deslz_ndup: {1}\".format(deslz_dup, deslz_ndup))\n",
    "                            arqLogErros.write('\\n')\n",
    "                        percentNaoDup = 0\n",
    "        #             print(\"{0}% de nao-duplicatas.\".format(str(percentage2)[:5]))\n",
    "\n",
    "            #             print(\"linhaAtual\")\n",
    "            #             print(linhaAtual)\n",
    "\n",
    "                    da = linhaAtual['da'].item()\n",
    "                    dm = duplicatas + tp_adc\n",
    "                    ndm = nao_duplicatas + tn_adc\n",
    "\n",
    "                    tp = float(linhaAtual['tp'].item() + dm)\n",
    "                    fp = float(linhaAtual['fp'].item())\n",
    "                    tn = float(linhaAtual['tn'].item())# + ndm) #Retirado\n",
    "                    fn = float(linhaAtual['fn'].item() - dm) #Adicionado\n",
    "\n",
    "                    precision = tp/(tp+fp)\n",
    "                    recall = tp/(tp+fn)\n",
    "                    fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "                        #Adicionando valor à última linha\n",
    "                    estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                        'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                        'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais, precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "\n",
    "        #             dirDest = \"../../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\" #COmentei agora, DIego!\n",
    "                #         dirDest = \"../../Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/conjuntosDS/treinoTeste/\"\n",
    "                #         dirDest = \"./arqResult/csv/conjuntosDS/conjuntosDiverg/treinoTeste/\"\n",
    "\n",
    "                        #algUtl = str(algUtl).replace('.0','')\n",
    "                    algUtl = str(algUtl)\n",
    "\n",
    "                    geraTrainSet(conj_treino, dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "                    indicesCT = conj_treino.index.values.tolist()\n",
    "\n",
    "                    indicesDSCRT = conj_descart.index.values.tolist() ##VERIFICAR SE ISSO PROCEDE\n",
    "\n",
    "        #             print(\"ANTES DE GERAR O CONJUNTO GERAL\")\n",
    "\n",
    "        #             print(\"pc_vetores: {0} - conj_treino: {1} - conj_descart: {2}\".format(len(pc_vetores), len(conj_treino), len(conj_descart)))\n",
    "        #             print(\"conj_teste deve ser: {0}\".format((len(pc_vetores) - (len(conj_treino) + len(conj_descart)))))\n",
    "\n",
    "        #             geral = pd.concat([pc_vetores,conj_treino,conj_descart]) #Concatenando pc_vetores e conj_treino\n",
    "                    geral = pd.concat([pc_vetores,conj_treino]) #Concatenando pc_vetores e conj_treino\n",
    "\n",
    "        #             print(\"DEPOIS DE GERAR O CONJUNTO GERAL\")\n",
    "        #             print(\"geral: {0}\".format(len(geral)))\n",
    "\n",
    "                    #Resta para compor o conjunto teste tudo aquilo que está em pc_vetores, mas não em conj_treino\n",
    "                    conj_teste = geral.drop(indicesCT, axis='rows')\n",
    "\n",
    "        #             print(\"DEPOIS DE DROPAR O QUE ESTAVA NO CONJUNTO DE TREINAMENTO\")\n",
    "        #             print(\"conj_teste: {0}\".format(len(conj_teste)))\n",
    "\n",
    "        #             conj_teste = conj_teste.drop(indicesDSCRT, axis='rows') #PQ CARGAS D'ÁGUAS CRIEI ESSA LINHA?\n",
    "\n",
    "        #             print(\"DEPOIS DE DROPAR O QUE ESTAVA NO CONJUNTO DE DESCARTES\")\n",
    "        #             print(\"conj_teste: {0}\".format(len(conj_teste)))\n",
    "                \n",
    "                    geraTestSet(conj_teste, dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "        #             estats_conj = [[algUtl, permutacao, len(conj_treino), percentDup, percentNaoDup,len(conj_teste)]]\n",
    "\n",
    "                    estat_conj.loc[len(estat_conj.index)] = [algUtl, permutacao, len(conj_treino), percentDup, percentNaoDup, len(conj_teste), pode_passar]\n",
    "#                 arq = ''\n",
    "        #     print(\"Estatísticas\")\n",
    "        #     print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "        #     print(conj_treino)\n",
    "\n",
    "            ############################################################################################################################\n",
    "            #Estatísticas\n",
    "            ############################################################################################################################\n",
    "\n",
    "            # if (pode_passar):\n",
    "\n",
    "            ###### Criação do dataframe que armazenará as estatísticas dos conjuntos de treino e teste\n",
    "        #     estat_conj = pd.DataFrame(estat_conj_list, columns=['algoritmosUtilizados','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "\n",
    "        #     estat_conj = estat_conj.append(estat_conj_dic, ignore_index=True)\n",
    "\n",
    "            #Para voltar o dataframe ao normal\n",
    "            estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'etapa', 'permutacao'])\n",
    "\n",
    "            estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "            estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "            estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "        #     dirEst = \"../../csv/\"\n",
    "\n",
    "            # Diretório para Windows\n",
    "            # dirEst = \"C:\\Users\\Diego\\Documents\\NetBeansProjects\\Master-SKYAM\\AS\\src\\csv\\\\\"\n",
    "            # dirEst = \"../../Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/\"CA\n",
    "\n",
    "\n",
    "            # Diretório para Linux\n",
    "            # dirEst = \"./arqResult/csv/\"\n",
    "\n",
    "            estatisticas.to_csv(dirEstat+'estatisticaDS2-DgArj-k'+str(k)+'.csv', sep=';', index=False)   \n",
    "\n",
    "            estat_conj.to_csv(dirEstat+'estatisticasConjuntos-DgArj-k'+str(k)+'.csv', sep=';', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
