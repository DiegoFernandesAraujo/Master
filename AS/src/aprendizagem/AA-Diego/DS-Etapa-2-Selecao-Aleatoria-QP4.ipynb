{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Desconsiderando os registros que possuam grande concordância ou pouquíssima concordância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção aleatória de conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base atual: cd\n",
      "QP atual: qp4\n",
      "Orçamento atual: 50 \n",
      "['diverg(5)93_NEW.csv']\n",
      "diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 93\n",
      "Orçamento atual: 100 \n",
      "['diverg(5)93_NEW.csv']\n",
      "diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 93\n",
      "Ei seu bixim: 100\n",
      "Orçamento atual: 150 \n",
      "['diverg(5)93_NEW.csv']\n",
      "diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 93\n",
      "Quantidade de elementos insuficientes para realizar seleção aleatória!\n",
      "Tamanho de pc_vetores: 100 - Tamanho da amostra: 150\n",
      "Orçamento atual: 200 \n",
      "['diverg(5)93_NEW.csv']\n",
      "diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "Analisando o arquivo: diverg(5)93_NEW.csv\n",
      "##################################################################\n",
      "permutacao: 93\n",
      "Quantidade de elementos insuficientes para realizar seleção aleatória!\n",
      "Tamanho de pc_vetores: 100 - Tamanho da amostra: 200\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "import os, errno\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# nao_passaram = 0\n",
    "# iteracoes = 0\n",
    "\n",
    "############################################################################################################################\n",
    "#Definição de funções\n",
    "############################################################################################################################\n",
    "\n",
    "#Função para geração do conjunto de treinamento\n",
    "def geraTrainSet(ct, dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "        \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)     \n",
    "    \n",
    "#Função para geração do conjunto de teste\n",
    "def geraTestSet(ct, dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)\n",
    "\n",
    "#Função para geração do conjunto de treinamento e teste\n",
    "#caso a seleção aleatória seja maior que o conjunto PC\n",
    "def geraTrainSetVazio(dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "    with open(dir+file1+\".csv\", \"w\") as my_empty_csv:\n",
    "      my_empty_csv.write('ERRO!')\n",
    "    \n",
    "def geraTestSetVazio(dir, file1):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "    with open(dir+file1+\".csv\", \"w\") as my_empty_csv:\n",
    "      my_empty_csv.write('ERRO!')        \n",
    "    \n",
    "    \n",
    "############################\n",
    "\n",
    "#Parâmetros do usuário (Definir entrada dos dados)\n",
    "estat_ord = 'med' #Estatística para ordenamento\n",
    "#qtd_alg = 23 #Quantidade total de algoritmos (Modificado para ser atualizado em cada iteração de acordo com a quantidade máxima de algoritmos em cada experimento)\n",
    "qtd_alg_nd = 2 #Quantidade máxima de algoritmos para separar o conjunto de possíves não-duplicadas\n",
    "# k = 3 #Tamanho da janela\n",
    "# janelas = [2,3,4,5]\n",
    "# janelas = [3] \n",
    "# janelas = [1, 0.01, 0.03, 0.05] # K = {1, 1%, 3%, 5%}\n",
    "janelas = [0.01] #Quando houver a janela vencedora. Após testar as combinações acima\n",
    " #com todas as bases. Lembrando que só deve ser usada para as demais QP além e QP6\n",
    "# orcamentos = [50, 100, 150, 200]\n",
    "orcamentos = [150, 200]\n",
    "tam_min_ct = 20\n",
    "seed = 500\n",
    "# nAlg = 23\n",
    "\n",
    "etapa = '2 - AA[random]'\n",
    "\n",
    "bases = [\"cd\"]\n",
    "qps = [\"qp4\"] #Apenas qp4, na verdade\n",
    "\n",
    "for base in bases:\n",
    "    \n",
    "    print(\"Base atual: {0}\".format(base))\n",
    "    \n",
    "    for qp in qps:\n",
    "        \n",
    "        print(\"QP atual: {0}\".format(qp))\n",
    "\n",
    "\n",
    "        dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAA/\"+base+\"/\"+qp+\"/\"\n",
    "        dirEstat = \"../../csv/estatisticas/\"+base+\"/\"+qp+\"/\"\n",
    "        estat = dirEstat+\"estatisticaDS.csv\"\n",
    "\n",
    "        for orcamento in orcamentos:\n",
    "\n",
    "            dirDest = \"../../csv/conjuntosDS/treinoTeste/\"+base+\"/\"+qp+\"/\"+\"Random-\"+str(orcamento)+\"/\"\n",
    "\n",
    "            print(\"Orçamento atual: {0} \".format(orcamento))\n",
    "\n",
    "            nao_passaram = 0\n",
    "            iteracoes = 0\n",
    "\n",
    "            estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados', 'etapa', 'permutacao'], sep=';')\n",
    "\n",
    "            ###### Criação do dataframe que armazenará as estatísticas dos conjuntos de treino e teste\n",
    "            #   estat_conj = pd.DataFrame (index=['algUtl', 'permutacao'], columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "            estat_conj = pd.DataFrame (columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "\n",
    "\n",
    "            arquivos = [] #Adicionado depois\n",
    "\n",
    "            for _, _, arquivo in os.walk(dirOrig):\n",
    "                arquivos.extend(arquivo)   \n",
    "                \n",
    "            print(arquivos)\n",
    "\n",
    "            for arq in arquivos:\n",
    "                \n",
    "                print(arq)\n",
    "\n",
    "                if ('_NEW' in arq):# & (iteracoes <= 50):\n",
    "#                 if ('diverg(10)1_NEW' in arq): # & (iteracoes <= 0): #Aqui, Diego!\n",
    "#                 if (True): # & (iteracoes <= 0): #Aqui, Diego!\n",
    "                    #         if ('diverg(10)18_NEW' in arq) & (iteracoes <= 0):\n",
    "                    #         if ('diverg(10)18_NEW' in arq) | ('diverg(10)15_NEW' in arq) & (iteracoes <= 1):\n",
    "                    print(\"##################################################################\")\n",
    "                    print(\"Analisando o arquivo: {0}\".format(arq))\n",
    "                    print(\"##################################################################\")\n",
    "\n",
    "                    iteracoes += 1\n",
    "\n",
    "                    num = re.sub(r'diverg.*\\)', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    num = num.replace('_NEW.csv','')\n",
    "\n",
    "                    algUtl = re.sub(r'diverg.*\\(', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    algUtl = re.sub(r'\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "                    algUtl = int(algUtl)\n",
    "\n",
    "                    permutacao = int(num)\n",
    "                    print(\"permutacao: {0}\".format(permutacao))\n",
    "\n",
    "                    linhaAtual = estatisticas.xs((algUtl, '1 - acm diverg', permutacao))    \n",
    "\n",
    "                    ###### Leitura do conjunto de pares conflitantes\n",
    "                    pc = dirOrig+arq\n",
    "                    \n",
    "#                     print(pc)\n",
    "\n",
    "                    pc = pd.read_csv(pc, sep=';', index_col=['elemento1', 'elemento2']) #pares conflitantes\n",
    "\n",
    "                    cols = list(pc.columns.values)\n",
    "                    cols.pop(cols.index('duplicata'))\n",
    "                    pc = pc[['duplicata']+cols]\n",
    "\n",
    "                    pc_aa = pc.iloc[:, :5 ] #Conjunto onde serão aplicadas as janelas deslizantes\n",
    "                    pc_vetores = pc.iloc[:, 5: ] #Conjunto base para compor o conjunto treinamento \n",
    "\n",
    "                    duplicata = pc_aa.loc[:, 'duplicata' ]\n",
    "\n",
    "                    #Adicionando a coluna de duplicatas a pc_vetores\n",
    "                    pc_vetores = pd.concat([duplicata, pc_vetores], axis=1, ignore_index=False)\n",
    "\n",
    "                    #             conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "#                     conj_treino = pc_vetores.sample(orcamento, random_state=500)\n",
    "                    if(len(pc_vetores) == orcamento):\n",
    "        \n",
    "                        print(\"Ei seu bixim: {0}\".format(len(pc_vetores)))\n",
    "        \n",
    "                        estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                        'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                        'fp', 'tn', 'fn'] ] = (['ERRO-Insuf', 1, orcamento,\n",
    "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "                        algUtl = str(algUtl)\n",
    "\n",
    "                        geraTrainSetVazio(dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "                        geraTestSetVazio(dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "                        estat_conj.loc[len(estat_conj.index)] = [algUtl, permutacao, 0, 0, 0, 0]\n",
    "\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    #Apenas para criar o conjunto treino inicialmente\n",
    "                    conj_treino = pc_vetores.sample(10, random_state=500)\n",
    "                    orcamentoAux = orcamento\n",
    "                    \n",
    "                    try:\n",
    "                        #O verdadeiro conj_treino deve ter o valor gerado aqui\n",
    "                        conj_treino = pc_vetores.sample(orcamento, random_state=500)\n",
    "                    except ValueError:\n",
    "                        print(\"Quantidade de elementos insuficientes para realizar seleção aleatória!\")\n",
    "                        print(\"Tamanho de pc_vetores: {0} - Tamanho da amostra: {1}\". format(len(pc_vetores), orcamentoAux))\n",
    "                        \n",
    "                        estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                        'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                        'fp', 'tn', 'fn'] ] = (['ERRO-Insuf', 1, orcamentoAux,\n",
    "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "                        algUtl = str(algUtl)\n",
    "\n",
    "                        geraTrainSetVazio(dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "                        geraTestSetVazio(dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "                        estat_conj.loc[len(estat_conj.index)] = [algUtl, permutacao, 0, 0, 0, 0]\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    iteracao = 1\n",
    "                    inspecoesManuais = orcamento\n",
    "\n",
    "                    duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "                    duplicatas = duplicatas.count(True)\n",
    "                    percentDup = float(duplicatas/float(len(conj_treino))*100)\n",
    "                    percentDup = float(\"{0:.2f}\".format(percentDup))\n",
    "        #             print(\"{0}% de duplicatas.\".format(str(percentage)[:5]))\n",
    "\n",
    "                    nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "                    nao_duplicatas = nao_duplicatas.count(False)\n",
    "                    percentNaoDup = float(nao_duplicatas/float(len(conj_treino))*100)\n",
    "                    percentNaoDup = float(\"{0:.2f}\".format(percentNaoDup))\n",
    "\n",
    "                    abordagem = 'DS'\n",
    "\n",
    "                    da = linhaAtual['da'].item()\n",
    "                    dm = duplicatas\n",
    "                    ndm = nao_duplicatas\n",
    "\n",
    "                    tp = float(linhaAtual['tp'].item() + dm)\n",
    "                    fp = float(linhaAtual['fp'].item())\n",
    "                    tn = float(linhaAtual['tn'].item())# + ndm) #Retirado\n",
    "                    fn = float(linhaAtual['fn'].item() - dm) #Adicionado\n",
    "\n",
    "                    precision = tp/(tp+fp)\n",
    "                    recall = tp/(tp+fn)\n",
    "                    fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "                        #Adicionando valor à última linha\n",
    "                    estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                        'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                        'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais, precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "                        #algUtl = str(algUtl).replace('.0','')\n",
    "                    algUtl = str(algUtl)\n",
    "\n",
    "                    geraTrainSet(conj_treino, dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "                    #Resta para compor o conjunto teste tudo aquilo que está em pc_vetores, mas não em conj_treino\n",
    "                    conj_teste = pc_vetores.loc[pc_vetores.index.difference(conj_treino.index)]\n",
    "                    geraTestSet(conj_teste, dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "                    estat_conj.loc[len(estat_conj.index)] = [algUtl, permutacao, len(conj_treino), percentDup, percentNaoDup, len(conj_teste)]\n",
    "\n",
    "\n",
    "            ############################################################################################################################\n",
    "            #Estatísticas\n",
    "            ############################################################################################################################\n",
    "            #Para voltar o dataframe ao normal\n",
    "            estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'etapa', 'permutacao'])\n",
    "\n",
    "            estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "            estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "            estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "            estatisticas.to_csv(dirEstat+'estatisticaDS2-Random'+str(orcamento)+'.csv', sep=';', index=False)   \n",
    "\n",
    "            estat_conj.to_csv(dirEstat+'estatisticasConjuntos-Random'+str(orcamento)+'.csv', sep=';', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
