{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Desconsiderando os registros que possuam grande concordância ou pouquíssima concordância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificada a ordenação de dup e ndup a fim de fazer com que as janelas deslizem a partir do meio do conjunto todo e assim pegar pares da região de incerteza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orçamento = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficiente de variação <= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_local <= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lançando mão da entropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "Analisando o arquivo: diverg(10)10_NEW.csv\n",
      "##################################################################\n",
      "ANTES DE GERAR O CONJUNTO GERAL\n",
      "pc_vetores: 583 - conj_treino: 62 - conj_descart: 10\n",
      "conj_teste deve ser: 511\n",
      "DEPOIS DE GERAR O CONJUNTO GERAL\n",
      "geral: 655\n",
      "DEPOIS DE DROPAR O QUE ESTAVA NO CONJUNTO DE TREINAMENTO\n",
      "conj_teste: 531\n",
      "DEPOIS DE DROPAR O QUE ESTAVA NO CONJUNTO DE DESCARTES\n",
      "conj_teste: 511\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "from collections import Counter\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# nao_passaram = 0\n",
    "# iteracoes = 0\n",
    "\n",
    "############################################################################################################################\n",
    "#Definição de funções\n",
    "############################################################################################################################\n",
    "\n",
    "#Função para geração do F1 médio\n",
    "def geraF1(toClass, classificador): #toClass é o conjunto de treinamento\n",
    "    \n",
    "    f1 = 0\n",
    "    std = 0\n",
    "    coef_var = 0\n",
    "    \n",
    "    if classificador == 'SVM':\n",
    "        modelo = SVC(random_state = seed)\n",
    "    elif classificador == 'DT':\n",
    "        modelo = DecisionTreeClassifier(random_state = seed)\n",
    "    \n",
    "    #Separação do conjunto X e y\n",
    "    XtoClass = toClass.iloc[:,1:]\n",
    "    ytoClass = toClass.duplicata\n",
    "    \n",
    "    #Divisão dos conjuntos de treino e teste (20% para esse último)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(XtoClass, ytoClass, test_size=0.20, random_state=seed)\n",
    "    \n",
    "    #Validação cruzada\n",
    "    #This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    "    \n",
    "    kfold = KFold(n_splits=5, random_state=seed)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        kfold = StratifiedKFold(n_splits=5, random_state=seed) #Mudar para n-fold #Adicionado depois!\n",
    "        \n",
    "    except ValueError:\n",
    "                \n",
    "        kfold = KFold(n_splits=5, random_state=seed)\n",
    "            \n",
    "    except:\n",
    "        print('Erro com a validação cruzada!')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "        \n",
    "        f1 = cv_results.mean()\n",
    "        std = cv_results.std()\n",
    "        coef_var = std/f1\n",
    "    except:\n",
    "        print(\"ERRO NA VALIDAÇÃO CRUZADA!\")\n",
    "#         print(\"Conjunto de treinamento:\")\n",
    "#         print(toClass)\n",
    "        print(\"Tamanho de toClass: {0}\".format(len(toClass)))\n",
    "        \n",
    "    \n",
    "#     tamTreino = len(XtoClass)\n",
    "    \n",
    "    return f1, std, coef_var#, tamTreino\n",
    "\n",
    "#Função para geração do conjunto de treinamento\n",
    "def geraTrainSet(ct, dir, file1):\n",
    "    \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)     \n",
    "    \n",
    "#Função para geração do conjunto de teste\n",
    "def geraTestSet(ct, dir, file1):\n",
    "    \n",
    "    #Desnecessária essa parte se quiser deixar a primeira coluna com o status das duplicatas\n",
    "    cols = list(ct.columns.values)\n",
    "    cols.pop(cols.index('duplicata'))\n",
    "    ct = ct[cols+['duplicata']]\n",
    "    \n",
    "    ct.to_csv(dir+file1, sep=';', index=False)            \n",
    "    \n",
    "############################################################################################################################\n",
    "#Repetições para os experimentos começam aqui\n",
    "############################################################################################################################\n",
    "\n",
    "#Parâmetros do usuário (Definir entrada dos dados)\n",
    "estat_ord = 'med' #Estatística para ordenamento\n",
    "#qtd_alg = 23 #Quantidade total de algoritmos (Modificado para ser atualizado em cada iteração de acordo com a quantidade máxima de algoritmos em cada experimento)\n",
    "qtd_alg_nd = 2 #Quantidade máxima de algoritmos para separar o conjunto de possíves não-duplicadas\n",
    "# k = 3 #Tamanho da janela\n",
    "# janelas = [2,3,4,5]\n",
    "janelas = [3]\n",
    "orcamento = 200 #Ou uma porcentagem da base de dados\n",
    "orcamento_orig = orcamento\n",
    "tam_min_ct = 20\n",
    "seed = 500\n",
    "# nAlg = 23\n",
    "\n",
    "etapa = '2 - AA[dg-arj]'\n",
    "\n",
    "# dirOrig = \"../../csv/conjuntosDS/conjuntosDiverg/\"\n",
    "# dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAA/\"\n",
    "dirOrig = \"../../csv/conjuntosDS/conjuntosDivergAAMenor/\"\n",
    "estat = \"../../csv/estatisticaInicialDS.csv\"\n",
    "\n",
    "for k in janelas:\n",
    "    \n",
    "    nao_passaram = 0\n",
    "    iteracoes = 0\n",
    "\n",
    "\n",
    "    estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados', 'etapa', 'permutacao'], sep=';')\n",
    "    \n",
    "    ###### Criação do dataframe que armazenará as estatísticas dos conjuntos de treino e teste\n",
    "#   estat_conj = pd.DataFrame (index=['algUtl', 'permutacao'], columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "    estat_conj = pd.DataFrame (columns=['algUtl','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "\n",
    "\n",
    "    arquivos = [] #Adicionado depois\n",
    "\n",
    "    for _, _, arquivo in os.walk(dirOrig):\n",
    "         arquivos.extend(arquivo)   \n",
    "            \n",
    "    for arq in arquivos:\n",
    "\n",
    "#         if ('_NEW' in arq):# & (iteracoes <= 50):\n",
    "        if ('diverg(10)10_NEW' in arq) & (iteracoes <= 0):\n",
    "            print(\"##################################################################\")\n",
    "            print(\"Analisando o arquivo: {0}\".format(arq))\n",
    "            print(\"##################################################################\")\n",
    "\n",
    "            iteracoes += 1\n",
    "\n",
    "            num = re.sub(r'diverg.*\\)', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            num = num.replace('_NEW.csv','')\n",
    "\n",
    "            algUtl = re.sub(r'diverg.*\\(', r'', arq) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = re.sub(r'\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = int(algUtl)\n",
    "\n",
    "            permutacao = int(num)\n",
    "\n",
    "            linhaAtual = estatisticas.xs((algUtl, '1 - acm diverg', permutacao))    \n",
    "\n",
    "            ###### Leitura do conjunto de pares conflitantes\n",
    "            pc = dirOrig+arq\n",
    "\n",
    "            pc = pd.read_csv(pc, sep=';', index_col=['elemento1', 'elemento2']) #pares conflitantes\n",
    "\n",
    "            cols = list(pc.columns.values)\n",
    "            cols.pop(cols.index('duplicata'))\n",
    "            pc = pc[['duplicata']+cols]\n",
    "\n",
    "            pc_aa = pc.iloc[:, :5 ] #Conjunto onde serão aplicadas as janelas deslizantes\n",
    "            pc_vetores = pc.iloc[:, 5: ] #Conjunto base para compor o conjunto treinamento \n",
    "            \n",
    "            #Criação da coluna de ENTROPIA\n",
    "            \n",
    "            #ENTROPIA = −[P+(e) · ln(P+(e)) +P−(e) · ln(P−(e))]\n",
    "\n",
    "            #Onde, P+(e) é a fração de casos positivos identificados pelo comitê (|CASOS_POSITIVOS|/|COMITÊ|).\n",
    "            \n",
    "            #             pc_aa['entropia'] = -(pc_aa['qtdAlg']/nAlg * np.log(pc_aa['qtdAlg']/nAlg) + ((nAlg - pc_aa['qtdAlg'])/nAlg) * np.log((nAlg - pc_aa['qtdAlg'])/nAlg))\n",
    "            pc_aa['entropia'] = -(pc_aa['qtdAlg']/algUtl * np.log(pc_aa['qtdAlg']/algUtl) + ((algUtl - pc_aa['qtdAlg'])/algUtl) * np.log((algUtl - pc_aa['qtdAlg'])/algUtl))\n",
    "\n",
    "            # pc_aa = pc.loc[:, :'med' ]\n",
    "            # pc_vetor = pc.loc[:, 'med': ] #Como referenciar a coluna vizinha à 'med'?\n",
    "\n",
    "            duplicata = pc_aa.loc[:, 'duplicata' ]\n",
    "\n",
    "            #Adicionando a coluna de duplicatas a pc_vetores\n",
    "            pc_vetores = pd.concat([duplicata, pc_vetores], axis=1, ignore_index=False)\n",
    "\n",
    "            ###### \n",
    "\n",
    "            #Separação do conjunto de pares conflitantes em dois a partir da quantidade de algoritmos \n",
    "            #que aponta o par como possível duplicata \n",
    "            #(conjunto A com quantidade de algoritmos = 1, com maioria composta por possíveis não-duplicatas,\n",
    "            #e conjunto B com quantidade de algoritmos > 1, contendo mais possíveis duplicatas que o conjunto A)\n",
    "            ndup = pc_aa.loc[pc['qtdAlg'] <= qtd_alg_nd]\n",
    "            dup = pc_aa.loc[(pc['qtdAlg'] > qtd_alg_nd) & (pc['qtdAlg'] < (algUtl - qtd_alg_nd))]\n",
    "            #dup = pc_aa.loc[(pc['qtdAlg'] > qtd_alg_nd) & (pc['qtdAlg'] < (qtd_alg - qtd_alg_nd))]\n",
    "            # dup = dup[pc['qtdAlg'] <= (qtd_alg - qtd_alg_nd)]\n",
    "\n",
    "            ###### Ordenamento dos pares pela estatística selecionada\n",
    "#             ndup = ndup.sort_values(estat_ord) \n",
    "#             dup = dup.sort_values(estat_ord, ascending=False)\n",
    "            \n",
    "            ###### Ordenamento dos pares pela estatística selecionada \n",
    "            #Modificando a ordenação a fim de fazer com que as janelas deslizem \n",
    "            #a partir do meio do conjunto todo e assim pegar pares da região de incerteza do conjunto todo\n",
    "            ndup = ndup.sort_values(estat_ord, ascending=False) #ndup - pegando do maior para o menor\n",
    "            dup = dup.sort_values(estat_ord) #dup - pegando do menor para o maior \n",
    "\n",
    "            ###### Variáveis para verificar se pode deslizar a janela dentro de dup (ou ndup)\n",
    "\n",
    "            deslz_dup = len(dup)/k\n",
    "            deslz_dup\n",
    "\n",
    "            deslz_ndup = len(ndup)/k\n",
    "            deslz_ndup\n",
    "\n",
    "            ###### Validação do tamanho para deslizamento\n",
    "\n",
    "            #Se não houver espaço suficiente para deslizar as janelas,\n",
    "            #a ponto de formar o conjunto mínimo de treinamento\n",
    "            if (deslz_dup < tam_min_ct/2) | (deslz_ndup < tam_min_ct/2):\n",
    "                pode_passar = False #Teria que ser informado para o usuário definir novo tamanho de janela\n",
    "                print(\"Arquivo: {0} não passou!\".format(arq))\n",
    "                nao_passaram += 1\n",
    "            else:\n",
    "                pode_passar = True\n",
    "     \n",
    "            ###### Criação do dataframe que armazenará o conjunto de treinamento\n",
    "\n",
    "            conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "            \n",
    "            ###### Criação do dataframe que armazenará os pares descartados na etada de max_local\n",
    "            conj_descart = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "            \n",
    "            ###### Povoamento inicial sem aleatoriedade no except\n",
    "\n",
    "            import sys\n",
    "\n",
    "            orcamento = 200\n",
    "            conj_treino = pd.DataFrame(columns=pc_vetores.columns.values)\n",
    "\n",
    "            continua = True\n",
    "            f1_anterior = 0\n",
    "            f1_atual = 0\n",
    "            f1_svm = 0\n",
    "            f1_dt = 0\n",
    "\n",
    "            jan_inic_ndup = 0 \n",
    "            jan_fin_ndup = k\n",
    "\n",
    "            jan_inic_dup = 0 \n",
    "            jan_fin_dup = k\n",
    "\n",
    "            cont = 0\n",
    "\n",
    "            continua = True\n",
    "\n",
    "            if (pode_passar):\n",
    "\n",
    "                #Povoamento inicial com 20 pares rotulados (10 de cada)\n",
    "                while (cont < tam_min_ct) & (continua):\n",
    "\n",
    "    #                 print(\"cont < 20: {0} - continua: {1}\".format(cont < tam_min_ct, continua))\n",
    "\n",
    "    #                 print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_dup, jan_fin_ndup))\n",
    "\n",
    "                    #Desliza-se a janela\n",
    "                    reexecuta = True\n",
    "\n",
    "                    deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "    #                 print(\"reexecuta: {0} - deslz_ndup >= 1: {1}\".format(reexecuta, deslz_ndup >= 1))\n",
    "\n",
    "                    while (reexecuta) & (deslz_ndup >= 1):\n",
    "\n",
    "                        grupo = ndup.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "                        #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                        #Seleciona-se o par com maior valor de similaridade para rotulação\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['min'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "                            #'min' pode ser 'max' ou 'med'\n",
    "                                                        \n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                            #Na verdade a retirada não é feita aqui, mas sim no fim da geração do conj_treino\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_ndup = jan_inic_ndup + k\n",
    "                            jan_fin_ndup = jan_fin_ndup + k\n",
    "\n",
    "                            deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "#                             print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "#                             print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!') #Tentar modificar para imprimir o erro e local de ocorrência\n",
    "\n",
    "    #                 print(\"Possível não-duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                    #Seleciona-se o par com maior entropia (mais conflitante) para rotulação\n",
    "\n",
    "                    deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz_dup >= 1):\n",
    "\n",
    "                        grupo = dup.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('entropia') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "                            print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    #Atualização das janelas\n",
    "                    jan_inic_ndup = jan_inic_ndup + k\n",
    "                    jan_fin_ndup = jan_fin_ndup + k\n",
    "\n",
    "                    jan_inic_dup = jan_inic_dup + k\n",
    "                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                    if(deslz_dup < 1) | (deslz_ndup < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                        continua = False\n",
    "\n",
    "\n",
    "                    cont += 1 #Atualização da variável utilizada para monitorar o tamanho do conjunto de treinamento inicial\n",
    "\n",
    "\n",
    "                #Treina SVM e Decision Tree (justificar o pq) e verifica a média da medida de qualidade (f1, precision...)\n",
    "                f1_svm, std_svm, cv_svm = geraF1(conj_treino, 'SVM')\n",
    "                f1_dt, std_dt, cv_dt = geraF1(conj_treino, 'DT')\n",
    "\n",
    "                f1_atual = (f1_svm + f1_dt)/2\n",
    "                std_atual = (std_svm + std_dt)/2\n",
    "                cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                ###### Aplicação das janelas deslizantes após o povoamento incial sem aleatoriedade no except\n",
    "\n",
    "\n",
    "\n",
    "                # continua = True\n",
    "                max_local = 0\n",
    "                igual = 0\n",
    "\n",
    "    #             print(\"Início\")\n",
    "    #             print(\"orcamento: {0}\".format(orcamento))\n",
    "    #             print(\"Quantidade de itens no conjunto de treinamento: {}\".format(len(conj_treino)))\n",
    "\n",
    "                while continua:\n",
    "\n",
    "                    f1_anterior = f1_atual\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz_ndup >= 1):\n",
    "                        grupo = ndup.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "                        #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                        #Seleciona-se o par com maior valor de similaridade para rotulação\n",
    "                        \n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['min'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_ndup = jan_inic_ndup + k\n",
    "                            jan_fin_ndup = jan_fin_ndup + k\n",
    "\n",
    "                            deslz_ndup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível não-duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                    #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                    deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz_dup >= 1):\n",
    "\n",
    "                        grupo = dup.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor de entropia\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            deslz_dup -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                    f1_svm, std_svm, cv_svm = geraF1(conj_treino, 'SVM')\n",
    "                    f1_dt, std_dt, cv_dt = geraF1(conj_treino, 'DT')\n",
    "\n",
    "                    f1_atual = (f1_svm + f1_dt)/2\n",
    "                    std_atual = (std_svm + std_dt)/2\n",
    "                    cv_atual = (cv_svm + cv_dt)/2 #Coeficiente de variação\n",
    "\n",
    "                    cv_atual = cv_atual*100\n",
    "\n",
    "                    #Atualização das condições de parada\n",
    "                    #depois de selecionar e rotular a possível duplicata e possível não-duplicata\n",
    "                    \n",
    "                    if orcamento > 0 : #Se ainda tem orçamento pra gastar\n",
    "                        #if cv_atual < 10:\n",
    "                        if cv_atual <= 5:\n",
    "                            if (f1_atual >= f1_anterior) and (igual <= 3): #Selecionam-se novos pares para rotulação\n",
    "                                max_local = 0\n",
    "\n",
    "                                if f1_atual == f1_anterior:\n",
    "                                    igual += 1\n",
    "                                elif (f1_atual > f1_anterior) and (igual > 0):\n",
    "                                    igual = 0\n",
    "\n",
    "                                continua = True\n",
    "                            elif (f1_atual < f1_anterior):\n",
    "                                max_local += 1\n",
    "                                igual = 0\n",
    "                                #Se entrar aqui tem que remover os últimos pares que entraram no conjunto de treinamento\n",
    "\n",
    "                                #IMPORTANTE! Fazer com que esses devem sejam extraídos para o conjunto PM, não apenas descartados\n",
    "                                conj_descart = conj_descart.append(conj_treino.tail(2)) #Guardando os vetores a serem retirados do conjunto treinamento\n",
    "                                conj_treino.drop(conj_treino.tail(2).index,inplace=True)\n",
    "\n",
    "#                                 print(\"f1_atual < f1_anterior\")\n",
    "#                                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "#                                 input(\"Pressione ENTER para continuar\")\n",
    "\n",
    "                                if (max_local <= 4):\n",
    "                                    f1_atual = f1_anterior\n",
    "                                else:\n",
    "                                    f1_atual = f1_anterior\n",
    "#                                     print('O f1 passou a piorar')\n",
    "#                                     print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "#                                     input(\"Pressione ENTER para continuar\")\n",
    "                                    continua = False\n",
    "                                    break\n",
    "                            elif (igual > 3): #Se a medida de qualidade for igual à anterior (por três vezes)\n",
    "#                                     print('F1 convergiu!') \n",
    "#                                     input(\"Pressione ENTER para continuar\")\n",
    "                                    continua = False\n",
    "                                    break\n",
    "\n",
    "                    else:\n",
    "                        continua = False\n",
    "                        break\n",
    "\n",
    "                    #Atualização das janelas\n",
    "                    jan_inic_ndup = jan_inic_ndup + k\n",
    "                    jan_fin_ndup = jan_fin_ndup + k\n",
    "\n",
    "                    jan_inic_dup = jan_inic_dup + k\n",
    "                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                    if(deslz_dup < 1) | (deslz_ndup < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                        continua = False\n",
    "\n",
    "    #                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "    #                 print(\"igual: {0}\".format(igual))\n",
    "\n",
    "\n",
    "            else: #Se não pode passar, nesses experimentos, ao invés de solicitar que o usuário\n",
    "                  #determine novo tamanho de janela, é estabelecido um único conjunto por onde\n",
    "                  #as janelas irão deslizar.\n",
    "\n",
    "                print('ENTROU NO ELSE POR NÃO PASSAR')\n",
    "\n",
    "                pc_aa = pc_aa.sort_values(estat_ord) \n",
    "\n",
    "                deslz = len(pc_aa)/k\n",
    "\n",
    "                jan_inic_dup = 0 \n",
    "                jan_fin_dup = k\n",
    "\n",
    "                jan_inic_ndup = len(pc_aa) #Fim de pc_aa\n",
    "                jan_fin_ndup = len(pc_aa) - k\n",
    "\n",
    "\n",
    "                #se a janela final de ndup for menor que a janela final de dup, para\n",
    "\n",
    "                #Povoamento inicial com 20 pares rotulados (10 de cada)\n",
    "                while (cont < tam_min_ct) & (continua) & (jan_fin_dup < jan_fin_ndup):\n",
    "\n",
    "                    #Desliza-se a janela\n",
    "                    reexecuta = True\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "    #                 print(\"reexecuta: {0} - deslz_ndup >= 1: {1}\".format(reexecuta, deslz_ndup >= 1))\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "    #                     grupo = pc_aa.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "                        grupo = pc_aa.iloc[jan_fin_ndup:jan_inic_ndup] # three rows of dataframe\n",
    "\n",
    "                        #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                        #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['min'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            print(grupo)\n",
    "                            jan_inic_ndup = jan_inic_ndup - k\n",
    "                            jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "#                             print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "#                             print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível não-duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                    #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "                        grupo = pc_aa.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            print(grupo)\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            print(\"orcamento: {0} - jan_inic_ndup: {1} - jan_fin_ndup: {2}\".format(orcamento, jan_inic_ndup, jan_fin_ndup))\n",
    "                            print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    #Atualização das janelas\n",
    "                    jan_inic_ndup = jan_inic_ndup - k\n",
    "                    jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                    jan_inic_dup = jan_inic_dup + k\n",
    "                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                    if(deslz < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                        continua = False\n",
    "\n",
    "\n",
    "                    cont += 1\n",
    "\n",
    "\n",
    "                #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                f1_svm, std_svm, cv_svm = geraF1(conj_treino, 'SVM')\n",
    "                f1_dt, std_dt, cv_dt = geraF1(conj_treino, 'DT')\n",
    "\n",
    "                f1_atual = (f1_svm + f1_dt)/2\n",
    "                std_atual = (std_svm + std_dt)/2\n",
    "                cv_atual = (cv_svm + cv_dt)/2\n",
    "\n",
    "                ###### Aplicação das janelas deslizantes após o povoamento incial sem aleatoriedade no except\n",
    "\n",
    "\n",
    "                # continua = True\n",
    "                max_local = 0\n",
    "                igual = 0\n",
    "\n",
    "    #             print(\"Início\")\n",
    "    #             print(\"orcamento: {0}\".format(orcamento))\n",
    "    #             print(\"Quantidade de itens no conjunto de treinamento: {}\".format(len(conj_treino)))\n",
    "\n",
    "                while continua:\n",
    "\n",
    "                    f1_anterior = f1_atual\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz_ndup >= 1):\n",
    "                        grupo = pc_aa.iloc[jan_inic_ndup:jan_fin_ndup] # three rows of dataframe\n",
    "\n",
    "                        #SELEÇÃO DA POSSÍVEL NÃO-DUPLICATA\n",
    "                        #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['min'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False #Se selecionou um registro no comando anterior, não precisa reexecutar o while\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\")\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_ndup = jan_inic_ndup - k\n",
    "                            jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível não-duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    reexecuta = True\n",
    "\n",
    "                    #SELEÇÃO DA POSSÍVEL DUPLICATA\n",
    "                    #Seleciona-se o par com menor quantidade de pares em concordância (talvez selecionar o que teve maior concordância também?) para rotulação\n",
    "\n",
    "                    deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                    while (reexecuta) & (deslz >= 1):\n",
    "\n",
    "                        grupo = pc_aa.iloc[jan_inic_dup:jan_fin_dup] # three rows of dataframe\n",
    "\n",
    "                        try:\n",
    "\n",
    "                            id_row_sel = grupo['entropia'].idxmax() #Retorna o índice da linha com maior valor da coluna ('min') especificada\n",
    "\n",
    "                            #Só passa pra cá se não lançar except\n",
    "                            reexecuta = False\n",
    "                            #Rotula o par, retira do conjunto U (Nesse caso \"pc_vetores\" terá os pares retirados ao final da composição do conjunto de treinamento)\n",
    "                            vetor_sel = pc_vetores.loc[id_row_sel]\n",
    "                            conj_treino = conj_treino.append(vetor_sel) #Adicionando o vetor selecionado ao conjunto treino\n",
    "                            orcamento -= 1\n",
    "\n",
    "                        except ValueError:\n",
    "\n",
    "                            print(\"Atualizando janelas no except\")\n",
    "                            jan_inic_dup = jan_inic_dup + k\n",
    "                            jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                            deslz -= 1 #Deslizou a janela -> Diminuiu o espaço para ela rodar\n",
    "\n",
    "                            reexecuta = True\n",
    "\n",
    "                        except:\n",
    "                            print('Eita!')\n",
    "\n",
    "    #                 print(\"Possível duplicata\")\n",
    "    #                 print(vetor_sel)\n",
    "\n",
    "                    #Treina SVM e Decision Tree (justificar o pq) e verifica-se a média da medida de qualidade (f1, precision...)\n",
    "                    f1_svm, std_svm, cv_svm = geraF1(conj_treino, 'SVM')\n",
    "                    f1_dt, std_dt, cv_dt = geraF1(conj_treino, 'DT')\n",
    "\n",
    "                    f1_atual = (f1_svm + f1_dt)/2\n",
    "                    std_atual = (std_svm + std_dt)/2\n",
    "                    cv_atual = (cv_svm + cv_dt)/2 #Coeficiente de variação\n",
    "\n",
    "                    cv_atual = cv_atual*100\n",
    "\n",
    "\n",
    "                    if orcamento > 0 : #Se ainda tem orçamento pra gastar\n",
    "                        #if cv_atual < 10:\n",
    "                        if cv_atual <= 5:\n",
    "                            if (f1_atual >= f1_anterior) and (igual <= 3): #Selecionam-se novos pares para rotulação\n",
    "                                max_local = 0\n",
    "\n",
    "                                if f1_atual == f1_anterior:\n",
    "                                    igual += 1\n",
    "                                elif (f1_atual > f1_anterior) and (igual > 0):\n",
    "                                    igual = 0\n",
    "\n",
    "                                continua = True\n",
    "                            elif (f1_atual < f1_anterior):\n",
    "                                max_local += 1\n",
    "                                igual = 0\n",
    "                                #Se entrar aqui tem que remover os últimos pares que entraram no conjunto de treinamento\n",
    "\n",
    "                                conj_descart = conj_descart.append(conj_treino.tail(2)) #Guardando os vetores a serem retirados do conjunto treinamento\n",
    "                                conj_treino.drop(conj_treino.tail(2).index,inplace=True)\n",
    "\n",
    "    #                             print(\"f1_atual < f1_anterior\")\n",
    "    #                             print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "\n",
    "                                if (max_local <= 4):\n",
    "                                    f1_atual = f1_anterior\n",
    "                                else:\n",
    "                                    f1_atual = f1_anterior\n",
    "    #                                 print('O f1 passou a piorar')\n",
    "    #                                 print(\"F1 anterior: {0} - F1 atual: {1}\".format(f1_anterior, f1_atual))\n",
    "                                    continua = False\n",
    "                                    break\n",
    "                            elif (igual > 3): #Se a medida de qualidade for igual à anterior (por três vezes)\n",
    "    #                                 print('F1 convergiu!') \n",
    "                                    continua = False\n",
    "                                    break\n",
    "\n",
    "                    else:\n",
    "                        continua = False\n",
    "                        break\n",
    "\n",
    "                    #Atualização das janelas\n",
    "                    jan_inic_ndup = jan_inic_ndup - k\n",
    "                    jan_fin_ndup = jan_fin_ndup - k\n",
    "\n",
    "                    jan_inic_dup = jan_inic_dup + k\n",
    "                    jan_fin_dup = jan_fin_dup + k\n",
    "\n",
    "                    if(deslz < 1): #Se não houver mais espaço para deslizar as janelas\n",
    "                        continua = False\n",
    "\n",
    "\n",
    "                ##### Salvando os arquivos de treino e teste\n",
    "\n",
    "#                 dirDest = \"../../csv/conjuntosDS/treinoTeste/\"\n",
    "\n",
    "            dirDest = \"../../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\"\n",
    "\n",
    "            abordagem = 'DS'\n",
    "        \n",
    "            #Verdadeiros positivos constantes no conjunto de pares descartados\n",
    "            tp_adc = [i for i in conj_descart.duplicata if i == True]\n",
    "            tp_adc = tp_adc.count(True)\n",
    "            \n",
    "            #Verdadeiros negativos constantes no conjunto de pares descartados\n",
    "            tn_adc = [i for i in conj_descart.duplicata if i == False]\n",
    "            tn_adc = tn_adc.count(False)\n",
    "\n",
    "            iteracao = 1\n",
    "            inspecoesManuais = orcamento_orig - orcamento\n",
    "\n",
    "            duplicatas = [i for i in conj_treino.duplicata if i == True]\n",
    "            duplicatas = duplicatas.count(True)\n",
    "            percentDup = float(duplicatas/float(len(conj_treino))*100)\n",
    "            percentDup = float(\"{0:.2f}\".format(percentDup))\n",
    "#             print(\"{0}% de duplicatas.\".format(str(percentage)[:5]))\n",
    "            \n",
    "            nao_duplicatas = [i for i in conj_treino.duplicata if i == False]\n",
    "            nao_duplicatas = nao_duplicatas.count(False)\n",
    "            percentNaoDup = float(nao_duplicatas/float(len(conj_treino))*100)\n",
    "            percentNaoDup = float(\"{0:.2f}\".format(percentNaoDup))\n",
    "#             print(\"{0}% de nao-duplicatas.\".format(str(percentage2)[:5]))\n",
    "\n",
    "    #             print(\"linhaAtual\")\n",
    "    #             print(linhaAtual)\n",
    "\n",
    "            da = linhaAtual['da'].item()\n",
    "            dm = duplicatas + tp_adc\n",
    "            ndm = nao_duplicatas + tn_adc\n",
    "\n",
    "            tp = float(linhaAtual['tp'].item() + dm)\n",
    "            fp = float(linhaAtual['fp'].item())\n",
    "            tn = float(linhaAtual['tn'].item())# + ndm) #Retirado\n",
    "            fn = float(linhaAtual['fn'].item() - dm) #Adicionado\n",
    "\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "                #Adicionando valor à última linha\n",
    "            estatisticas.loc[(algUtl, etapa, permutacao), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais,\n",
    "                precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "\n",
    "            dirDest = \"../../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\"\n",
    "        #         dirDest = \"../../Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/conjuntosDS/treinoTeste/\"\n",
    "        #         dirDest = \"./arqResult/csv/conjuntosDS/conjuntosDiverg/treinoTeste/\"\n",
    "\n",
    "                #algUtl = str(algUtl).replace('.0','')\n",
    "            algUtl = str(algUtl)\n",
    "\n",
    "            geraTrainSet(conj_treino, dirDest, 'train' + '(' + algUtl + ')' + num + '.csv')\n",
    "\n",
    "            indicesCT = conj_treino.index.values.tolist()\n",
    "            \n",
    "            indicesDSCRT = conj_descart.index.values.tolist() ##VERIFICAR SE ISSO PROCEDE\n",
    "\n",
    "            print(\"ANTES DE GERAR O CONJUNTO GERAL\")\n",
    "            \n",
    "#             print(\"Conjunto original: {0}\".format(len(pc)))\n",
    "            \n",
    "            print(\"pc_vetores: {0} - conj_treino: {1} - conj_descart: {2}\".format(len(pc_vetores), len(conj_treino), len(conj_descart)))\n",
    "            print(\"conj_teste deve ser: {0}\".format((len(pc_vetores) - (len(conj_treino) + len(conj_descart)))))\n",
    "            \n",
    "            ##VERIFICAR SE ISSO PROCEDE\n",
    "            geral = pd.concat([pc_vetores,conj_treino,conj_descart]) #Concatenando pc_vetores e conj_treino\n",
    "\n",
    "            print(\"DEPOIS DE GERAR O CONJUNTO GERAL\")\n",
    "            print(\"geral: {0}\".format(len(geral)))\n",
    "            \n",
    "            #Resta para compor o conjunto teste tudo aquilo que está em pc_vetores, mas não em conj_treino\n",
    "            conj_teste = geral.drop(indicesCT, axis='rows')\n",
    "            \n",
    "            print(\"DEPOIS DE DROPAR O QUE ESTAVA NO CONJUNTO DE TREINAMENTO\")\n",
    "            print(\"conj_teste: {0}\".format(len(conj_teste)))\n",
    "            \n",
    "            conj_teste = conj_teste.drop(indicesDSCRT, axis='rows') ##VERIFICAR SE ISSO PROCEDE\n",
    "            \n",
    "            print(\"DEPOIS DE DROPAR O QUE ESTAVA NO CONJUNTO DE DESCARTES\")\n",
    "            print(\"conj_teste: {0}\".format(len(conj_teste)))\n",
    "\n",
    "            geraTestSet(conj_teste, dirDest, 'test' + '(' + algUtl + ')' + num + '.csv')\n",
    "            \n",
    "#             estats_conj = [[algUtl, permutacao, len(conj_treino), percentDup, percentNaoDup,len(conj_teste)]]\n",
    "            \n",
    "            estat_conj.loc[len(estat_conj.index)] = [algUtl, permutacao, len(conj_treino), percentDup, percentNaoDup, len(conj_teste)]\n",
    "\n",
    "#     print(\"Estatísticas\")\n",
    "#     print(\"orcamento: {0} - jan_inic_dup: {1} - jan_fin_dup: {2}\".format(orcamento, jan_inic_dup, jan_fin_dup))\n",
    "#     print(conj_treino)\n",
    "\n",
    "    ############################################################################################################################\n",
    "    #Estatísticas\n",
    "    ############################################################################################################################\n",
    "\n",
    "    # if (pode_passar):\n",
    "    \n",
    "    ###### Criação do dataframe que armazenará as estatísticas dos conjuntos de treino e teste\n",
    "#     estat_conj = pd.DataFrame(estat_conj_list, columns=['algoritmosUtilizados','permutacao','tamConjTreino','prctgDup','prctgNaoDup','tamConjTeste'])\n",
    "    \n",
    "#     estat_conj = estat_conj.append(estat_conj_dic, ignore_index=True)\n",
    "    \n",
    "    #Para voltar o dataframe ao normal\n",
    "    estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'etapa', 'permutacao'])\n",
    "\n",
    "    estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "    dirEst = \"../../csv/\"\n",
    "\n",
    "    # Diretório para Windows\n",
    "    # dirEst = \"C:\\Users\\Diego\\Documents\\NetBeansProjects\\Master-SKYAM\\AS\\src\\csv\\\\\"\n",
    "    # dirEst = \"../../Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/\"\n",
    "\n",
    "\n",
    "    # Diretório para Linux\n",
    "    # dirEst = \"./arqResult/csv/\"\n",
    "\n",
    "    estatisticas.to_csv(dirEst+'estatisticaInicialDS2-DgArj-k'+str(k)+'.csv', sep=';', index=False)   \n",
    "    \n",
    "    estat_conj.to_csv(dirEst+'estatisticasConjuntos-DgArj-k'+str(k)+'.csv', sep=';', index=False)   \n",
    "\n",
    "    if(iteracoes >= 3000):\n",
    "\n",
    "        print(\"Não passaram: {0}\".format(nao_passaram))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
