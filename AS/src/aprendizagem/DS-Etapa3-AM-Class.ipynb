{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Arquivos atuais: train(10)1.csv e test(10)1.csv\n",
      "Iteração: 1\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "RFC com hiperparâmetros tunados: F1 = 0.759762 com desvio padrão = 0.169822\n",
      "[[128   6]\n",
      " [  3 167]]\n",
      "tn, fp, fn, tp\n",
      "128 6 3 167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.96      0.97       134\n",
      "        1.0       0.97      0.98      0.97       170\n",
      "\n",
      "avg / total       0.97      0.97      0.97       304\n",
      "\n",
      "precision: 0.96532\n",
      "recall: 0.98235\n",
      "f1: 0.97376\n",
      "non-matches: 134 - matches: 170\n",
      "\n",
      "tp é igual a: 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos atuais: train(10)10.csv e test(10)10.csv\n",
      "Iteração: 2\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-32ece9a2234c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%s_macro'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Melhor conjunto de hiperparâmetros encontrado:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 316\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0m_set_random_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[1;34m(estimator, random_state)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mto_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"always\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\warnings.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters_mutated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showwarning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowwarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "dirOrig = \"../csv/conjuntosDS/treinoTeste/\"\n",
    "# dirOrig = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/conjuntosDS/treinoTeste/\"\n",
    "# dirOrig = \"../arqResult/csv/conjuntosDS/conjuntosDiverg/treinoTeste/\"\n",
    "estat = \"../csv/estatisticaInicialDS2.csv\"\n",
    "# estat = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/estatisticaInicialDS2.csv\"\n",
    "# estat = \"../arqResult/csv/estatisticaInicialDS2.csv\"\n",
    "\n",
    "etapa = '3 - clasf'\n",
    "\n",
    "# estatisticas = pd.read_csv(estat, index_col=['etapa','permutacao'], sep=';')\n",
    "estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados','permutacao','etapa'], sep=';')\n",
    "# estatisticas.tail()\n",
    "\n",
    "arquivos = os.listdir(dirOrig)\n",
    "# print(arquivos)\n",
    "#print(len(arquivos))\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for arq in arquivos:\n",
    "    if arq.startswith(\"train\"):\n",
    "        train.append(arq)\n",
    "    elif arq.startswith(\"test\"):\n",
    "        test.append(arq)\n",
    "        \n",
    "# print('tamanho de train: %d' %(len(train)))        \n",
    "\n",
    "# print('tamanho de test: %d' %(len(test)))\n",
    "\n",
    "# print (train)    \n",
    "# print (test)    \n",
    "\n",
    "\n",
    "\n",
    "#lista = ['10', '15', '20', '25'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "lista = ['10', '15', '20'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "# lista = ['10'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "# lista = ['3'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "\n",
    "for i in lista: \n",
    "    \n",
    "    cont = 0\n",
    "    \n",
    "    trainAtual = []\n",
    "    testAtual = []\n",
    "    \n",
    "    for arq in train:\n",
    "        if '('+i+')' in arq:\n",
    "            trainAtual.append(arq)\n",
    "    for arq in test:\n",
    "        if '('+i+')' in arq:\n",
    "            testAtual.append(arq)\n",
    "    \n",
    "#     print('lista desordenada')\n",
    "#     print(trainAtual)\n",
    "    \n",
    "#     print('tamanho antes: %d' %(len(trainAtual)))\n",
    "    \n",
    "    #Ordenando a lista\n",
    "    trainAtual = sorted(trainAtual)\n",
    "    testAtual = sorted(testAtual)\n",
    "    \n",
    "#     for x in trainAtual:\n",
    "#         print(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "# #     print('lista ordenada')\n",
    "# #     print(trainAtual)\n",
    "    \n",
    "#     print('tamanho depois: %d' %(len(trainAtual)))\n",
    "    \n",
    "#     print(type(trainAtual))\n",
    "\n",
    "    \n",
    "    print (i)\n",
    "    \n",
    "#     print(trainAtual)\n",
    "#     print(testAtual)\n",
    "    \n",
    "    tam = len(trainAtual) #Mesma coisa para testAtual\n",
    "    \n",
    "    for pos in range(tam):\n",
    "#         print(pos)\n",
    "        print('Arquivos atuais: %s e %s' %(trainAtual[pos], testAtual[pos]))\n",
    "        \n",
    "        treino = dirOrig+trainAtual[pos]\n",
    "        teste = dirOrig+testAtual[pos]\n",
    "        \n",
    "#         print('treino: %s' %(treino))\n",
    "\n",
    "#         tp, fp, tn, fn = 0\n",
    "        \n",
    "        num = trainAtual[pos].replace('train('+i+')','')\n",
    "        num = num.replace('.csv','')\n",
    "        \n",
    "        cont += 1\n",
    "        \n",
    "        print('Iteração: %d' %(cont))\n",
    "        \n",
    "#         print('num: %s' %(num))\n",
    "        \n",
    "        algUtl = re.sub('train.*\\(', r'', trainAtual[pos]) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "        algUtl = re.sub('\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "        algUtl = int(algUtl)\n",
    "        \n",
    "        \n",
    "#         print('algUtl: %d' %(algUtl))\n",
    "        \n",
    "        permutacao = int(num)\n",
    "        #linhaAtual = estatisticas.loc[('2 - AA[pet-chr]', permutacao), : ] #Armazena a linha correspondente à permutação\n",
    "#         linhaAtual = estatisticas.loc[('1 - acm diverg', permutacao), : ] #Armazena a linha correspondente à permutação\n",
    "        linhaAtual = estatisticas.loc[algUtl, permutacao,'2 - AA[pet-chr]', : ] #Armazena a linha correspondente à permutação\n",
    "#         print (linhaAtual)\n",
    "#         print(linhaAtual.columns)\n",
    "\n",
    "    #'''\n",
    "#         all = pd.read_csv(\"train.csv\", index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "#         toClass = pd.read_csv(\"test.csv\", index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "        \n",
    "#         all = pd.read_csv(treino, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "#         toClass = pd.read_csv(teste, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "\n",
    "        all = pd.read_csv(treino, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'track10', 'track11', 'duplicata'), header = 0) #Era header = None\n",
    "        toClass = pd.read_csv(teste, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'track10', 'track11', 'duplicata'), header = 0) #Era header = None\n",
    "\n",
    "\n",
    "        # all['artist-title'] = all['artist'] * all['title']\n",
    "        # cols = list(all.columns.values)\n",
    "        # cols.pop(cols.index('duplicata'))\n",
    "        # all = all[cols+['duplicata']]\n",
    "\n",
    "        #Pesos baseados no Alg17\n",
    "\n",
    "        all['artist-title'] = all['artist'] * all['title']\n",
    "        all['soma-pesos'] = (all['artist']*1 + all['title']*2 + all['track01']*0.8 + all['track02']*0.8)/4.6\n",
    "        cols = list(all.columns.values)\n",
    "        cols.pop(cols.index('duplicata'))\n",
    "        all = all[cols+['duplicata']]\n",
    "\n",
    "        # toClass['artist-title'] = toClass['artist'] * toClass['title']\n",
    "        # cols = list(toClass.columns.values)\n",
    "        # cols.pop(cols.index('duplicata'))\n",
    "        # toClass = toClass[cols+['duplicata']]\n",
    "\n",
    "        #Pesos baseados no Alg17\n",
    "\n",
    "        toClass['artist-title'] = toClass['artist'] * toClass['title']\n",
    "        toClass['soma-pesos'] = (toClass['artist']*1 + toClass['title']*2 + toClass['track01']*0.8 + toClass['track02']*0.8)/4.6\n",
    "        cols = list(toClass.columns.values)\n",
    "        cols.pop(cols.index('duplicata'))\n",
    "        toClass = toClass[cols+['duplicata']]\n",
    "\n",
    "        #Separação do conjunto X do conjunto y\n",
    "        # X = all.loc[:,'title':'artist-title']\n",
    "        X = all.loc[:,'title':'soma-pesos']\n",
    "        y = all.duplicata\n",
    "\n",
    "        # XtoClass = toClass.loc[:,'title':'artist-title']\n",
    "        XtoClass = toClass.loc[:,'title':'soma-pesos']\n",
    "        ytoClass = toClass.duplicata\n",
    "\n",
    "        from sklearn import model_selection\n",
    "\n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        from sklearn.model_selection import KFold\n",
    "        from sklearn import model_selection\n",
    "        \n",
    "        seed = 500\n",
    "\n",
    "        '''\n",
    "        \n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.svm import SVC\n",
    "\n",
    "        modelos = []\n",
    "        modelos.append(('LR', LogisticRegression()))\n",
    "        modelos.append(('KNN', KNeighborsClassifier()))\n",
    "        modelos.append(('DTC', DecisionTreeClassifier()))\n",
    "        modelos.append(('SVM', SVC()))\n",
    "        modelos.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "        \n",
    "\n",
    "        # Avaliação de cada modelo por vez\n",
    "        resultados = []\n",
    "        nomes = []\n",
    "        for nome, modelo in modelos:\n",
    "            kfold = StratifiedKFold(n_splits=10, random_state=seed) #Mudar para n-fold\n",
    "            cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "            msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std()) #Iprimir em um arquivo\n",
    "            print(msg)\n",
    "        '''\n",
    "        \n",
    "        dtc = RandomForestClassifier(random_state=12)\n",
    "\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "        param_grid = [{\"criterion\": ['gini', 'entropy'],\"n_estimators\": [10,25,30,35,40,45,50,100],\n",
    "                       #\"max_depth\": [2,3,4,5,6,7],\n",
    "                      \"class_weight\": [\"balanced\",None],\n",
    "                      \"min_samples_split\": [2, 5, 10]}]\n",
    "\n",
    "        score = 'f1'\n",
    "\n",
    "        print(\"# Tunando hiperparâmetros para %s\" % score)\n",
    "        print()\n",
    "\n",
    "        grid = GridSearchCV(dtc, param_grid, cv=5, scoring='%s_macro' % score)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Melhor conjunto de hiperparâmetros encontrado:\")\n",
    "        print()\n",
    "        print(grid.best_params_)\n",
    "        # print()\n",
    "        # print(\"Grade de valores encontrados:\")\n",
    "        # print()\n",
    "        medias = grid.cv_results_['mean_test_score']\n",
    "        desvios = grid.cv_results_['std_test_score']\n",
    "        # for media, desvio, params in zip(medias, desvios, grid.cv_results_['params']):\n",
    "        #     print(\"%0.3f (+/-%0.03f) for %r\" % (media, desvio * 2, params))\n",
    "        #     print()\n",
    "\n",
    "        rfc = RandomForestClassifier(**grid.best_params_, random_state=500)\n",
    "\n",
    "#         rfc = RandomForestClassifier(parameters = grid.best_params_, random_state=12)\n",
    "\n",
    "        kfold = KFold(n_splits=10, random_state=seed)\n",
    "    \n",
    "        try:\n",
    "    \n",
    "            kfold = StratifiedKFold(n_splits=10, random_state=seed) #Mudar para n-fold #Adicionado depois!\n",
    "        \n",
    "        except ValueError:\n",
    "                \n",
    "            kfold = KFold(n_splits=10, random_state=seed)\n",
    "            \n",
    "        except:\n",
    "            print('Erro com o arquivo: ' + treino)\n",
    "\n",
    "        cv_results2 = model_selection.cross_val_score(rfc, X_train, y_train, cv=kfold, scoring='f1')\n",
    "        msg = \"%s com hiperparâmetros tunados: F1 = %f com desvio padrão = %f\" % ('RFC', cv_results2.mean(), cv_results2.std())\n",
    "        print(msg)\n",
    "\n",
    "        rfc.fit(X_train, y_train)\n",
    "        predicoes = rfc.predict(X_test)\n",
    "\n",
    "#         from sklearn.metrics import confusion_matrix\n",
    "#         matriz = confusion_matrix(y_test, predicoes)\n",
    "\n",
    "#         print(matriz)\n",
    "\n",
    "        from sklearn.metrics import classification_report\n",
    "        from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "        # print(classification_report(y_test, predicoes))\n",
    "#         prec, rec, fbeta, supp = precision_recall_fscore_support(y_test, predicoes, average=None)\n",
    "#         print ('precision: %.5f' %(prec[1]))\n",
    "#         print ('recall: %.5f' %(rec[1]))\n",
    "#         print ('f1: %.5f' %(fbeta[1]))\n",
    "#         print ('non-matches: %d - matches: %d' %(supp[0], supp[1]))\n",
    "#         print('')\n",
    "\n",
    "        # from sklearn.externals.six import StringIO  \n",
    "        # from IPython.display import Image  \n",
    "        # from sklearn.tree import export_graphviz\n",
    "        # import pydotplus\n",
    "        # dot_data = StringIO()\n",
    "        # export_graphviz(rfc, out_file=dot_data,  \n",
    "        #                 filled=True, rounded=True,\n",
    "        #                 special_characters=True, feature_names=X.columns)\n",
    "        # graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "        # Image(graph.create_png())\n",
    "\n",
    "        predicoes = rfc.predict(XtoClass)\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        matriz = confusion_matrix(ytoClass, predicoes)\n",
    "        print(matriz)\n",
    "        \n",
    "        this_tn, this_fp, this_fn, this_tp = 0, 0, 0, 0\n",
    "        \n",
    "        this_tn, this_fp, this_fn, this_tp = confusion_matrix(ytoClass, predicoes).ravel()\n",
    "        print('tn, fp, fn, tp')\n",
    "        print(this_tn, this_fp, this_fn, this_tp)\n",
    "\n",
    "\n",
    "\n",
    "        from sklearn.metrics import classification_report\n",
    "        from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "        print(classification_report(ytoClass, predicoes))\n",
    "        prec, rec, fbeta, supp = precision_recall_fscore_support(ytoClass, predicoes, average=None)\n",
    "        print ('precision: %.5f' %(prec[1]))\n",
    "        print ('recall: %.5f' %(rec[1]))\n",
    "        print ('f1: %.5f' %(fbeta[1]))\n",
    "        print ('non-matches: %d - matches: %d' %(supp[0], supp[1]))\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        #Atualizar as estatísticas\n",
    "        abordagem = 'DS'\n",
    "        #print 'abordagem é %s' %(abordagem)\n",
    "        \n",
    "        #algUtl = linhaAtual['algoritmosUtilizados'].item()\n",
    "        iteracao = 2\n",
    "        inspecoesManuais = linhaAtual['inspecoesManuais'].item()\n",
    "        da = linhaAtual['da'].item() + (this_tp + this_fp) #Adiciona todos os casos positivos identificados\n",
    "        dm = linhaAtual['dm'].item()             #na predição\n",
    "        ndm = linhaAtual['ndm'].item()\n",
    "        \n",
    "        \n",
    "        fn = float(linhaAtual['fn'].item() - this_tp ) #Não tenho certeza se é isso\n",
    "        tp = this_tp + float(linhaAtual['tp'].item()) #+ dm) #Recuperar de toClass\n",
    "        print('tp é igual a: %d' %(tp))\n",
    "        \n",
    "        fp = this_fp + float(linhaAtual['fp'].item())\n",
    "        #tn = tn + float(linhaAtual['tn'].item() - tp) #+ ndm) #Recuperar de toClass\n",
    "        tn = (9762 * 9763) / 2 -(tp+fp+fn)\n",
    "        \n",
    "        \n",
    "        \n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "        #Adicionando valor à última linha\n",
    "#         estatisticas.loc[(etapa, permutacao), ['abordagem', 'algoritmosUtilizados', 'iteracao', 'inspecoesManuais',\n",
    "#            'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "#            'fp', 'tn', 'fn'] ] = ([abordagem, algUtl, iteracao, inspecoesManuais,\n",
    "#            precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "        estatisticas.loc[(algUtl, permutacao, etapa), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "            'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "            'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais,\n",
    "            precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "    \n",
    "        #'''\n",
    "\n",
    "# estatisticas = estatisticas.reset_index(level=['etapa', 'permutacao'])\n",
    "estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'permutacao', 'etapa'])\n",
    "# estatisticas.head()                   \n",
    "#                    \n",
    "\n",
    "estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "dirEst = \"../csv/\"\n",
    "# dirEst = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/\"\n",
    "# dirEst = \"../arqResult/csv/\"\n",
    "\n",
    "\n",
    "estatisticas.to_csv(dirEst+'estatisticaInicialDS3.csv', sep=';', index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
