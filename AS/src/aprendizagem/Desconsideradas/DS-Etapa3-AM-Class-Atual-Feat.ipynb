{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../csv/conjuntosDS/treinoTeste-k3/\n",
      "10\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)10.csv e test(10)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 35}\n",
      "[[368   7]\n",
      " [ 13 145]]\n",
      "tn, fp, fn, tp\n",
      "368 7 13 145\n",
      "tp é igual a: 242\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)11.csv e test(10)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 10}\n",
      "[[786   7]\n",
      " [ 20  94]]\n",
      "tn, fp, fn, tp\n",
      "786 7 20 94\n",
      "tp é igual a: 244\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)12.csv e test(10)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 25}\n",
      "[[468  66]\n",
      " [  4 164]]\n",
      "tn, fp, fn, tp\n",
      "468 66 4 164\n",
      "tp é igual a: 260\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)13.csv e test(10)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 10}\n",
      "[[339  19]\n",
      " [  4 161]]\n",
      "tn, fp, fn, tp\n",
      "339 19 4 161\n",
      "tp é igual a: 246\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)14.csv e test(10)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 35}\n",
      "[[463  11]\n",
      " [ 18 153]]\n",
      "tn, fp, fn, tp\n",
      "463 11 18 153\n",
      "tp é igual a: 238\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)15.csv e test(10)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 10}\n",
      "[[342  59]\n",
      " [  5 185]]\n",
      "tn, fp, fn, tp\n",
      "342 59 5 185\n",
      "tp é igual a: 249\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)16.csv e test(10)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 25}\n",
      "[[ 13  21]\n",
      " [  0 162]]\n",
      "tn, fp, fn, tp\n",
      "13 21 0 162\n",
      "tp é igual a: 248\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)17.csv e test(10)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[232   7]\n",
      " [ 50 130]]\n",
      "tn, fp, fn, tp\n",
      "232 7 50 130\n",
      "tp é igual a: 212\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)18.csv e test(10)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[ 10 511]\n",
      " [ 36 139]]\n",
      "tn, fp, fn, tp\n",
      "10 511 36 139\n",
      "tp é igual a: 228\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)19.csv e test(10)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[322  14]\n",
      " [  4 149]]\n",
      "tn, fp, fn, tp\n",
      "322 14 4 149\n",
      "tp é igual a: 240\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)20.csv e test(10)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[639   9]\n",
      " [ 10 134]]\n",
      "tn, fp, fn, tp\n",
      "639 9 10 134\n",
      "tp é igual a: 245\n",
      "15\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)10.csv e test(15)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 10}\n",
      "[[704  18]\n",
      " [ 19 180]]\n",
      "tn, fp, fn, tp\n",
      "704 18 19 180\n",
      "tp é igual a: 238\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)11.csv e test(15)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 35}\n",
      "[[139   7]\n",
      " [ 18 152]]\n",
      "tn, fp, fn, tp\n",
      "139 7 18 152\n",
      "tp é igual a: 243\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)12.csv e test(15)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[804   9]\n",
      " [ 33 156]]\n",
      "tn, fp, fn, tp\n",
      "804 9 33 156\n",
      "tp é igual a: 232\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)13.csv e test(15)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 35}\n",
      "[[528  10]\n",
      " [ 22 180]]\n",
      "tn, fp, fn, tp\n",
      "528 10 22 180\n",
      "tp é igual a: 243\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)14.csv e test(15)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 10}\n",
      "[[390  50]\n",
      " [ 15 180]]\n",
      "tn, fp, fn, tp\n",
      "390 50 15 180\n",
      "tp é igual a: 242\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)15.csv e test(15)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 25}\n",
      "[[750  10]\n",
      " [ 15 175]]\n",
      "tn, fp, fn, tp\n",
      "750 10 15 175\n",
      "tp é igual a: 249\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)16.csv e test(15)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[636   7]\n",
      " [ 21 145]]\n",
      "tn, fp, fn, tp\n",
      "636 7 21 145\n",
      "tp é igual a: 237\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)17.csv e test(15)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "[[468  21]\n",
      " [ 16 172]]\n",
      "tn, fp, fn, tp\n",
      "468 21 16 172\n",
      "tp é igual a: 243\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)18.csv e test(15)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 30}\n",
      "[[697   8]\n",
      " [ 12 155]]\n",
      "tn, fp, fn, tp\n",
      "697 8 12 155\n",
      "tp é igual a: 246\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)19.csv e test(15)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[818   6]\n",
      " [ 25 158]]\n",
      "tn, fp, fn, tp\n",
      "818 6 25 158\n",
      "tp é igual a: 239\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)20.csv e test(15)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[805  19]\n",
      " [ 12 165]]\n",
      "tn, fp, fn, tp\n",
      "805 19 12 165\n",
      "tp é igual a: 253\n",
      "20\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)10.csv e test(20)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 45}\n",
      "[[781  13]\n",
      " [  7 157]]\n",
      "tn, fp, fn, tp\n",
      "781 13 7 157\n",
      "tp é igual a: 259\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)11.csv e test(20)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 25}\n",
      "[[811  20]\n",
      " [ 11 174]]\n",
      "tn, fp, fn, tp\n",
      "811 20 11 174\n",
      "tp é igual a: 254\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)12.csv e test(20)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[704   9]\n",
      " [ 12 159]]\n",
      "tn, fp, fn, tp\n",
      "704 9 12 159\n",
      "tp é igual a: 246\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)13.csv e test(20)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[779  10]\n",
      " [ 30 156]]\n",
      "tn, fp, fn, tp\n",
      "779 10 30 156\n",
      "tp é igual a: 235\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)14.csv e test(20)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[838  13]\n",
      " [ 30 157]]\n",
      "tn, fp, fn, tp\n",
      "838 13 30 157\n",
      "tp é igual a: 236\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)15.csv e test(20)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[744  82]\n",
      " [  7 189]]\n",
      "tn, fp, fn, tp\n",
      "744 82 7 189\n",
      "tp é igual a: 259\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)16.csv e test(20)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[748   8]\n",
      " [ 39 156]]\n",
      "tn, fp, fn, tp\n",
      "748 8 39 156\n",
      "tp é igual a: 226\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)17.csv e test(20)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[579  24]\n",
      " [ 19 179]]\n",
      "tn, fp, fn, tp\n",
      "579 24 19 179\n",
      "tp é igual a: 247\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)18.csv e test(20)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_split': 10, 'n_estimators': 25}\n",
      "[[688  20]\n",
      " [ 11 168]]\n",
      "tn, fp, fn, tp\n",
      "688 20 11 168\n",
      "tp é igual a: 247\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)19.csv e test(20)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 50}\n",
      "[[719  10]\n",
      " [ 19 165]]\n",
      "tn, fp, fn, tp\n",
      "719 10 19 165\n",
      "tp é igual a: 240\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)20.csv e test(20)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 25}\n",
      "[[810  14]\n",
      " [ 16 180]]\n",
      "tn, fp, fn, tp\n",
      "810 14 16 180\n",
      "tp é igual a: 249\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# janelas = [2,3,4,5]\n",
    "janelas = [3]\n",
    "\n",
    "for k in janelas:\n",
    "\n",
    "    abordagemAA = '2 - AA[dg-arj]' #'2 - AA[pet-chr]' ou '2 - AA[dg-arj]'\n",
    "    dirOrig = \"../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\"\n",
    "    # dirOrig = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/conjuntosDS/treinoTeste/\"\n",
    "    # dirOrig = \"../arqResult/csv/conjuntosDS/conjuntosDiverg/treinoTeste/\"\n",
    "    # estat = \"../csv/estatisticaInicialDS2.csv\"\n",
    "    estat = \"../csv/estatisticaInicialDS2-DgArj-k\"+str(k)+\".csv\"\n",
    "    # estat = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/estatisticaInicialDS2.csv\"\n",
    "    # estat = \"../arqResult/csv/estatisticaInicialDS2.csv\"\n",
    "\n",
    "    print(dirOrig)\n",
    "    \n",
    "    etapa = '3 - clasf'\n",
    "\n",
    "    # estatisticas = pd.read_csv(estat, index_col=['etapa','permutacao'], sep=';')\n",
    "    estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados','permutacao','etapa'], sep=';')\n",
    "#     estatisticas.tail()\n",
    "\n",
    "    arquivos = os.listdir(dirOrig)\n",
    "    # print(arquivos)\n",
    "    #print(len(arquivos))\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for arq in arquivos:\n",
    "        if arq.startswith(\"train\"):\n",
    "            train.append(arq)\n",
    "        elif arq.startswith(\"test\"):\n",
    "            test.append(arq)\n",
    "\n",
    "    # print('tamanho de train: %d' %(len(train)))        \n",
    "\n",
    "    # print('tamanho de test: %d' %(len(test)))\n",
    "\n",
    "    # print (train)    \n",
    "    # print (test)    \n",
    "\n",
    "\n",
    "\n",
    "    #lista = ['10', '15', '20', '25'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "    lista = ['10', '15', '20'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "#     lista = ['10'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "    # lista = ['3'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "\n",
    "    for i in lista: \n",
    "\n",
    "        cont = 0\n",
    "\n",
    "        trainAtual = []\n",
    "        testAtual = []\n",
    "\n",
    "        for arq in train:\n",
    "            if '('+i+')' in arq:\n",
    "#             if 'train(10)22' in arq:    \n",
    "                trainAtual.append(arq)\n",
    "        for arq in test:\n",
    "            if '('+i+')' in arq:\n",
    "#             if 'test(10)22' in arq:\n",
    "                testAtual.append(arq)\n",
    "\n",
    "    #     print('lista desordenada')\n",
    "    #     print(trainAtual)\n",
    "\n",
    "    #     print('tamanho antes: %d' %(len(trainAtual)))\n",
    "\n",
    "        #Ordenando a lista\n",
    "        trainAtual = sorted(trainAtual)\n",
    "        testAtual = sorted(testAtual)\n",
    "\n",
    "    #     for x in trainAtual:\n",
    "    #         print(x)\n",
    "\n",
    "\n",
    "\n",
    "    # #     print('lista ordenada')\n",
    "    # #     print(trainAtual)\n",
    "\n",
    "    #     print('tamanho depois: %d' %(len(trainAtual)))\n",
    "\n",
    "    #     print(type(trainAtual))\n",
    "\n",
    "\n",
    "        print (i)\n",
    "\n",
    "    #     print(trainAtual)\n",
    "    #     print(testAtual)\n",
    "\n",
    "        tam = len(trainAtual) #Mesma coisa para testAtual\n",
    "\n",
    "        for pos in range(tam):\n",
    "    #         print(pos)\n",
    "            print('')\n",
    "            print('##########################')\n",
    "            print('Arquivos atuais: %s e %s' %(trainAtual[pos], testAtual[pos]))\n",
    "            print('##########################')\n",
    "\n",
    "            treino = dirOrig+trainAtual[pos]\n",
    "            teste = dirOrig+testAtual[pos]\n",
    "\n",
    "    #         print('treino: %s' %(treino))\n",
    "\n",
    "    #         tp, fp, tn, fn = 0\n",
    "\n",
    "            num = trainAtual[pos].replace('train('+i+')','')\n",
    "            num = num.replace('.csv','')\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "            print('Iteração: %d' %(cont))\n",
    "\n",
    "    #         print('num: %s' %(num))\n",
    "\n",
    "            algUtl = re.sub('train.*\\(', r'', trainAtual[pos]) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = re.sub('\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = int(algUtl)\n",
    "\n",
    "\n",
    "            print('algUtl: %d' %(algUtl))\n",
    "\n",
    "            permutacao = int(num)\n",
    "    #         linhaAtual = estatisticas.loc[('2 - AA[pet-chr]', permutacao), : ] #Armazena a linha correspondente à permutação\n",
    "    #         linhaAtual = estatisticas.loc[('1 - acm diverg', permutacao), : ] #Armazena a linha correspondente à permutação\n",
    "            linhaAtual = estatisticas.loc[algUtl, permutacao, abordagemAA, : ] #Armazena a linha correspondente à permutação\n",
    "#             print (linhaAtual)\n",
    "#             print(linhaAtual.columns)\n",
    "\n",
    "        #'''\n",
    "    #         all = pd.read_csv(\"train.csv\", index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "    #         toClass = pd.read_csv(\"test.csv\", index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "\n",
    "    #         all = pd.read_csv(treino, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "    #         toClass = pd.read_csv(teste, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "\n",
    "            all = pd.read_csv(treino, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'track10', 'track11', 'duplicata'), header = 0) #Era header = None\n",
    "            toClass = pd.read_csv(teste, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'track10', 'track11', 'duplicata'), header = 0) #Era header = None\n",
    "\n",
    "\n",
    "            # all['artist-title'] = all['artist'] * all['title']\n",
    "            # cols = list(all.columns.values)\n",
    "            # cols.pop(cols.index('duplicata'))\n",
    "            # all = all[cols+['duplicata']]\n",
    "\n",
    "            #Pesos baseados no Alg17\n",
    "\n",
    "            all['artist-title'] = all['artist'] * all['title']\n",
    "            all['soma-pesos'] = (all['artist']*1 + all['title']*2 + all['track01']*0.8 + all['track02']*0.8)/4.6 + (all['track03'] + all['track10'] + all['track11'])/3\n",
    "#             all['tracks'] = ((all['track01'] * all['track02'] * all['track03'] * all['track10'] * all['track11'])/(all['artist'] + all['title']))\n",
    "            cols = list(all.columns.values)\n",
    "            cols.pop(cols.index('duplicata'))\n",
    "            all = all[cols+['duplicata']]\n",
    "\n",
    "            # toClass['artist-title'] = toClass['artist'] * toClass['title']\n",
    "            # cols = list(toClass.columns.values)\n",
    "            # cols.pop(cols.index('duplicata'))\n",
    "            # toClass = toClass[cols+['duplicata']]\n",
    "\n",
    "            #Pesos baseados no Alg17\n",
    "\n",
    "            toClass['artist-title'] = toClass['artist'] * toClass['title']\n",
    "            toClass['soma-pesos'] = (toClass['artist']*1 + toClass['title']*2 + toClass['track01']*0.8 + toClass['track02']*0.8)/4.6 + (toClass['track03'] + toClass['track10'] + toClass['track11'])/3\n",
    "#             toClass['tracks'] = ((toClass['track01'] * toClass['track02'] * toClass['track03'] * toClass['track10'] * toClass['track11'])/(toClass['artist'] + toClass['title']))\n",
    "            cols = list(toClass.columns.values)\n",
    "            cols.pop(cols.index('duplicata'))\n",
    "            toClass = toClass[cols+['duplicata']]\n",
    "\n",
    "            #Separação do conjunto X do conjunto y\n",
    "            # X = all.loc[:,'title':'artist-title']\n",
    "            X = all.loc[:,'title':'soma-pesos']\n",
    "            y = all.duplicata\n",
    "\n",
    "            # XtoClass = toClass.loc[:,'title':'artist-title']\n",
    "            XtoClass = toClass.loc[:,'title':'soma-pesos']\n",
    "            ytoClass = toClass.duplicata\n",
    "\n",
    "            from sklearn import model_selection\n",
    "\n",
    "            X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            from sklearn.model_selection import StratifiedKFold\n",
    "            from sklearn.model_selection import KFold\n",
    "            from sklearn import model_selection\n",
    "\n",
    "            seed = 500\n",
    "\n",
    "            '''\n",
    "\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            from sklearn.tree import DecisionTreeClassifier\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            from sklearn.svm import SVC\n",
    "\n",
    "            modelos = []\n",
    "            modelos.append(('LR', LogisticRegression()))\n",
    "            modelos.append(('KNN', KNeighborsClassifier()))\n",
    "            modelos.append(('RFC', DecisionTreeClassifier()))\n",
    "            modelos.append(('SVM', SVC()))\n",
    "            modelos.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "\n",
    "            # Avaliação de cada modelo por vez\n",
    "            resultados = []\n",
    "            nomes = []\n",
    "            for nome, modelo in modelos:\n",
    "                kfold = StratifiedKFold(n_splits=10, random_state=seed) #Mudar para n-fold\n",
    "                cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "                msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std()) #Iprimir em um arquivo\n",
    "                print(msg)\n",
    "            '''\n",
    "\n",
    "            rfc = RandomForestClassifier(random_state=12)\n",
    "\n",
    "            from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "            param_grid = [{\"criterion\": ['gini', 'entropy'],\"n_estimators\": [10,25,30,35,40,45,50,100],\n",
    "                           #\"max_depth\": [2,3,4,5,6,7],\n",
    "                          \"class_weight\": [\"balanced\",None],\n",
    "                          \"min_samples_split\": [2, 5, 10]}]\n",
    "\n",
    "            score = 'f1'\n",
    "\n",
    "            print(\"# Tunando hiperparâmetros para %s\" % score)\n",
    "            print()\n",
    "\n",
    "            grid = GridSearchCV(rfc, param_grid, cv=5, scoring='%s_macro' % score)\n",
    "            grid.fit(X_train, y_train)\n",
    "\n",
    "            print(\"Melhor conjunto de hiperparâmetros encontrado:\")\n",
    "            print()\n",
    "            print(grid.best_params_)\n",
    "            # print()\n",
    "            # print(\"Grade de valores encontrados:\")\n",
    "            # print()\n",
    "            medias = grid.cv_results_['mean_test_score']\n",
    "            desvios = grid.cv_results_['std_test_score']\n",
    "            # for media, desvio, params in zip(medias, desvios, grid.cv_results_['params']):\n",
    "            #     print(\"%0.3f (+/-%0.03f) for %r\" % (media, desvio * 2, params))\n",
    "            #     print()\n",
    "\n",
    "            rfc = RandomForestClassifier(**grid.best_params_, random_state=500)\n",
    "\n",
    "    #         rfc = RandomForestClassifier(parameters = grid.best_params_, random_state=12)\n",
    "\n",
    "#             kfold = KFold(n_splits=2, random_state=seed)\n",
    "    \n",
    "#             try:\n",
    "    \n",
    "#                 kfold = StratifiedKFold(n_splits=10, random_state=seed) #Mudar para n-fold #Adicionado depois!\n",
    "        \n",
    "#             except ValueError:\n",
    "                \n",
    "# #                 kfold = StratifiedKFold(n_splits=5, random_state=seed) #Tirei pra ver se melhora\n",
    "            \n",
    "# #             except ValueError:\n",
    "                \n",
    "#                 kfold = KFold(n_splits=10, random_state=seed)\n",
    "            \n",
    "# #             except ValueError:\n",
    "                \n",
    "# #                 kfold = KFold(n_splits=5, random_state=seed)\n",
    "                \n",
    "# #             except ValueError:\n",
    "                \n",
    "# #                 kfold = KFold(random_state=seed) #Default n_splits = 3\n",
    "            \n",
    "# #             except ValueError:\n",
    "                \n",
    "# #                 kfold = KFold(n_splits=2, random_state=seed)\n",
    "            \n",
    "#             except:\n",
    "#                 print('Erro com a geração dos folds!')\n",
    "#                 print('Erro com o arquivo: ' + treino)\n",
    "#                 exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "#                 fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "#                 print(exc_type, fname, exc_tb.tb_lineno)\n",
    "#                 print(sys.exc_info())\n",
    "                \n",
    "            #Isso só serve para validar o uso do conjunto de treino \n",
    "            #Não influencia no resultado final\n",
    "#             try:\n",
    "#                 cv_results2 = model_selection.cross_val_score(rfc, X_train, y_train, cv=kfold, scoring='f1')\n",
    "#                 msg = \"%s com hiperparâmetros tunados: F1 = %f com desvio padrão = %f\" % ('RFC', cv_results2.mean(), cv_results2.std())\n",
    "#                 print(msg)\n",
    "            \n",
    "#             except:\n",
    "#                 print(\"ERRO NA VALIDAÇÃO CRUZADA!\")\n",
    "#                 exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "#                 fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "#                 print(exc_type, fname, exc_tb.tb_lineno)\n",
    "#                 print(sys.exc_info())\n",
    "\n",
    "                \n",
    "            rfc.fit(X_train, y_train) #Treinando o modelo\n",
    "            predicoes = rfc.predict(X_test) #Realizando a predição\n",
    "\n",
    "    #         from sklearn.metrics import confusion_matrix\n",
    "    #         matriz = confusion_matrix(y_test, predicoes)\n",
    "\n",
    "    #         print(matriz)\n",
    "\n",
    "            from sklearn.metrics import classification_report\n",
    "            from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "            # print(classification_report(y_test, predicoes))\n",
    "    #         prec, rec, fbeta, supp = precision_recall_fscore_support(y_test, predicoes, average=None)\n",
    "    #         print ('precision: %.5f' %(prec[1]))\n",
    "    #         print ('recall: %.5f' %(rec[1]))\n",
    "    #         print ('f1: %.5f' %(fbeta[1]))\n",
    "    #         print ('non-matches: %d - matches: %d' %(supp[0], supp[1]))\n",
    "    #         print('')\n",
    "\n",
    "            # from sklearn.externals.six import StringIO  \n",
    "            # from IPython.display import Image  \n",
    "            # from sklearn.tree import export_graphviz\n",
    "            # import pydotplus\n",
    "            # dot_data = StringIO()\n",
    "            # export_graphviz(rfc, out_file=dot_data,  \n",
    "            #                 filled=True, rounded=True,\n",
    "            #                 special_characters=True, feature_names=X.columns)\n",
    "            # graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "            # Image(graph.create_png())\n",
    "\n",
    "            predicoes = rfc.predict(XtoClass)\n",
    "\n",
    "            from sklearn.metrics import confusion_matrix\n",
    "            matriz = confusion_matrix(ytoClass, predicoes)\n",
    "            print(matriz)\n",
    "\n",
    "            this_tn, this_fp, this_fn, this_tp = 0, 0, 0, 0\n",
    "\n",
    "            this_tn, this_fp, this_fn, this_tp = confusion_matrix(ytoClass, predicoes).ravel()\n",
    "            print('tn, fp, fn, tp')\n",
    "            print(this_tn, this_fp, this_fn, this_tp)\n",
    "\n",
    "\n",
    "\n",
    "            from sklearn.metrics import classification_report\n",
    "            from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "            # print(classification_report(y_test, predicoes))\n",
    "    #         prec, rec, fbeta, supp = precision_recall_fscore_support(ytoClass, predicoes, average=None)\n",
    "    #         print ('precision: %.5f' %(prec[1]))\n",
    "    #         print ('recall: %.5f' %(rec[1]))\n",
    "    #         print ('f1: %.5f' %(fbeta[1]))\n",
    "    #         print ('non-matches: %d - matches: %d' %(supp[0], supp[1]))\n",
    "    #         print('')\n",
    "\n",
    "\n",
    "            ########################\n",
    "\n",
    "            #Atualizar as estatísticas\n",
    "            abordagem = 'DS'\n",
    "            #print 'abordagem é %s' %(abordagem)\n",
    "\n",
    "            #algUtl = linhaAtual['algoritmosUtilizados'].item()\n",
    "            iteracao = 2\n",
    "            inspecoesManuais = linhaAtual['inspecoesManuais'].item()\n",
    "            da = linhaAtual['da'].item() + (this_tp + this_fp) #Adiciona todos os casos positivos identificados\n",
    "            dm = linhaAtual['dm'].item()             #na predição\n",
    "            ndm = linhaAtual['ndm'].item()\n",
    "\n",
    "\n",
    "            fn = float(linhaAtual['fn'].item() - this_tp ) #Não tenho certeza se é isso\n",
    "            tp = this_tp + float(linhaAtual['tp'].item()) #+ dm) #Recuperar de toClass\n",
    "            print('tp é igual a: %d' %(tp))\n",
    "\n",
    "            fp = this_fp + float(linhaAtual['fp'].item())\n",
    "            #tn = tn + float(linhaAtual['tn'].item() - tp) #+ ndm) #Recuperar de toClass\n",
    "            tn = (9762 * 9763) / 2 -(tp+fp+fn)\n",
    "\n",
    "\n",
    "\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "            #Adicionando valor à última linha\n",
    "    #         estatisticas.loc[(etapa, permutacao), ['abordagem', 'algoritmosUtilizados', 'iteracao', 'inspecoesManuais',\n",
    "    #            'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "    #            'fp', 'tn', 'fn'] ] = ([abordagem, algUtl, iteracao, inspecoesManuais,\n",
    "    #            precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "            estatisticas.loc[(algUtl, permutacao, etapa), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais,\n",
    "                precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "\n",
    "            #'''\n",
    "\n",
    "    # estatisticas = estatisticas.reset_index(level=['etapa', 'permutacao'])\n",
    "    estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'permutacao', 'etapa'])\n",
    "    # estatisticas.head()                   \n",
    "    #                    \n",
    "\n",
    "    estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "    dirEst = \"../csv/\"\n",
    "    # dirEst = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/\"\n",
    "    # dirEst = \"../arqResult/csv/\"\n",
    "\n",
    "\n",
    "    estatisticas.to_csv(dirEst+'estatisticaInicialDS3-k'+str(k)+'.csv', sep=';', index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
