{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../csv/conjuntosDS/treinoTeste-k3/\n",
      "10\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)10.csv e test(10)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 10\n",
      "LR: 0.806667 (0.138082)\n",
      "KNN: 0.920000 (0.097980)\n",
      "DTC: 0.856667 (0.166032)\n",
      "SVM: 0.806667 (0.138082)\n",
      "RFC: 0.860000 (0.195959)\n",
      "[0.80666666666666664, 0.13808210118138653, 0.92000000000000015, 0.0979795897113271, 0.85666666666666669, 0.16603212540549694, 0.80666666666666664, 0.13808210118138653, 0.85999999999999999, 0.19595917942265426]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)11.csv e test(10)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 10\n",
      "LR: 0.566667 (0.300000)\n",
      "KNN: 0.550000 (0.394757)\n",
      "DTC: 0.550000 (0.394757)\n",
      "SVM: 0.316667 (0.320156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.433333 (0.448454)\n",
      "[0.56666666666666665, 0.29999999999999999, 0.55000000000000004, 0.39475730941090037, 0.55000000000000004, 0.39475730941090037, 0.3166666666666666, 0.32015621187164245, 0.43333333333333329, 0.448454134902457]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)12.csv e test(10)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 10\n",
      "LR: 0.870000 (0.107703)\n",
      "KNN: 0.881667 (0.123929)\n",
      "DTC: 0.863333 (0.141578)\n",
      "SVM: 0.861667 (0.119269)\n",
      "RFC: 0.825714 (0.130379)\n",
      "[0.86999999999999988, 0.1077032961426901, 0.8816666666666666, 0.12392874296680871, 0.86333333333333329, 0.14157840387730206, 0.86166666666666669, 0.11926860441876563, 0.82571428571428562, 0.13037883055075436]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)13.csv e test(10)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 10\n",
      "LR: 0.820000 (0.130128)\n",
      "KNN: 0.763333 (0.198018)\n",
      "DTC: 0.863333 (0.180401)\n",
      "SVM: 0.773333 (0.127192)\n",
      "RFC: 0.766667 (0.200000)\n",
      "[0.81999999999999995, 0.13012814197295425, 0.76333333333333331, 0.19801795653705526, 0.86333333333333329, 0.18040078836979745, 0.77333333333333332, 0.12719189352225943, 0.76666666666666672, 0.20000000000000001]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)14.csv e test(10)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 10\n",
      "LR: 0.889921 (0.082001)\n",
      "KNN: 0.912143 (0.093025)\n",
      "DTC: 0.765238 (0.175917)\n",
      "SVM: 0.912143 (0.093025)\n",
      "RFC: 0.878810 (0.113121)\n",
      "[0.88992063492063489, 0.082000720519912723, 0.91214285714285714, 0.093024574326203896, 0.76523809523809527, 0.17591742032985308, 0.91214285714285714, 0.093024574326203896, 0.87880952380952382, 0.11312130025520646]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)15.csv e test(10)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 10\n",
      "LR: 0.905714 (0.095661)\n",
      "KNN: 0.925714 (0.092317)\n",
      "DTC: 0.879048 (0.132791)\n",
      "SVM: 0.905714 (0.095661)\n",
      "RFC: 0.893333 (0.137275)\n",
      "[0.90571428571428569, 0.095660965958761168, 0.9257142857142856, 0.092317110979448627, 0.87904761904761908, 0.13279141572670633, 0.90571428571428569, 0.095660965958761168, 0.89333333333333331, 0.13727506854649335]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)16.csv e test(10)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 10\n",
      "ERRO com LR!\n",
      "KNN: 1.000000 (0.000000)\n",
      "DTC: 1.000000 (0.000000)\n",
      "ERRO com SVM!\n",
      "RFC: 1.000000 (0.000000)\n",
      "[0, 0, 1.0, 0.0, 1.0, 0.0, 0, 0, 1.0, 0.0]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)17.csv e test(10)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 10\n",
      "LR: 0.700000 (0.378594)\n",
      "KNN: 0.700000 (0.378594)\n",
      "DTC: 0.646667 (0.351568)\n",
      "SVM: 0.700000 (0.378594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.680000 (0.367333)\n",
      "[0.69999999999999996, 0.37859388972001823, 0.69999999999999996, 0.37859388972001823, 0.64666666666666672, 0.35156791662493891, 0.69999999999999996, 0.37859388972001823, 0.68000000000000005, 0.36733272837215764]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)18.csv e test(10)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 10\n",
      "ERRO com LR!\n",
      "KNN: 0.980000 (0.060000)\n",
      "DTC: 0.946667 (0.110755)\n",
      "ERRO com SVM!\n",
      "RFC: 0.980000 (0.060000)\n",
      "[0, 0, 0.98000000000000009, 0.059999999999999991, 0.94666666666666666, 0.11075498483890765, 0, 0, 0.98000000000000009, 0.059999999999999991]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)19.csv e test(10)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 10\n",
      "LR: 0.924242 (0.049946)\n",
      "KNN: 0.926227 (0.083367)\n",
      "DTC: 0.934798 (0.089776)\n",
      "SVM: 0.946429 (0.086381)\n",
      "RFC: 0.935317 (0.085921)\n",
      "[0.9242424242424242, 0.04994640531343883, 0.92622655122655129, 0.083367410247403378, 0.93479797979797985, 0.089775891773914707, 0.94642857142857151, 0.086381333017484463, 0.93531746031746044, 0.08592071702745778]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)20.csv e test(10)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 10\n",
      "LR: 0.873333 (0.134825)\n",
      "KNN: 0.873333 (0.134825)\n",
      "DTC: 0.700000 (0.295522)\n",
      "SVM: 0.873333 (0.134825)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.640000 (0.340196)\n",
      "[0.87333333333333341, 0.13482498944104454, 0.87333333333333341, 0.13482498944104454, 0.69999999999999996, 0.29552213679068667, 0.87333333333333341, 0.13482498944104454, 0.64000000000000001, 0.34019602192461529]\n",
      "15\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)10.csv e test(15)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 15\n",
      "LR: 0.873333 (0.134825)\n",
      "KNN: 0.906667 (0.120000)\n",
      "DTC: 0.880000 (0.151438)\n",
      "SVM: 0.926667 (0.117189)\n",
      "RFC: 0.846667 (0.157903)\n",
      "[0.87333333333333329, 0.13482498944104457, 0.90666666666666662, 0.12, 0.87999999999999989, 0.15143755588800731, 0.92666666666666653, 0.1171893055416463, 0.84666666666666668, 0.15790292376436016]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)11.csv e test(15)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 15\n",
      "LR: 0.884762 (0.130476)\n",
      "KNN: 0.931429 (0.085905)\n",
      "DTC: 0.892381 (0.116491)\n",
      "SVM: 0.901429 (0.152857)\n",
      "RFC: 0.932381 (0.112159)\n",
      "[0.88476190476190486, 0.1304761904761905, 0.93142857142857127, 0.085904550733559473, 0.89238095238095239, 0.11649063493350391, 0.90142857142857147, 0.15285714285714286, 0.93238095238095231, 0.11215877957937442]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)12.csv e test(15)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 15\n",
      "LR: 0.895238 (0.150283)\n",
      "KNN: 0.929870 (0.144524)\n",
      "DTC: 0.884921 (0.141751)\n",
      "SVM: 0.917460 (0.129887)\n",
      "RFC: 0.898413 (0.149779)\n",
      "[0.89523809523809528, 0.15028317941009048, 0.92987012987012996, 0.14452392460512783, 0.884920634920635, 0.14175056428168054, 0.91746031746031742, 0.1298874447331986, 0.89841269841269844, 0.14977937920108506]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)13.csv e test(15)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 15\n",
      "LR: 0.872381 (0.113425)\n",
      "KNN: 0.863333 (0.180401)\n",
      "DTC: 0.880000 (0.151438)\n",
      "SVM: 0.880000 (0.151438)\n",
      "RFC: 0.933333 (0.133333)\n",
      "[0.87238095238095248, 0.11342533280730976, 0.86333333333333329, 0.18040078836979745, 0.88000000000000012, 0.15143755588800731, 0.88000000000000012, 0.15143755588800731, 0.93333333333333324, 0.13333333333333336]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)14.csv e test(15)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 15\n",
      "LR: 0.932381 (0.112159)\n",
      "KNN: 0.900000 (0.152753)\n",
      "DTC: 0.881429 (0.151732)\n",
      "SVM: 0.926667 (0.117189)\n",
      "RFC: 0.896667 (0.171561)\n",
      "[0.93238095238095242, 0.11215877957937441, 0.90000000000000002, 0.15275252316519469, 0.88142857142857145, 0.1517315029240528, 0.92666666666666675, 0.11718930554164629, 0.8966666666666665, 0.17156145643277027]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)15.csv e test(15)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 15\n",
      "LR: 0.893741 (0.099687)\n",
      "KNN: 0.945707 (0.078675)\n",
      "DTC: 0.837453 (0.111170)\n",
      "SVM: 0.934596 (0.078066)\n",
      "RFC: 0.920707 (0.095394)\n",
      "[0.89374125874125876, 0.099686590146687223, 0.94570707070707072, 0.078674889844289095, 0.83745310245310234, 0.11116967989356233, 0.93459595959595954, 0.07806625303727123, 0.92070707070707081, 0.095394401446649693]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)16.csv e test(15)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 15\n",
      "LR: 0.945714 (0.084225)\n",
      "KNN: 0.954603 (0.072212)\n",
      "DTC: 0.943651 (0.070134)\n",
      "SVM: 0.985714 (0.042857)\n",
      "RFC: 0.965512 (0.053967)\n",
      "[0.94571428571428573, 0.084225159845620998, 0.95460317460317456, 0.072211581284828047, 0.94365079365079363, 0.070133767016239301, 0.98571428571428577, 0.042857142857142871, 0.96551226551226554, 0.053966903548938634]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)17.csv e test(15)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 15\n",
      "LR: 0.945714 (0.084225)\n",
      "KNN: 0.965714 (0.069752)\n",
      "DTC: 0.946667 (0.110755)\n",
      "SVM: 0.980000 (0.060000)\n",
      "RFC: 0.960000 (0.080000)\n",
      "[0.94571428571428573, 0.084225159845620998, 0.96571428571428564, 0.069751746375621163, 0.94666666666666666, 0.11075498483890765, 0.98000000000000009, 0.059999999999999991, 0.95999999999999996, 0.079999999999999988]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)18.csv e test(15)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 15\n",
      "LR: 0.845714 (0.166042)\n",
      "KNN: 0.899048 (0.134431)\n",
      "DTC: 0.747619 (0.212746)\n",
      "SVM: 0.819048 (0.302522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.830476 (0.218749)\n",
      "[0.84571428571428553, 0.16604236816912391, 0.8990476190476191, 0.13443085705595345, 0.74761904761904774, 0.21274578955893977, 0.81904761904761902, 0.30252152712892555, 0.83047619047619037, 0.21874927923431628]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)19.csv e test(15)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 15\n",
      "LR: 0.941270 (0.059413)\n",
      "KNN: 0.952381 (0.058966)\n",
      "DTC: 0.857540 (0.085561)\n",
      "SVM: 0.952381 (0.058966)\n",
      "RFC: 0.941667 (0.118145)\n",
      "[0.94126984126984126, 0.059412594514961573, 0.95238095238095233, 0.058965636892084776, 0.85753968253968238, 0.085560745785966286, 0.95238095238095233, 0.058965636892084776, 0.94166666666666665, 0.11814539065631523]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)20.csv e test(15)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 15\n",
      "LR: 0.880000 (0.151438)\n",
      "KNN: 0.900000 (0.152753)\n",
      "DTC: 0.880000 (0.151438)\n",
      "SVM: 0.900000 (0.152753)\n",
      "RFC: 0.913333 (0.136789)\n",
      "[0.87999999999999989, 0.15143755588800731, 0.90000000000000002, 0.15275252316519469, 0.88000000000000012, 0.15143755588800731, 0.90000000000000002, 0.15275252316519469, 0.91333333333333333, 0.13678856352455462]\n",
      "20\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)10.csv e test(20)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 20\n",
      "LR: 0.912121 (0.076801)\n",
      "KNN: 0.928485 (0.065132)\n",
      "DTC: 0.897929 (0.082045)\n",
      "SVM: 0.928687 (0.078804)\n",
      "RFC: 0.918759 (0.124423)\n",
      "[0.91212121212121211, 0.076800896586950967, 0.92848484848484847, 0.06513201493468547, 0.8979292929292928, 0.082044968769061616, 0.92868686868686878, 0.078803676219938834, 0.91875901875901866, 0.12442329625109526]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)11.csv e test(20)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 20\n",
      "LR: 0.920000 (0.097980)\n",
      "KNN: 0.872381 (0.113425)\n",
      "DTC: 0.756667 (0.197231)\n",
      "SVM: 0.886667 (0.119443)\n",
      "RFC: 0.886667 (0.119443)\n",
      "[0.92000000000000015, 0.0979795897113271, 0.87238095238095226, 0.11342533280730976, 0.7566666666666666, 0.19723082923316021, 0.88666666666666671, 0.11944315244779279, 0.88666666666666671, 0.11944315244779279]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)12.csv e test(20)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 20\n",
      "LR: 0.918095 (0.111733)\n",
      "KNN: 0.932381 (0.112159)\n",
      "DTC: 0.713810 (0.204712)\n",
      "SVM: 0.932381 (0.112159)\n",
      "RFC: 0.854762 (0.173810)\n",
      "[0.91809523809523808, 0.11173340476999974, 0.93238095238095242, 0.11215877957937442, 0.71380952380952389, 0.20471151096381568, 0.93238095238095242, 0.11215877957937442, 0.85476190476190472, 0.17380952380952383]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)13.csv e test(20)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 20\n",
      "LR: 0.910714 (0.082464)\n",
      "KNN: 0.940115 (0.061572)\n",
      "DTC: 0.924603 (0.063814)\n",
      "SVM: 0.926227 (0.083367)\n",
      "RFC: 0.921825 (0.086177)\n",
      "[0.91071428571428581, 0.082464289437925137, 0.94011544011544002, 0.061571537449982991, 0.92460317460317465, 0.06381366961182601, 0.92622655122655129, 0.083367410247403378, 0.92182539682539688, 0.086176918750155193]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)14.csv e test(20)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 20\n",
      "LR: 0.940000 (0.091652)\n",
      "KNN: 0.960000 (0.080000)\n",
      "DTC: 0.893333 (0.137275)\n",
      "SVM: 0.946667 (0.110755)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.866667 (0.305505)\n",
      "[0.94000000000000006, 0.091651513899116785, 0.95999999999999996, 0.079999999999999988, 0.89333333333333331, 0.13727506854649335, 0.94666666666666666, 0.11075498483890765, 0.86666666666666659, 0.30550504633038933]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)15.csv e test(20)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 20\n",
      "LR: 0.929004 (0.059761)\n",
      "KNN: 0.899048 (0.103268)\n",
      "DTC: 0.884762 (0.098064)\n",
      "SVM: 0.929206 (0.074425)\n",
      "RFC: 0.929206 (0.074425)\n",
      "[0.92900432900432917, 0.059761169145450162, 0.8990476190476191, 0.10326784553475871, 0.88476190476190486, 0.098064411861652087, 0.92920634920634926, 0.074424642846553077, 0.92920634920634926, 0.074424642846553063]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)16.csv e test(20)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 20\n",
      "LR: 0.905000 (0.087787)\n",
      "KNN: 0.897172 (0.120186)\n",
      "DTC: 0.888997 (0.125510)\n",
      "SVM: 0.915714 (0.073609)\n",
      "RFC: 0.899711 (0.117505)\n",
      "[0.90500000000000003, 0.087786567773671845, 0.89717171717171718, 0.1201857216689759, 0.88899711399711401, 0.12551044246130363, 0.9157142857142857, 0.073608533305310697, 0.89971139971139968, 0.11750542475343805]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)17.csv e test(20)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 20\n",
      "LR: 0.927381 (0.081982)\n",
      "KNN: 0.938492 (0.083527)\n",
      "DTC: 0.896270 (0.080431)\n",
      "SVM: 0.949206 (0.063014)\n",
      "RFC: 0.924603 (0.100452)\n",
      "[0.92738095238095242, 0.081981668396884977, 0.93849206349206349, 0.08352679734992477, 0.89626984126984133, 0.080430977249346905, 0.94920634920634916, 0.063014073781838764, 0.92460317460317465, 0.10045249099870947]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)18.csv e test(20)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 20\n",
      "LR: 0.867381 (0.117533)\n",
      "KNN: 0.945714 (0.084225)\n",
      "DTC: 0.877857 (0.140497)\n",
      "SVM: 0.945714 (0.084225)\n",
      "RFC: 0.945714 (0.084225)\n",
      "[0.86738095238095236, 0.11753346606927963, 0.94571428571428573, 0.084225159845620998, 0.87785714285714289, 0.14049656833633237, 0.94571428571428573, 0.084225159845620998, 0.94571428571428573, 0.084225159845620998]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)19.csv e test(20)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 20\n",
      "LR: 0.886667 (0.119443)\n",
      "KNN: 0.886667 (0.119443)\n",
      "DTC: 0.873333 (0.134825)\n",
      "SVM: 0.906667 (0.120000)\n",
      "RFC: 0.843333 (0.175151)\n",
      "[0.88666666666666671, 0.11944315244779279, 0.88666666666666671, 0.11944315244779279, 0.87333333333333329, 0.13482498944104457, 0.90666666666666662, 0.12, 0.84333333333333338, 0.17515072873892867]\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)20.csv e test(20)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 20\n",
      "LR: 0.881429 (0.102579)\n",
      "KNN: 0.876667 (0.128062)\n",
      "DTC: 0.835714 (0.209883)\n",
      "SVM: 0.899048 (0.134431)\n",
      "RFC: 0.892381 (0.116491)\n",
      "[0.88142857142857134, 0.10257898897723569, 0.87666666666666659, 0.128062484748657, 0.83571428571428574, 0.20988334952578602, 0.8990476190476191, 0.13443085705595345, 0.89238095238095239, 0.11649063493350392]\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# janelas = [2,3,4,5]\n",
    "janelas = [3]\n",
    "\n",
    "# estat_modelos = pd.DataFrame (columns=['algUtl','permutacao','modelo','media','desvio'])\n",
    "estat_modelos = pd.DataFrame (columns=['algUtl','permutacao', 'media-LR', 'desvio-LR', 'media-KNN', 'desvio-KNN', 'media-DTC', 'desvio-DTC', 'media-SVM', 'desvio-SVM', 'media-RFC', 'desvio-RFC'])\n",
    "# estat_modelos = pd.DataFrame (columns=['algUtl','permutacao', 'lista'])\n",
    "dirEst = \"../csv/\"\n",
    "\n",
    "for k in janelas:\n",
    "\n",
    "    abordagemAA = '2 - AA[dg-arj]' #'2 - AA[pet-chr]' ou '2 - AA[dg-arj]'\n",
    "    dirOrig = \"../csv/conjuntosDS/treinoTeste-k\"+str(k)+\"/\"\n",
    "    # dirOrig = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/conjuntosDS/treinoTeste/\"\n",
    "    # dirOrig = \"../arqResult/csv/conjuntosDS/conjuntosDiverg/treinoTeste/\"\n",
    "    # estat = \"../csv/estatisticaInicialDS2.csv\"\n",
    "    estat = \"../csv/estatisticaInicialDS2-DgArj-k\"+str(k)+\".csv\"\n",
    "    # estat = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/estatisticaInicialDS2.csv\"\n",
    "    # estat = \"../arqResult/csv/estatisticaInicialDS2.csv\"\n",
    "\n",
    "    print(dirOrig)\n",
    "    \n",
    "    etapa = '3 - clasf'\n",
    "\n",
    "    # estatisticas = pd.read_csv(estat, index_col=['etapa','permutacao'], sep=';')\n",
    "    estatisticas = pd.read_csv(estat, index_col=['algoritmosUtilizados','permutacao','etapa'], sep=';')\n",
    "#     estatisticas.tail()\n",
    "\n",
    "    arquivos = os.listdir(dirOrig)\n",
    "    # print(arquivos)\n",
    "    #print(len(arquivos))\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for arq in arquivos:\n",
    "        if arq.startswith(\"train\"):\n",
    "            train.append(arq)\n",
    "        elif arq.startswith(\"test\"):\n",
    "            test.append(arq)\n",
    "\n",
    "    # print('tamanho de train: %d' %(len(train)))        \n",
    "\n",
    "    # print('tamanho de test: %d' %(len(test)))\n",
    "\n",
    "    # print (train)    \n",
    "    # print (test)    \n",
    "\n",
    "\n",
    "\n",
    "    #lista = ['10', '15', '20', '25'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "    lista = ['10', '15', '20'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "#     lista = ['10'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "    # lista = ['3'] #Assumindo que serão esses os conjuntos de algoritmos\n",
    "\n",
    "    for i in lista: \n",
    "\n",
    "        cont = 0\n",
    "\n",
    "        trainAtual = []\n",
    "        testAtual = []\n",
    "\n",
    "        for arq in train:\n",
    "            if '('+i+')' in arq:\n",
    "#             if '('+i+')'+'20' in arq:\n",
    "#             if ('train(10)20' in arq) | ('train(15)20' in arq) | ('train(20)20' in arq):    \n",
    "                trainAtual.append(arq)\n",
    "        for arq in test:\n",
    "            if '('+i+')' in arq:\n",
    "#             if '('+i+')'+'20' in arq:\n",
    "#             if ('test(10)20' in arq) | ('test(15)20' in arq) | ('test(20)20' in arq):\n",
    "                testAtual.append(arq)\n",
    "\n",
    "    #     print('lista desordenada')\n",
    "    #     print(trainAtual)\n",
    "\n",
    "    #     print('tamanho antes: %d' %(len(trainAtual)))\n",
    "\n",
    "        #Ordenando a lista\n",
    "        trainAtual = sorted(trainAtual)\n",
    "        testAtual = sorted(testAtual)\n",
    "\n",
    "    #     for x in trainAtual:\n",
    "    #         print(x)\n",
    "\n",
    "\n",
    "\n",
    "    # #     print('lista ordenada')\n",
    "    # #     print(trainAtual)\n",
    "\n",
    "    #     print('tamanho depois: %d' %(len(trainAtual)))\n",
    "\n",
    "    #     print(type(trainAtual))\n",
    "\n",
    "\n",
    "        print (i)\n",
    "\n",
    "    #     print(trainAtual)\n",
    "    #     print(testAtual)\n",
    "\n",
    "        tam = len(trainAtual) #Mesma coisa para testAtual\n",
    "\n",
    "        for pos in range(tam):\n",
    "    #         print(pos)\n",
    "            print('')\n",
    "            print('##########################')\n",
    "            print('Arquivos atuais: %s e %s' %(trainAtual[pos], testAtual[pos]))\n",
    "            print('##########################')\n",
    "\n",
    "            treino = dirOrig+trainAtual[pos]\n",
    "            teste = dirOrig+testAtual[pos]\n",
    "\n",
    "    #         print('treino: %s' %(treino))\n",
    "\n",
    "    #         tp, fp, tn, fn = 0\n",
    "\n",
    "            num = trainAtual[pos].replace('train('+i+')','')\n",
    "            num = num.replace('.csv','')\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "            print('Iteração: %d' %(cont))\n",
    "\n",
    "    #         print('num: %s' %(num))\n",
    "\n",
    "            algUtl = re.sub('train.*\\(', r'', trainAtual[pos]) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = re.sub('\\).*', r'', algUtl) #Alterar para fazer a substituição de tudo em uma linha só\n",
    "            algUtl = int(algUtl)\n",
    "\n",
    "\n",
    "            print('algUtl: %d' %(algUtl))\n",
    "\n",
    "#             permutacao = int(num)\n",
    "    #         linhaAtual = estatisticas.loc[('2 - AA[pet-chr]', permutacao), : ] #Armazena a linha correspondente à permutação\n",
    "    #         linhaAtual = estatisticas.loc[('1 - acm diverg', permutacao), : ] #Armazena a linha correspondente à permutação\n",
    "#             linhaAtual = estatisticas.loc[algUtl, permutacao, abordagemAA, : ] #Armazena a linha correspondente à permutação\n",
    "#             print (linhaAtual)\n",
    "#             print(linhaAtual.columns)\n",
    "\n",
    "        #'''\n",
    "    #         all = pd.read_csv(\"train.csv\", index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "    #         toClass = pd.read_csv(\"test.csv\", index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "\n",
    "    #         all = pd.read_csv(treino, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "    #         toClass = pd.read_csv(teste, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'duplicata'), header = None)\n",
    "\n",
    "            all = pd.read_csv(treino, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'track10', 'track11', 'duplicata'), header = 0) #Era header = None\n",
    "            toClass = pd.read_csv(teste, index_col=False, sep=';', names=('title', 'artist', 'track01', 'track02', 'track03', 'track10', 'track11', 'duplicata'), header = 0) #Era header = None\n",
    "\n",
    "\n",
    "            # all['artist-title'] = all['artist'] * all['title']\n",
    "            # cols = list(all.columns.values)\n",
    "            # cols.pop(cols.index('duplicata'))\n",
    "            # all = all[cols+['duplicata']]\n",
    "\n",
    "            #Pesos baseados no Alg17\n",
    "\n",
    "            all['artist-title'] = all['artist'] * all['title']\n",
    "            all['soma-pesos'] = (all['artist']*1 + all['title']*2 + all['track01']*0.8 + all['track02']*0.8)/4.6\n",
    "            cols = list(all.columns.values)\n",
    "            cols.pop(cols.index('duplicata'))\n",
    "            all = all[cols+['duplicata']]\n",
    "\n",
    "            # toClass['artist-title'] = toClass['artist'] * toClass['title']\n",
    "            # cols = list(toClass.columns.values)\n",
    "            # cols.pop(cols.index('duplicata'))\n",
    "            # toClass = toClass[cols+['duplicata']]\n",
    "\n",
    "            #Pesos baseados no Alg17\n",
    "\n",
    "            toClass['artist-title'] = toClass['artist'] * toClass['title']\n",
    "            toClass['soma-pesos'] = (toClass['artist']*1 + toClass['title']*2 + toClass['track01']*0.8 + toClass['track02']*0.8)/4.6\n",
    "            cols = list(toClass.columns.values)\n",
    "            cols.pop(cols.index('duplicata'))\n",
    "            toClass = toClass[cols+['duplicata']]\n",
    "\n",
    "            #Separação do conjunto X do conjunto y\n",
    "            # X = all.loc[:,'title':'artist-title']\n",
    "            X = all.loc[:,'title':'soma-pesos']\n",
    "            y = all.duplicata\n",
    "\n",
    "            # XtoClass = toClass.loc[:,'title':'artist-title']\n",
    "            XtoClass = toClass.loc[:,'title':'soma-pesos']\n",
    "            ytoClass = toClass.duplicata\n",
    "\n",
    "            from sklearn import model_selection\n",
    "\n",
    "            X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            from sklearn.model_selection import StratifiedKFold\n",
    "            from sklearn.model_selection import KFold\n",
    "            from sklearn import model_selection\n",
    "\n",
    "            seed = 500\n",
    "\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            from sklearn.tree import DecisionTreeClassifier\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            from sklearn.svm import SVC\n",
    "\n",
    "            modelos = []\n",
    "            modelos.append(('LR', LogisticRegression()))\n",
    "            modelos.append(('KNN', KNeighborsClassifier()))\n",
    "            modelos.append(('DTC', DecisionTreeClassifier()))\n",
    "            modelos.append(('SVM', SVC()))\n",
    "            modelos.append(('RFC', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "\n",
    "            # Avaliação de cada modelo por vez\n",
    "            resultados = []\n",
    "            nomes = []\n",
    "            lista = []\n",
    "            for nome, modelo in modelos:\n",
    "                media = 0\n",
    "                desvio = 0\n",
    "                \n",
    "                try:\n",
    "                    kfold = StratifiedKFold(n_splits=10, random_state=seed) #Mudar para n-fold\n",
    "                    cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='f1')\n",
    "                    media = cv_results.mean()\n",
    "                    desvio = cv_results.std()\n",
    "                    msg = \"%s: %f (%f)\" % (nome, media, desvio) #Iprimir em um arquivo\n",
    "                    print(msg)\n",
    "                except ValueError:\n",
    "                    media = 0\n",
    "                    desvio = 0\n",
    "                    print('ERRO com {0}!'.format(nome))\n",
    "                    nome = nome + ' - ERRO!'\n",
    "#                     break\n",
    "                except:\n",
    "                    media = 0.0\n",
    "                    desvio = 0\n",
    "                    \n",
    "                \n",
    "#                 lista = lista + str(media) + ';' + str(desvio) + ';'\n",
    "                lista.append(media)\n",
    "                lista.append(desvio)\n",
    "            print(lista)   \n",
    "#                 estat_modelos.loc[len(estat_modelos.index)] = [algUtl, num, nome, media, desvio]\n",
    "            estat_modelos.loc[len(estat_modelos.index)] = [algUtl, num, lista[0], lista[1], lista[2], lista[3], lista[4], lista[5], lista[6], lista[7], lista[8], lista[9]]\n",
    "                \n",
    "#             estat_modelos.to_csv(dirEst+'estatisticasModelos.csv', sep=';', index=False)   \n",
    "    estat_modelos.to_csv(dirEst+'estatisticasModelos.csv', sep=';', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../csv/conjuntosDS/treinoTeste-k3/\n",
      "10\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)10.csv e test(10)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 50}\n",
      "[[351  14]\n",
      " [  4 152]]\n",
      "tn, fp, fn, tp\n",
      "351 14 4 152\n",
      "tp é igual a: 251\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)11.csv e test(10)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[758  27]\n",
      " [  7 106]]\n",
      "tn, fp, fn, tp\n",
      "758 27 7 106\n",
      "tp é igual a: 257\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)12.csv e test(10)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[517   9]\n",
      " [  8 158]]\n",
      "tn, fp, fn, tp\n",
      "517 9 8 158\n",
      "tp é igual a: 256\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)13.csv e test(10)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[351  10]\n",
      " [  9 147]]\n",
      "tn, fp, fn, tp\n",
      "351 10 9 147\n",
      "tp é igual a: 241\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)14.csv e test(10)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[460   9]\n",
      " [  9 158]]\n",
      "tn, fp, fn, tp\n",
      "460 9 9 158\n",
      "tp é igual a: 247\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)15.csv e test(10)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 35}\n",
      "[[393   8]\n",
      " [  3 179]]\n",
      "tn, fp, fn, tp\n",
      "393 8 3 179\n",
      "tp é igual a: 251\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)16.csv e test(10)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[  0  35]\n",
      " [  0 154]]\n",
      "tn, fp, fn, tp\n",
      "0 35 0 154\n",
      "tp é igual a: 248\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)17.csv e test(10)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 30}\n",
      "[[223  13]\n",
      " [ 10 165]]\n",
      "tn, fp, fn, tp\n",
      "223 13 10 165\n",
      "tp é igual a: 252\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)18.csv e test(10)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[ 17 506]\n",
      " [  4 166]]\n",
      "tn, fp, fn, tp\n",
      "17 506 4 166\n",
      "tp é igual a: 260\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)19.csv e test(10)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[341  10]\n",
      " [ 14 159]]\n",
      "tn, fp, fn, tp\n",
      "341 10 14 159\n",
      "tp é igual a: 230\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(10)20.csv e test(10)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 10\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 35}\n",
      "[[637  10]\n",
      " [  4 131]]\n",
      "tn, fp, fn, tp\n",
      "637 10 4 131\n",
      "tp é igual a: 251\n",
      "15\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)10.csv e test(15)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[706  11]\n",
      " [  9 181]]\n",
      "tn, fp, fn, tp\n",
      "706 11 9 181\n",
      "tp é igual a: 248\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)11.csv e test(15)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[138  12]\n",
      " [ 23 139]]\n",
      "tn, fp, fn, tp\n",
      "138 12 23 139\n",
      "tp é igual a: 238\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)12.csv e test(15)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[800  13]\n",
      " [ 15 170]]\n",
      "tn, fp, fn, tp\n",
      "800 13 15 170\n",
      "tp é igual a: 250\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)13.csv e test(15)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 45}\n",
      "[[534  11]\n",
      " [ 13 183]]\n",
      "tn, fp, fn, tp\n",
      "534 11 13 183\n",
      "tp é igual a: 252\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)14.csv e test(15)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[433  10]\n",
      " [  6 180]]\n",
      "tn, fp, fn, tp\n",
      "433 10 6 180\n",
      "tp é igual a: 251\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)15.csv e test(15)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[749  14]\n",
      " [  8 176]]\n",
      "tn, fp, fn, tp\n",
      "749 14 8 176\n",
      "tp é igual a: 256\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)16.csv e test(15)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[636  10]\n",
      " [ 25 132]]\n",
      "tn, fp, fn, tp\n",
      "636 10 25 132\n",
      "tp é igual a: 233\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)17.csv e test(15)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[470  12]\n",
      " [ 10 178]]\n",
      "tn, fp, fn, tp\n",
      "470 12 10 178\n",
      "tp é igual a: 249\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)18.csv e test(15)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "[[687  11]\n",
      " [  9 153]]\n",
      "tn, fp, fn, tp\n",
      "687 11 9 153\n",
      "tp é igual a: 249\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)19.csv e test(15)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'entropy', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "[[802   8]\n",
      " [ 17 167]]\n",
      "tn, fp, fn, tp\n",
      "802 8 17 167\n",
      "tp é igual a: 247\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(15)20.csv e test(15)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 15\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[803   8]\n",
      " [ 12 166]]\n",
      "tn, fp, fn, tp\n",
      "803 8 12 166\n",
      "tp é igual a: 253\n",
      "20\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)10.csv e test(20)10.csv\n",
      "##########################\n",
      "Iteração: 1\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': None, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[802  15]\n",
      " [ 13 175]]\n",
      "tn, fp, fn, tp\n",
      "802 15 13 175\n",
      "tp é igual a: 253\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)11.csv e test(20)11.csv\n",
      "##########################\n",
      "Iteração: 2\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[814  13]\n",
      " [ 14 172]]\n",
      "tn, fp, fn, tp\n",
      "814 13 14 172\n",
      "tp é igual a: 251\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)12.csv e test(20)12.csv\n",
      "##########################\n",
      "Iteração: 3\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[680  15]\n",
      " [  8 171]]\n",
      "tn, fp, fn, tp\n",
      "680 15 8 171\n",
      "tp é igual a: 250\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)13.csv e test(20)13.csv\n",
      "##########################\n",
      "Iteração: 4\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[774  18]\n",
      " [  4 173]]\n",
      "tn, fp, fn, tp\n",
      "774 18 4 173\n",
      "tp é igual a: 261\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)14.csv e test(20)14.csv\n",
      "##########################\n",
      "Iteração: 5\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[829  13]\n",
      " [ 21 169]]\n",
      "tn, fp, fn, tp\n",
      "829 13 21 169\n",
      "tp é igual a: 245\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)15.csv e test(20)15.csv\n",
      "##########################\n",
      "Iteração: 6\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 25}\n",
      "[[799  17]\n",
      " [ 12 182]]\n",
      "tn, fp, fn, tp\n",
      "799 17 12 182\n",
      "tp é igual a: 254\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)16.csv e test(20)16.csv\n",
      "##########################\n",
      "Iteração: 7\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 35}\n",
      "[[747  19]\n",
      " [ 11 174]]\n",
      "tn, fp, fn, tp\n",
      "747 19 11 174\n",
      "tp é igual a: 254\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)17.csv e test(20)17.csv\n",
      "##########################\n",
      "Iteração: 8\n",
      "algUtl: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tunando hiperparâmetros para f1\n",
      "\n",
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "[[588  13]\n",
      " [ 16 177]]\n",
      "tn, fp, fn, tp\n",
      "588 13 16 177\n",
      "tp é igual a: 250\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)18.csv e test(20)18.csv\n",
      "##########################\n",
      "Iteração: 9\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[685   9]\n",
      " [ 23 154]]\n",
      "tn, fp, fn, tp\n",
      "685 9 23 154\n",
      "tp é igual a: 235\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)19.csv e test(20)19.csv\n",
      "##########################\n",
      "Iteração: 10\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 10}\n",
      "[[705  12]\n",
      " [ 12 172]]\n",
      "tn, fp, fn, tp\n",
      "705 12 12 172\n",
      "tp é igual a: 247\n",
      "\n",
      "##########################\n",
      "Arquivos atuais: train(20)20.csv e test(20)20.csv\n",
      "##########################\n",
      "Iteração: 11\n",
      "algUtl: 20\n",
      "# Tunando hiperparâmetros para f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado:\n",
      "\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 25}\n",
      "[[816  11]\n",
      " [ 20 167]]\n",
      "tn, fp, fn, tp\n",
      "816 11 20 167\n",
      "tp é igual a: 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:399: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  user_expressions, allow_stdin)\n"
     ]
    }
   ],
   "source": [
    "            rfc = RandomForestClassifier(random_state=12)\n",
    "\n",
    "            from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "            param_grid = [{\"criterion\": ['gini', 'entropy'],\"n_estimators\": [10,25,30,35,40,45,50,100],\n",
    "                           #\"max_depth\": [2,3,4,5,6,7],\n",
    "                          \"class_weight\": [\"balanced\",None],\n",
    "                          \"min_samples_split\": [2, 5, 10]}]\n",
    "\n",
    "            score = 'f1'\n",
    "\n",
    "            print(\"# Tunando hiperparâmetros para %s\" % score)\n",
    "            print()\n",
    "\n",
    "            grid = GridSearchCV(rfc, param_grid, cv=5, scoring='%s_macro' % score)\n",
    "            grid.fit(X_train, y_train)\n",
    "\n",
    "            print(\"Melhor conjunto de hiperparâmetros encontrado:\")\n",
    "            print()\n",
    "            print(grid.best_params_)\n",
    "            # print()\n",
    "            # print(\"Grade de valores encontrados:\")\n",
    "            # print()\n",
    "            medias = grid.cv_results_['mean_test_score']\n",
    "            desvios = grid.cv_results_['std_test_score']\n",
    "            # for media, desvio, params in zip(medias, desvios, grid.cv_results_['params']):\n",
    "            #     print(\"%0.3f (+/-%0.03f) for %r\" % (media, desvio * 2, params))\n",
    "            #     print()\n",
    "\n",
    "            rfc = RandomForestClassifier(**grid.best_params_, random_state=500)\n",
    "\n",
    "    #         rfc = RandomForestClassifier(parameters = grid.best_params_, random_state=12)\n",
    "\n",
    "            kfold = KFold(n_splits=2, random_state=seed)\n",
    "    \n",
    "            try:\n",
    "    \n",
    "                kfold = StratifiedKFold(n_splits=10, random_state=seed) #Mudar para n-fold #Adicionado depois!\n",
    "        \n",
    "            except ValueError:\n",
    "                \n",
    "#                 kfold = StratifiedKFold(n_splits=5, random_state=seed) #Tirei pra ver se melhora\n",
    "            \n",
    "#             except ValueError:\n",
    "                \n",
    "                kfold = KFold(n_splits=10, random_state=seed)\n",
    "            \n",
    "#             except ValueError:\n",
    "                \n",
    "#                 kfold = KFold(n_splits=5, random_state=seed)\n",
    "                \n",
    "#             except ValueError:\n",
    "                \n",
    "#                 kfold = KFold(random_state=seed) #Default n_splits = 3\n",
    "            \n",
    "#             except ValueError:\n",
    "                \n",
    "#                 kfold = KFold(n_splits=2, random_state=seed)\n",
    "            \n",
    "            except:\n",
    "                print('Erro com a geração dos folds!')\n",
    "                print('Erro com o arquivo: ' + treino)\n",
    "                exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                print(sys.exc_info())\n",
    "                \n",
    "            #Isso só serve para validar o uso do conjunto de treino \n",
    "            #Não influencia no resultado final\n",
    "#             try:\n",
    "#                 cv_results2 = model_selection.cross_val_score(rfc, X_train, y_train, cv=kfold, scoring='f1')\n",
    "#                 msg = \"%s com hiperparâmetros tunados: F1 = %f com desvio padrão = %f\" % ('RFC', cv_results2.mean(), cv_results2.std())\n",
    "#                 print(msg)\n",
    "            \n",
    "#             except:\n",
    "#                 print(\"ERRO NA VALIDAÇÃO CRUZADA!\")\n",
    "#                 exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "#                 fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "#                 print(exc_type, fname, exc_tb.tb_lineno)\n",
    "#                 print(sys.exc_info())\n",
    "\n",
    "                \n",
    "            rfc.fit(X_train, y_train) #Treinando o modelo\n",
    "            predicoes = rfc.predict(X_test) #Realizando a predição\n",
    "\n",
    "    #         from sklearn.metrics import confusion_matrix\n",
    "    #         matriz = confusion_matrix(y_test, predicoes)\n",
    "\n",
    "    #         print(matriz)\n",
    "\n",
    "            from sklearn.metrics import classification_report\n",
    "            from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "            # print(classification_report(y_test, predicoes))\n",
    "    #         prec, rec, fbeta, supp = precision_recall_fscore_support(y_test, predicoes, average=None)\n",
    "    #         print ('precision: %.5f' %(prec[1]))\n",
    "    #         print ('recall: %.5f' %(rec[1]))\n",
    "    #         print ('f1: %.5f' %(fbeta[1]))\n",
    "    #         print ('non-matches: %d - matches: %d' %(supp[0], supp[1]))\n",
    "    #         print('')\n",
    "\n",
    "            # from sklearn.externals.six import StringIO  \n",
    "            # from IPython.display import Image  \n",
    "            # from sklearn.tree import export_graphviz\n",
    "            # import pydotplus\n",
    "            # dot_data = StringIO()\n",
    "            # export_graphviz(rfc, out_file=dot_data,  \n",
    "            #                 filled=True, rounded=True,\n",
    "            #                 special_characters=True, feature_names=X.columns)\n",
    "            # graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "            # Image(graph.create_png())\n",
    "\n",
    "            predicoes = rfc.predict(XtoClass)\n",
    "\n",
    "            from sklearn.metrics import confusion_matrix\n",
    "            matriz = confusion_matrix(ytoClass, predicoes)\n",
    "            print(matriz)\n",
    "\n",
    "            this_tn, this_fp, this_fn, this_tp = 0, 0, 0, 0\n",
    "\n",
    "            this_tn, this_fp, this_fn, this_tp = confusion_matrix(ytoClass, predicoes).ravel()\n",
    "            print('tn, fp, fn, tp')\n",
    "            print(this_tn, this_fp, this_fn, this_tp)\n",
    "\n",
    "\n",
    "\n",
    "            from sklearn.metrics import classification_report\n",
    "            from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "            # print(classification_report(y_test, predicoes))\n",
    "    #         prec, rec, fbeta, supp = precision_recall_fscore_support(ytoClass, predicoes, average=None)\n",
    "    #         print ('precision: %.5f' %(prec[1]))\n",
    "    #         print ('recall: %.5f' %(rec[1]))\n",
    "    #         print ('f1: %.5f' %(fbeta[1]))\n",
    "    #         print ('non-matches: %d - matches: %d' %(supp[0], supp[1]))\n",
    "    #         print('')\n",
    "\n",
    "\n",
    "            ########################\n",
    "\n",
    "            #Atualizar as estatísticas\n",
    "            abordagem = 'DS'\n",
    "            #print 'abordagem é %s' %(abordagem)\n",
    "\n",
    "            #algUtl = linhaAtual['algoritmosUtilizados'].item()\n",
    "            iteracao = 2\n",
    "            inspecoesManuais = linhaAtual['inspecoesManuais'].item()\n",
    "            da = linhaAtual['da'].item() + (this_tp + this_fp) #Adiciona todos os casos positivos identificados\n",
    "            dm = linhaAtual['dm'].item()             #na predição\n",
    "            ndm = linhaAtual['ndm'].item()\n",
    "\n",
    "\n",
    "            fn = float(linhaAtual['fn'].item() - this_tp ) #Não tenho certeza se é isso\n",
    "            tp = this_tp + float(linhaAtual['tp'].item()) #+ dm) #Recuperar de toClass\n",
    "            print('tp é igual a: %d' %(tp))\n",
    "\n",
    "            fp = this_fp + float(linhaAtual['fp'].item())\n",
    "            #tn = tn + float(linhaAtual['tn'].item() - tp) #+ ndm) #Recuperar de toClass\n",
    "            tn = (9762 * 9763) / 2 -(tp+fp+fn)\n",
    "\n",
    "\n",
    "\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            fmeasure = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "            #Adicionando valor à última linha\n",
    "    #         estatisticas.loc[(etapa, permutacao), ['abordagem', 'algoritmosUtilizados', 'iteracao', 'inspecoesManuais',\n",
    "    #            'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "    #            'fp', 'tn', 'fn'] ] = ([abordagem, algUtl, iteracao, inspecoesManuais,\n",
    "    #            precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "            estatisticas.loc[(algUtl, permutacao, etapa), ['abordagem', 'iteracao', 'inspecoesManuais',\n",
    "                'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp',\n",
    "                'fp', 'tn', 'fn'] ] = ([abordagem, iteracao, inspecoesManuais,\n",
    "                precision, recall, fmeasure, da, dm, ndm, tp, fp, tn, fn])\n",
    "\n",
    "            #'''\n",
    "\n",
    "    # estatisticas = estatisticas.reset_index(level=['etapa', 'permutacao'])\n",
    "    estatisticas = estatisticas.reset_index(level=['algoritmosUtilizados', 'permutacao', 'etapa'])\n",
    "    # estatisticas.head()                   \n",
    "    #                    \n",
    "\n",
    "    estatisticas = estatisticas[['abordagem', 'etapa', 'algoritmosUtilizados', 'permutacao', 'iteracao', 'inspecoesManuais', 'precision', 'recall', 'f-measure', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']]\n",
    "\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']] = \\\n",
    "    estatisticas[['algoritmosUtilizados', 'iteracao', 'inspecoesManuais', 'da', 'dm', 'ndm', 'tp', 'fp', 'tn', 'fn']].astype(int)\n",
    "\n",
    "    dirEst = \"../csv/\"\n",
    "    # dirEst = \"c:/Users/Diego/Documents/NetBeansProjects/Master-SKYAM/AS/src/csv/\"\n",
    "    # dirEst = \"../arqResult/csv/\"\n",
    "\n",
    "\n",
    "    estatisticas.to_csv(dirEst+'estatisticaInicialDS3-k'+str(k)+'.csv', sep=';', index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
